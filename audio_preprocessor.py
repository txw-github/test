
import os
import logging
import numpy as np
import soundfile as sf
from typing import Optional, Tuple, Dict
import tempfile
import subprocess
import json

logger = logging.getLogger(__name__)

class AdvancedAudioPreprocessor:
    """é«˜çº§éŸ³é¢‘é¢„å¤„ç†å™¨ - é’ˆå¯¹ä¸­æ–‡è¯­éŸ³è¯†åˆ«ä¼˜åŒ–"""

    def __init__(self, target_sample_rate: int = 16000, config_path: str = "audio_config.json"):
        self.target_sample_rate = target_sample_rate
        self.config = self._load_config(config_path)
        
        # è®¾ç½®FFmpegè·¯å¾„ï¼ˆå¦‚æœç”¨æˆ·æœ‰è‡ªå®šä¹‰è·¯å¾„ï¼‰
        ffmpeg_path = os.environ.get("FFMPEG_PATH")
        if ffmpeg_path:
            os.environ["PATH"] += os.pathsep + ffmpeg_path
        
    def _load_config(self, config_path: str) -> Dict:
        """åŠ è½½éŸ³é¢‘å¤„ç†é…ç½®"""
        default_config = {
            "noise_reduction": {
                "enable": True,
                "strength": 0.7,
                "method": "multi_stage",
                "adaptive": True
            },
            "voice_enhancement": {
                "enable": True,
                "vocal_isolation": True,
                "frequency_emphasis": [300, 3400],
                "dynamic_range_compression": True,
                "consonant_enhancement": True
            },
            "normalization": {
                "enable": True,
                "target_lufs": -16,
                "peak_limit": -1.5,
                "loudness_range": 11
            },
            "chinese_optimization": {
                "enable": True,
                "tone_preservation": True,
                "consonant_enhancement": True,
                "frequency_profile": "mandarin"
            },
            "advanced_features": {
                "speech_enhancement": True,
                "background_music_suppression": True,
                "reverb_reduction": True,
                "click_removal": True
            }
        }
        
        if os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                    # æ·±åº¦åˆå¹¶é…ç½®
                    for key in default_config:
                        if key in user_config and isinstance(user_config[key], dict):
                            default_config[key].update(user_config[key])
                    return default_config
            except Exception as e:
                logger.warning(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        
        return default_config

    def preprocess_audio(self, audio_path: str, output_path: Optional[str] = None, quality: str = "high") -> str:
        """
        å¤šçº§éŸ³é¢‘é¢„å¤„ç†ä»¥æé«˜ä¸­æ–‡è¯†åˆ«è´¨é‡
        quality: "high", "balanced", "fast"
        """
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")

        if output_path is None:
            temp_dir = tempfile.gettempdir()
            output_path = os.path.join(temp_dir, "enhanced_audio.wav")

        try:
            logger.info(f"ğŸµ å¼€å§‹é«˜çº§éŸ³é¢‘é¢„å¤„ç†: {audio_path} (è´¨é‡: {quality})")

            # æ ¹æ®è´¨é‡ç­‰çº§è°ƒæ•´å¤„ç†å‚æ•°
            quality_configs = {
                "high": {
                    "noise_strength": 0.8,
                    "voice_enhancement": True,
                    "advanced_processing": True,
                    "stages": 5
                },
                "balanced": {
                    "noise_strength": 0.6,
                    "voice_enhancement": True,
                    "advanced_processing": True,
                    "stages": 4
                },
                "fast": {
                    "noise_strength": 0.4,
                    "voice_enhancement": False,
                    "advanced_processing": False,
                    "stages": 3
                }
            }
            
            config = quality_configs.get(quality, quality_configs["balanced"])

            # é˜¶æ®µ1: åŸºç¡€æ ¼å¼è½¬æ¢å’Œé¢„å¤„ç†
            stage1_path = self._stage1_format_conversion(audio_path)
            
            # é˜¶æ®µ2: é«˜çº§é™å™ª
            stage2_path = self._stage2_advanced_noise_reduction(stage1_path, config["noise_strength"])
            
            # é˜¶æ®µ3: è¯­éŸ³å¢å¼ºï¼ˆå¯é€‰ï¼‰
            if config["voice_enhancement"]:
                stage3_path = self._stage3_voice_enhancement(stage2_path)
            else:
                stage3_path = stage2_path
            
            # é˜¶æ®µ4: ä¸­æ–‡è¯­éŸ³ä¼˜åŒ–
            stage4_path = self._stage4_chinese_optimization(stage3_path)
            
            # é˜¶æ®µ5: é«˜çº§åå¤„ç†ï¼ˆå¯é€‰ï¼‰
            if config["advanced_processing"]:
                stage5_path = self._stage5_advanced_postprocessing(stage4_path)
            else:
                stage5_path = stage4_path
            
            # æœ€ç»ˆé˜¶æ®µ: æ ‡å‡†åŒ–è¾“å‡º
            final_path = self._stage_final_normalization(stage5_path, output_path)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            temp_files = [stage1_path, stage2_path, stage3_path, stage4_path, stage5_path]
            self._cleanup_temp_files([f for f in temp_files if f != output_path])
            
            logger.info(f"âœ… éŸ³é¢‘é¢„å¤„ç†å®Œæˆ: {output_path}")
            return final_path

        except Exception as e:
            logger.error(f"âŒ éŸ³é¢‘é¢„å¤„ç†å¤±è´¥: {e}")
            return audio_path

    def _stage1_format_conversion(self, audio_path: str) -> str:
        """é˜¶æ®µ1: æ ¼å¼è½¬æ¢å’ŒåŸºç¡€é¢„å¤„ç†"""
        temp_path = tempfile.mktemp(suffix="_stage1.wav")
        
        try:
            # åŸºç¡€è½¬æ¢ + åˆæ­¥æ ‡å‡†åŒ–
            cmd = [
                "ffmpeg", "-y", "-i", audio_path,
                "-ar", str(self.target_sample_rate),
                "-ac", "1",  # å•å£°é“
                "-af", "volume=1.0",  # ä¿æŒåŸå§‹éŸ³é‡
                "-acodec", "pcm_s16le",
                "-loglevel", "error",
                temp_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode != 0:
                raise RuntimeError(f"æ ¼å¼è½¬æ¢å¤±è´¥: {result.stderr}")
                
            logger.debug("âœ“ é˜¶æ®µ1: æ ¼å¼è½¬æ¢å®Œæˆ")
            return temp_path
            
        except Exception as e:
            if os.path.exists(temp_path):
                os.remove(temp_path)
            raise

    def _stage2_advanced_noise_reduction(self, audio_path: str, strength: float) -> str:
        """é˜¶æ®µ2: é«˜çº§å¤šå±‚é™å™ª"""
        temp_path = tempfile.mktemp(suffix="_stage2.wav")
        
        try:
            if not self.config["noise_reduction"]["enable"]:
                import shutil
                shutil.copy2(audio_path, temp_path)
                return temp_path
            
            # æ„å»ºå¤šå±‚é™å™ªæ»¤é•œé“¾
            filters = []
            
            # 1. é«˜é€šæ»¤æ³¢å™¨ - å»é™¤ä½é¢‘å™ªå£°
            filters.append("highpass=f=85")
            
            # 2. ä½é€šæ»¤æ³¢å™¨ - å»é™¤é«˜é¢‘å™ªå£°  
            filters.append("lowpass=f=7500")
            
            # 3. è‡ªé€‚åº”é™å™ª
            filters.append(f"afftdn=nf=-20:nt=w:om=o:tn=1:tf=0.5")
            
            # 4. å»é™¤ç‚¹å‡»å£°å’Œçˆ†éŸ³
            filters.append("declick=t=w:l=2")
            
            # 5. å»é™¤å˜¶å˜¶å£°
            filters.append("dehiss=m=o")
            
            # 6. åŠ¨æ€é™å™ª (æ ¹æ®å¼ºåº¦è°ƒæ•´)
            if strength > 0.6:
                filters.append(f"anlmdn=s={strength}:p=0.002:r=0.002:m=15")
            
            # 7. é—¨é™é™å™ª
            filters.append("agate=threshold=0.1:ratio=2:attack=10:release=100")
            
            filter_chain = ",".join(filters)
            
            cmd = [
                "ffmpeg", "-y", "-i", audio_path,
                "-af", filter_chain,
                "-acodec", "pcm_s16le",
                "-loglevel", "error",
                temp_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode != 0:
                # é™å™ªå¤±è´¥æ—¶ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
                logger.warning("é«˜çº§é™å™ªå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€é™å™ª")
                simple_cmd = [
                    "ffmpeg", "-y", "-i", audio_path,
                    "-af", "highpass=f=85,lowpass=f=7500,afftdn=nf=-15",
                    "-acodec", "pcm_s16le",
                    "-loglevel", "error",
                    temp_path
                ]
                subprocess.run(simple_cmd, check=True, capture_output=True)
                
            logger.debug("âœ“ é˜¶æ®µ2: é«˜çº§é™å™ªå®Œæˆ")
            return temp_path
            
        except Exception as e:
            if os.path.exists(temp_path):
                os.remove(temp_path)
            raise

    def _stage3_voice_enhancement(self, audio_path: str) -> str:
        """é˜¶æ®µ3: è¯­éŸ³å¢å¼º"""
        temp_path = tempfile.mktemp(suffix="_stage3.wav")
        
        try:
            filters = []
            
            # 1. è¯­éŸ³é¢‘æ®µå¢å¼º (ä¸­æ–‡è¯­éŸ³ä¼˜åŒ–)
            filters.append("equalizer=f=300:width_type=h:width=1000:g=3")
            filters.append("equalizer=f=800:width_type=h:width=800:g=2.5")
            filters.append("equalizer=f=1600:width_type=h:width=600:g=2")
            filters.append("equalizer=f=3200:width_type=h:width=800:g=1.5")
            
            # 2. ä¸­æ–‡å£°è°ƒä¿æŠ¤å‹ç¼©
            filters.append("acompressor=threshold=0.4:ratio=2.5:attack=3:release=40:makeup=1")
            
            # 3. è¾…éŸ³å¢å¼º - æé«˜æ¸…æ™°åº¦
            filters.append("equalizer=f=4000:width_type=h:width=2000:g=2")
            filters.append("equalizer=f=6000:width_type=h:width=1500:g=1")
            
            # 4. å¤šé¢‘æ®µå‹ç¼©
            filters.append("mcompand=0.005,0.1 6 -47/-40,-34/-34,-17/-33 100 | 0.003,0.05 6 -47/-40,-34/-34,-17/-33 400 | 0.000625,0.0125 6 -47/-40,-34/-34,-15/-33 1600 | 0.0001,0.025 6 -47/-40,-34/-34,-31/-31,-0/-30 6400 | 0,0.025 6 -38/-31,-28/-28,-0/-25 22000")
            
            filter_chain = ",".join(filters)
            
            cmd = [
                "ffmpeg", "-y", "-i", audio_path,
                "-af", filter_chain,
                "-acodec", "pcm_s16le",
                "-loglevel", "error",
                temp_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode != 0:
                raise RuntimeError(f"è¯­éŸ³å¢å¼ºå¤±è´¥: {result.stderr}")
                
            logger.debug("âœ“ é˜¶æ®µ3: è¯­éŸ³å¢å¼ºå®Œæˆ")
            return temp_path
            
        except Exception as e:
            if os.path.exists(temp_path):
                os.remove(temp_path)
            raise

    def _stage4_chinese_optimization(self, audio_path: str) -> str:
        """é˜¶æ®µ4: ä¸­æ–‡è¯­éŸ³ä¸“é¡¹ä¼˜åŒ–"""
        temp_path = tempfile.mktemp(suffix="_stage4.wav")
        
        try:
            if not self.config["chinese_optimization"]["enable"]:
                import shutil
                shutil.copy2(audio_path, temp_path)
                return temp_path
            
            filters = []
            
            # 1. ä¸­æ–‡éŸ³è°ƒé¢‘ç‡ä¿æŠ¤
            filters.append("equalizer=f=200:width_type=h:width=400:g=1")  # åŸºé¢‘ä¿æŠ¤
            filters.append("equalizer=f=400:width_type=h:width=600:g=2")  # äºŒæ¬¡è°æ³¢
            
            # 2. ä¸­æ–‡è¾…éŸ³æ¸…æ™°åº¦å¢å¼º
            filters.append("equalizer=f=2500:width_type=h:width=1000:g=1.5")
            filters.append("equalizer=f=5000:width_type=h:width=1500:g=1.2")
            
            # 3. è¯­éŸ³æ´»åŠ¨æ£€æµ‹ä¼˜åŒ–å‹ç¼©
            filters.append("acompressor=threshold=0.3:ratio=3:attack=2:release=30:knee=2")
            
            # 4. ä¸­æ–‡è¯­éŸ³ç‰¹æœ‰çš„åŠ¨æ€èŒƒå›´ä¼˜åŒ–
            filters.append("dynaudnorm=framelen=500:gausssize=31:peak=0.95:maxgain=10:targetrms=0.20")
            
            filter_chain = ",".join(filters)
            
            cmd = [
                "ffmpeg", "-y", "-i", audio_path,
                "-af", filter_chain,
                "-acodec", "pcm_s16le",
                "-loglevel", "error",
                temp_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode != 0:
                raise RuntimeError(f"ä¸­æ–‡ä¼˜åŒ–å¤±è´¥: {result.stderr}")
                
            logger.debug("âœ“ é˜¶æ®µ4: ä¸­æ–‡ä¼˜åŒ–å®Œæˆ")
            return temp_path
            
        except Exception as e:
            if os.path.exists(temp_path):
                os.remove(temp_path)
            raise

    def _stage5_advanced_postprocessing(self, audio_path: str) -> str:
        """é˜¶æ®µ5: é«˜çº§åå¤„ç†"""
        temp_path = tempfile.mktemp(suffix="_stage5.wav")
        
        try:
            filters = []
            
            # 1. å»æ··å“
            if self.config["advanced_features"]["reverb_reduction"]:
                filters.append("aderivative")
                filters.append("aintegral")
            
            # 2. èƒŒæ™¯éŸ³ä¹æŠ‘åˆ¶
            if self.config["advanced_features"]["background_music_suppression"]:
                filters.append("extrastereo=m=0.5")  # ç«‹ä½“å£°åˆ†ç¦»
                filters.append("earwax")  # äººå£°çªå‡º
            
            # 3. æœ€ç»ˆæ¸…ç†
            filters.append("silenceremove=start_periods=1:start_silence=0.1:start_threshold=0.02")
            
            if filters:
                filter_chain = ",".join(filters)
                
                cmd = [
                    "ffmpeg", "-y", "-i", audio_path,
                    "-af", filter_chain,
                    "-acodec", "pcm_s16le",
                    "-loglevel", "error",
                    temp_path
                ]
                
                result = subprocess.run(cmd, capture_output=True, text=True)
                if result.returncode != 0:
                    # åå¤„ç†å¤±è´¥æ—¶ç›´æ¥å¤åˆ¶
                    import shutil
                    shutil.copy2(audio_path, temp_path)
            else:
                import shutil
                shutil.copy2(audio_path, temp_path)
                
            logger.debug("âœ“ é˜¶æ®µ5: é«˜çº§åå¤„ç†å®Œæˆ")
            return temp_path
            
        except Exception as e:
            if os.path.exists(temp_path):
                os.remove(temp_path)
            # å¤±è´¥æ—¶ç›´æ¥å¤åˆ¶åŸæ–‡ä»¶
            import shutil
            shutil.copy2(audio_path, temp_path)
            return temp_path

    def _stage_final_normalization(self, audio_path: str, output_path: str) -> str:
        """æœ€ç»ˆé˜¶æ®µ: æ ‡å‡†åŒ–è¾“å‡º"""
        try:
            # æœ€ç»ˆæ ‡å‡†åŒ–å’Œé™åˆ¶
            cmd = [
                "ffmpeg", "-y", "-i", audio_path,
                "-af", f"loudnorm=I={self.config['normalization']['target_lufs']}:TP={self.config['normalization']['peak_limit']}:LRA={self.config['normalization']['loudness_range']},alimiter=level_in=1:level_out=0.95:limit=0.98",
                "-acodec", "pcm_s16le",
                "-loglevel", "error",
                output_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode != 0:
                raise RuntimeError(f"æœ€ç»ˆæ ‡å‡†åŒ–å¤±è´¥: {result.stderr}")
                
            logger.debug("âœ“ æœ€ç»ˆé˜¶æ®µ: æ ‡å‡†åŒ–å®Œæˆ")
            return output_path
            
        except Exception as e:
            # æœ€ç»ˆå¤±è´¥æ—¶ç›´æ¥å¤åˆ¶
            import shutil
            shutil.copy2(audio_path, output_path)
            return output_path

    def _cleanup_temp_files(self, temp_files: list):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        for temp_file in temp_files:
            try:
                if temp_file and os.path.exists(temp_file):
                    os.remove(temp_file)
            except:
                pass

    def analyze_audio_quality(self, audio_path: str) -> Dict:
        """è¯¦ç»†çš„éŸ³é¢‘è´¨é‡åˆ†æ"""
        try:
            audio_data, sample_rate = sf.read(audio_path)
            
            if len(audio_data.shape) > 1:
                audio_data = np.mean(audio_data, axis=1)

            # è®¡ç®—å„ç§è´¨é‡æŒ‡æ ‡
            metrics = {
                "duration": len(audio_data) / sample_rate,
                "sample_rate": sample_rate,
                "rms_level": float(np.sqrt(np.mean(audio_data**2))),
                "peak_level": float(np.max(np.abs(audio_data))),
                "dynamic_range": self._calculate_dynamic_range(audio_data),
                "frequency_analysis": self._analyze_frequency_content(audio_data, sample_rate),
                "speech_clarity": self._estimate_speech_clarity(audio_data, sample_rate),
                "noise_level": self._estimate_noise_level(audio_data),
                "chinese_speech_score": self._chinese_speech_analysis(audio_data, sample_rate)
            }

            # ç»¼åˆè´¨é‡è¯„åˆ†
            quality_score = self._calculate_comprehensive_score(metrics)
            metrics["overall_score"] = quality_score
            metrics["recommendations"] = self._generate_recommendations(metrics)

            logger.info(f"ğŸ“Š éŸ³é¢‘è´¨é‡åˆ†æ - æ—¶é•¿: {metrics['duration']:.1f}s, "
                       f"ç»¼åˆè¯„åˆ†: {quality_score:.1f}, "
                       f"ä¸­æ–‡é€‚é…åº¦: {metrics['chinese_speech_score']:.1f}")

            return metrics

        except Exception as e:
            logger.error(f"éŸ³é¢‘è´¨é‡åˆ†æå¤±è´¥: {e}")
            return {}

    def _calculate_dynamic_range(self, audio_data: np.ndarray) -> float:
        """è®¡ç®—åŠ¨æ€èŒƒå›´"""
        try:
            rms_values = []
            frame_size = int(0.1 * self.target_sample_rate)  # 100mså¸§
            
            for i in range(0, len(audio_data) - frame_size, frame_size):
                frame = audio_data[i:i + frame_size]
                rms = np.sqrt(np.mean(frame**2))
                if rms > 0:
                    rms_values.append(20 * np.log10(rms))
            
            if len(rms_values) > 1:
                return float(np.max(rms_values) - np.min(rms_values))
            return 0.0
        except:
            return 0.0

    def _analyze_frequency_content(self, audio_data: np.ndarray, sample_rate: int) -> Dict:
        """é¢‘ç‡å†…å®¹åˆ†æ"""
        try:
            from scipy import signal
            
            # è®¡ç®—åŠŸç‡è°±å¯†åº¦
            frequencies, psd = signal.welch(audio_data, sample_rate, nperseg=1024)
            
            # åˆ†æä¸åŒé¢‘æ®µçš„èƒ½é‡
            low_freq = np.sum(psd[(frequencies >= 80) & (frequencies <= 300)])
            mid_freq = np.sum(psd[(frequencies >= 300) & (frequencies <= 3400)])
            high_freq = np.sum(psd[(frequencies >= 3400) & (frequencies <= 8000)])
            
            total_energy = low_freq + mid_freq + high_freq
            
            if total_energy > 0:
                return {
                    "low_freq_ratio": float(low_freq / total_energy),
                    "mid_freq_ratio": float(mid_freq / total_energy),
                    "high_freq_ratio": float(high_freq / total_energy),
                    "speech_freq_dominance": float(mid_freq / total_energy)
                }
            else:
                return {"low_freq_ratio": 0, "mid_freq_ratio": 0, "high_freq_ratio": 0, "speech_freq_dominance": 0}
                
        except ImportError:
            logger.debug("scipyæœªå®‰è£…ï¼Œè·³è¿‡é¢‘ç‡åˆ†æ")
            return {"speech_freq_dominance": 0.5}  # é»˜è®¤å€¼
        except:
            return {"speech_freq_dominance": 0.5}

    def _estimate_speech_clarity(self, audio_data: np.ndarray, sample_rate: int) -> float:
        """ä¼°ç®—è¯­éŸ³æ¸…æ™°åº¦"""
        try:
            # è®¡ç®—è¯­éŸ³æ´»åŠ¨æ£€æµ‹
            frame_length = int(0.025 * sample_rate)  # 25ms
            hop_length = int(0.01 * sample_rate)     # 10ms
            
            speech_frames = 0
            total_frames = 0
            
            for i in range(0, len(audio_data) - frame_length, hop_length):
                frame = audio_data[i:i + frame_length]
                energy = np.sum(frame**2)
                zcr = np.sum(np.abs(np.diff(np.sign(frame))))
                
                # æ”¹è¿›çš„VAD
                if energy > 0.0005 and 15 < zcr < 150:
                    speech_frames += 1
                total_frames += 1
            
            if total_frames > 0:
                return float(speech_frames / total_frames)
            return 0.0
        except:
            return 0.5

    def _estimate_noise_level(self, audio_data: np.ndarray) -> float:
        """ä¼°ç®—å™ªå£°æ°´å¹³"""
        try:
            # ä½¿ç”¨å‰å1ç§’ä½œä¸ºé™éŸ³å‚è€ƒ
            silence_samples = int(1.0 * self.target_sample_rate)
            
            if len(audio_data) > 2 * silence_samples:
                start_silence = audio_data[:silence_samples]
                end_silence = audio_data[-silence_samples:]
                silence_rms = np.sqrt(np.mean(np.concatenate([start_silence, end_silence])**2))
                
                overall_rms = np.sqrt(np.mean(audio_data**2))
                
                if overall_rms > 0:
                    snr = 20 * np.log10(overall_rms / (silence_rms + 1e-10))
                    return max(0, min(100, float(snr)))
            
            return 25.0  # é»˜è®¤SNR
        except:
            return 25.0

    def _chinese_speech_analysis(self, audio_data: np.ndarray, sample_rate: int) -> float:
        """ä¸­æ–‡è¯­éŸ³ç‰¹å¾åˆ†æ"""
        try:
            # åˆ†æä¸­æ–‡è¯­éŸ³çš„ç‰¹å¾é¢‘ç‡åˆ†å¸ƒ
            freq_analysis = self._analyze_frequency_content(audio_data, sample_rate)
            
            # ä¸­æ–‡è¯­éŸ³çš„ç†æƒ³é¢‘ç‡åˆ†å¸ƒ
            ideal_mid_freq = 0.65  # ä¸­é¢‘åº”å ä¸»å¯¼
            ideal_high_freq = 0.25  # é€‚é‡é«˜é¢‘
            ideal_low_freq = 0.1   # å°‘é‡ä½é¢‘
            
            mid_score = 1.0 - abs(freq_analysis.get("mid_freq_ratio", 0.5) - ideal_mid_freq)
            high_score = 1.0 - abs(freq_analysis.get("high_freq_ratio", 0.2) - ideal_high_freq)
            low_score = 1.0 - abs(freq_analysis.get("low_freq_ratio", 0.3) - ideal_low_freq)
            
            # ç»¼åˆè¯„åˆ†
            chinese_score = (mid_score * 0.6 + high_score * 0.3 + low_score * 0.1) * 100
            return max(0, min(100, float(chinese_score)))
            
        except:
            return 75.0  # é»˜è®¤è¯„åˆ†

    def _calculate_comprehensive_score(self, metrics: Dict) -> float:
        """è®¡ç®—ç»¼åˆè´¨é‡è¯„åˆ†"""
        try:
            score = 0
            
            # é‡‡æ ·ç‡è¯„åˆ† (15%)
            if metrics["sample_rate"] >= 16000:
                score += 15
            elif metrics["sample_rate"] >= 8000:
                score += 10
            else:
                score += 5
            
            # RMSç”µå¹³è¯„åˆ† (20%)
            rms = metrics["rms_level"]
            if 0.08 <= rms <= 0.4:
                score += 20
            elif 0.02 <= rms <= 0.6:
                score += 15
            else:
                score += 8
            
            # å™ªå£°æ°´å¹³è¯„åˆ† (25%)
            noise_score = metrics["noise_level"]
            score += min(25, noise_score * 0.25)
            
            # è¯­éŸ³æ¸…æ™°åº¦è¯„åˆ† (25%)
            clarity = metrics["speech_clarity"]
            score += clarity * 25
            
            # ä¸­æ–‡é€‚é…åº¦è¯„åˆ† (15%)
            chinese_score = metrics["chinese_speech_score"]
            score += chinese_score * 0.15
            
            return max(0, min(100, float(score)))
            
        except:
            return 60.0

    def _generate_recommendations(self, metrics: Dict) -> list:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        try:
            if metrics["sample_rate"] < 16000:
                recommendations.append("å»ºè®®æé«˜éŸ³é¢‘é‡‡æ ·ç‡è‡³16kHzä»¥ä¸Š")
            
            if metrics["rms_level"] < 0.02:
                recommendations.append("éŸ³é¢‘éŸ³é‡è¿‡ä½ï¼Œå»ºè®®å¢åŠ å¢ç›Š")
            elif metrics["rms_level"] > 0.6:
                recommendations.append("éŸ³é¢‘éŸ³é‡è¿‡é«˜ï¼Œå¯èƒ½å­˜åœ¨å‰Šæ³¢å¤±çœŸ")
            
            if metrics["noise_level"] < 20:
                recommendations.append("æ£€æµ‹åˆ°è¾ƒé«˜å™ªå£°ï¼Œå»ºè®®è¿›è¡Œé«˜çº§é™å™ªå¤„ç†")
            
            if metrics["speech_clarity"] < 0.6:
                recommendations.append("è¯­éŸ³æ¸…æ™°åº¦è¾ƒä½ï¼Œå»ºè®®ä½¿ç”¨è¯­éŸ³å¢å¼º")
            
            if metrics["chinese_speech_score"] < 70:
                recommendations.append("å»ºè®®å¯ç”¨ä¸­æ–‡è¯­éŸ³ä¼˜åŒ–è®¾ç½®")
            
            freq_analysis = metrics.get("frequency_analysis", {})
            speech_dominance = freq_analysis.get("speech_freq_dominance", 0.5)
            if speech_dominance < 0.5:
                recommendations.append("è¯­éŸ³é¢‘æ®µèƒ½é‡ä¸è¶³ï¼Œå»ºè®®ä½¿ç”¨EQå¢å¼º")
                
        except:
            pass
        
        return recommendations

# ä¿æŒå‘åå…¼å®¹
class AudioPreprocessor(AdvancedAudioPreprocessor):
    """å‘åå…¼å®¹çš„éŸ³é¢‘é¢„å¤„ç†å™¨"""
    
    def process_audio(self, audio_path: str, output_path: Optional[str] = None, quality: str = "balanced") -> str:
        """å‘åå…¼å®¹çš„éŸ³é¢‘å¤„ç†æ–¹æ³•"""
        return self.preprocess_audio(audio_path, output_path, quality)
    
    @staticmethod
    def normalize_audio(audio_path, output_path):
        """æ ‡å‡†åŒ–éŸ³é¢‘éŸ³é‡ - ä¿æŒå‘åå…¼å®¹"""
        preprocessor = AdvancedAudioPreprocessor()
        return preprocessor.preprocess_audio(audio_path, output_path, "fast")
