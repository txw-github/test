
import os
import logging
import numpy as np
import soundfile as sf
from typing import Optional, Tuple, Dict
import tempfile
import subprocess
import json

logger = logging.getLogger(__name__)

class AdvancedAudioPreprocessor:
    """é«˜çº§éŸ³é¢‘é¢„å¤„ç†å™¨ - é’ˆå¯¹ä¸­æ–‡è¯­éŸ³è¯†åˆ«ä¼˜åŒ–"""

    def __init__(self, target_sample_rate: int = 16000, config_path: str = "audio_config.json"):
        self.target_sample_rate = target_sample_rate
        self.config = self._load_config(config_path)
        
    def _load_config(self, config_path: str) -> Dict:
        """åŠ è½½éŸ³é¢‘å¤„ç†é…ç½®"""
        default_config = {
            "noise_reduction": {
                "enable": True,
                "strength": 0.5,
                "method": "spectral_gating"
            },
            "voice_enhancement": {
                "enable": True,
                "vocal_isolation": True,
                "frequency_emphasis": [300, 3400]  # äººå£°é¢‘ç‡èŒƒå›´
            },
            "normalization": {
                "enable": True,
                "target_lufs": -16,
                "peak_limit": -1.5
            },
            "chinese_optimization": {
                "enable": True,
                "tone_preservation": True,
                "consonant_enhancement": True
            }
        }
        
        if os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                    # åˆå¹¶é…ç½®
                    for key in default_config:
                        if key in user_config:
                            default_config[key].update(user_config[key])
                    return default_config
            except Exception as e:
                logger.warning(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        
        return default_config

    def preprocess_audio(self, audio_path: str, output_path: Optional[str] = None) -> str:
        """
        å¤šçº§éŸ³é¢‘é¢„å¤„ç†ä»¥æé«˜ä¸­æ–‡è¯†åˆ«è´¨é‡
        """
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")

        if output_path is None:
            temp_dir = tempfile.gettempdir()
            output_path = os.path.join(temp_dir, "enhanced_audio.wav")

        try:
            logger.info(f"ğŸµ å¼€å§‹é«˜çº§éŸ³é¢‘é¢„å¤„ç†: {audio_path}")

            # é˜¶æ®µ1: åŸºç¡€æ ¼å¼è½¬æ¢å’Œæ ‡å‡†åŒ–
            stage1_path = self._stage1_basic_processing(audio_path)
            
            # é˜¶æ®µ2: é™å™ªå’Œå»æ··å“
            stage2_path = self._stage2_noise_reduction(stage1_path)
            
            # é˜¶æ®µ3: è¯­éŸ³å¢å¼ºå’Œä¸­æ–‡ä¼˜åŒ–
            stage3_path = self._stage3_voice_enhancement(stage2_path)
            
            # é˜¶æ®µ4: æœ€ç»ˆä¼˜åŒ–
            final_path = self._stage4_final_optimization(stage3_path, output_path)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            self._cleanup_temp_files([stage1_path, stage2_path, stage3_path])
            
            logger.info(f"âœ… éŸ³é¢‘é¢„å¤„ç†å®Œæˆ: {output_path}")
            return final_path

        except Exception as e:
            logger.error(f"âŒ éŸ³é¢‘é¢„å¤„ç†å¤±è´¥: {e}")
            return audio_path

    def _stage1_basic_processing(self, audio_path: str) -> str:
        """é˜¶æ®µ1: åŸºç¡€å¤„ç†"""
        temp_path = tempfile.mktemp(suffix="_stage1.wav")
        
        try:
            # åŸºç¡€æ ¼å¼è½¬æ¢ + å“åº¦æ ‡å‡†åŒ–
            cmd = [
                "ffmpeg", "-y", "-i", audio_path,
                "-ar", str(self.target_sample_rate),
                "-ac", "1",  # å•å£°é“
                "-af", f"loudnorm=I={self.config['normalization']['target_lufs']}:TP={self.config['normalization']['peak_limit']}:LRA=11",
                "-acodec", "pcm_s16le",
                "-loglevel", "error",
                temp_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode != 0:
                raise RuntimeError(f"åŸºç¡€å¤„ç†å¤±è´¥: {result.stderr}")
                
            logger.debug("âœ“ é˜¶æ®µ1: åŸºç¡€å¤„ç†å®Œæˆ")
            return temp_path
            
        except Exception as e:
            if os.path.exists(temp_path):
                os.remove(temp_path)
            raise

    def _stage2_noise_reduction(self, audio_path: str) -> str:
        """é˜¶æ®µ2: å¤šçº§é™å™ª"""
        temp_path = tempfile.mktemp(suffix="_stage2.wav")
        
        try:
            if not self.config["noise_reduction"]["enable"]:
                # å¦‚æœç¦ç”¨é™å™ªï¼Œç›´æ¥å¤åˆ¶
                import shutil
                shutil.copy2(audio_path, temp_path)
                return temp_path
            
            # æ„å»ºé™å™ªæ»¤é•œé“¾
            filters = []
            
            # 1. é«˜é€šæ»¤æ³¢å™¨å»é™¤ä½é¢‘å™ªå£°
            filters.append("highpass=f=80")
            
            # 2. ä½é€šæ»¤æ³¢å™¨å»é™¤é«˜é¢‘å™ªå£°
            filters.append("lowpass=f=8000")
            
            # 3. åŠ¨æ€é™å™ª
            filters.append("afftdn=nf=-25:nt=w:om=o:tn=1")
            
            # 4. å»é™¤çˆ†éŸ³å’Œå’”å—’å£°
            filters.append("declick=t=w:l=2")
            
            # 5. å»é™¤å˜¶å˜¶å£°
            filters.append("dehiss=m=o")
            
            filter_chain = ",".join(filters)
            
            cmd = [
                "ffmpeg", "-y", "-i", audio_path,
                "-af", filter_chain,
                "-acodec", "pcm_s16le",
                "-loglevel", "error",
                temp_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode != 0:
                # é™å™ªå¤±è´¥æ—¶ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
                logger.warning("é«˜çº§é™å™ªå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€é™å™ª")
                simple_cmd = [
                    "ffmpeg", "-y", "-i", audio_path,
                    "-af", "highpass=f=80,lowpass=f=8000",
                    "-acodec", "pcm_s16le",
                    "-loglevel", "error",
                    temp_path
                ]
                subprocess.run(simple_cmd, check=True, capture_output=True)
                
            logger.debug("âœ“ é˜¶æ®µ2: é™å™ªå¤„ç†å®Œæˆ")
            return temp_path
            
        except Exception as e:
            if os.path.exists(temp_path):
                os.remove(temp_path)
            raise

    def _stage3_voice_enhancement(self, audio_path: str) -> str:
        """é˜¶æ®µ3: è¯­éŸ³å¢å¼ºå’Œä¸­æ–‡ä¼˜åŒ–"""
        temp_path = tempfile.mktemp(suffix="_stage3.wav")
        
        try:
            if not self.config["voice_enhancement"]["enable"]:
                import shutil
                shutil.copy2(audio_path, temp_path)
                return temp_path
            
            filters = []
            
            # 1. è¯­éŸ³é¢‘æ®µå¢å¼º (300-3400Hzä¸ºäººå£°ä¸»è¦é¢‘æ®µ)
            freq_range = self.config["voice_enhancement"]["frequency_emphasis"]
            filters.append(f"equalizer=f={freq_range[0]}:width_type=h:width=1000:g=3")
            filters.append(f"equalizer=f=1000:width_type=h:width=800:g=2")
            filters.append(f"equalizer=f=2000:width_type=h:width=600:g=2")
            
            # 2. ä¸­æ–‡å£°è°ƒä¼˜åŒ– - ä¿æŠ¤éŸ³è°ƒå˜åŒ–
            if self.config["chinese_optimization"]["tone_preservation"]:
                filters.append("acompressor=threshold=0.5:ratio=2:attack=5:release=50")
            
            # 3. è¾…éŸ³å¢å¼º - æé«˜æ¸…æ™°åº¦
            if self.config["chinese_optimization"]["consonant_enhancement"]:
                filters.append("equalizer=f=4000:width_type=h:width=2000:g=1.5")
            
            # 4. åŠ¨æ€èŒƒå›´å‹ç¼©
            filters.append("compand=attacks=0.3:decays=0.8:points=-80/-80|-45/-30|-27/-20|-12/-8|-6/-6:soft-knee=6")
            
            filter_chain = ",".join(filters)
            
            cmd = [
                "ffmpeg", "-y", "-i", audio_path,
                "-af", filter_chain,
                "-acodec", "pcm_s16le",
                "-loglevel", "error",
                temp_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode != 0:
                raise RuntimeError(f"è¯­éŸ³å¢å¼ºå¤±è´¥: {result.stderr}")
                
            logger.debug("âœ“ é˜¶æ®µ3: è¯­éŸ³å¢å¼ºå®Œæˆ")
            return temp_path
            
        except Exception as e:
            if os.path.exists(temp_path):
                os.remove(temp_path)
            raise

    def _stage4_final_optimization(self, audio_path: str, output_path: str) -> str:
        """é˜¶æ®µ4: æœ€ç»ˆä¼˜åŒ–"""
        try:
            # æœ€ç»ˆå¤„ç†: æ ‡å‡†åŒ–å’Œé™åˆ¶å™¨
            cmd = [
                "ffmpeg", "-y", "-i", audio_path,
                "-af", "alimiter=level_in=1:level_out=0.9:limit=0.95:attack=7:release=100",
                "-acodec", "pcm_s16le",
                "-loglevel", "error",
                output_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode != 0:
                raise RuntimeError(f"æœ€ç»ˆä¼˜åŒ–å¤±è´¥: {result.stderr}")
                
            logger.debug("âœ“ é˜¶æ®µ4: æœ€ç»ˆä¼˜åŒ–å®Œæˆ")
            return output_path
            
        except Exception as e:
            # å¦‚æœæœ€ç»ˆä¼˜åŒ–å¤±è´¥ï¼Œç›´æ¥å¤åˆ¶
            import shutil
            shutil.copy2(audio_path, output_path)
            return output_path

    def _cleanup_temp_files(self, temp_files: list):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        for temp_file in temp_files:
            try:
                if os.path.exists(temp_file):
                    os.remove(temp_file)
            except:
                pass

    def analyze_audio_quality(self, audio_path: str) -> Dict:
        """è¯¦ç»†çš„éŸ³é¢‘è´¨é‡åˆ†æ"""
        try:
            audio_data, sample_rate = sf.read(audio_path)
            
            if len(audio_data.shape) > 1:
                audio_data = np.mean(audio_data, axis=1)

            # è®¡ç®—å„ç§è´¨é‡æŒ‡æ ‡
            metrics = {
                "duration": len(audio_data) / sample_rate,
                "sample_rate": sample_rate,
                "rms_level": float(np.sqrt(np.mean(audio_data**2))),
                "peak_level": float(np.max(np.abs(audio_data))),
                "dynamic_range": self._calculate_dynamic_range(audio_data),
                "frequency_analysis": self._analyze_frequency_content(audio_data, sample_rate),
                "speech_clarity": self._estimate_speech_clarity(audio_data, sample_rate),
                "noise_level": self._estimate_noise_level(audio_data),
                "chinese_speech_score": self._chinese_speech_analysis(audio_data, sample_rate)
            }

            # ç»¼åˆè´¨é‡è¯„åˆ†
            quality_score = self._calculate_comprehensive_score(metrics)
            metrics["overall_score"] = quality_score
            metrics["recommendations"] = self._generate_recommendations(metrics)

            logger.info(f"ğŸ“Š éŸ³é¢‘è´¨é‡åˆ†æ - æ—¶é•¿: {metrics['duration']:.1f}s, "
                       f"ç»¼åˆè¯„åˆ†: {quality_score:.1f}, "
                       f"ä¸­æ–‡é€‚é…åº¦: {metrics['chinese_speech_score']:.1f}")

            return metrics

        except Exception as e:
            logger.error(f"éŸ³é¢‘è´¨é‡åˆ†æå¤±è´¥: {e}")
            return {}

    def _calculate_dynamic_range(self, audio_data: np.ndarray) -> float:
        """è®¡ç®—åŠ¨æ€èŒƒå›´"""
        try:
            rms_values = []
            frame_size = int(0.1 * self.target_sample_rate)  # 100mså¸§
            
            for i in range(0, len(audio_data) - frame_size, frame_size):
                frame = audio_data[i:i + frame_size]
                rms = np.sqrt(np.mean(frame**2))
                if rms > 0:
                    rms_values.append(20 * np.log10(rms))
            
            if len(rms_values) > 1:
                return float(np.max(rms_values) - np.min(rms_values))
            return 0.0
        except:
            return 0.0

    def _analyze_frequency_content(self, audio_data: np.ndarray, sample_rate: int) -> Dict:
        """é¢‘ç‡å†…å®¹åˆ†æ"""
        try:
            from scipy import signal
            
            # è®¡ç®—åŠŸç‡è°±å¯†åº¦
            frequencies, psd = signal.welch(audio_data, sample_rate, nperseg=1024)
            
            # åˆ†æä¸åŒé¢‘æ®µçš„èƒ½é‡
            low_freq = np.sum(psd[(frequencies >= 80) & (frequencies <= 300)])
            mid_freq = np.sum(psd[(frequencies >= 300) & (frequencies <= 3400)])
            high_freq = np.sum(psd[(frequencies >= 3400) & (frequencies <= 8000)])
            
            total_energy = low_freq + mid_freq + high_freq
            
            if total_energy > 0:
                return {
                    "low_freq_ratio": float(low_freq / total_energy),
                    "mid_freq_ratio": float(mid_freq / total_energy),
                    "high_freq_ratio": float(high_freq / total_energy),
                    "speech_freq_dominance": float(mid_freq / total_energy)
                }
            else:
                return {"low_freq_ratio": 0, "mid_freq_ratio": 0, "high_freq_ratio": 0, "speech_freq_dominance": 0}
                
        except ImportError:
            logger.debug("scipyæœªå®‰è£…ï¼Œè·³è¿‡é¢‘ç‡åˆ†æ")
            return {"speech_freq_dominance": 0.5}  # é»˜è®¤å€¼
        except:
            return {"speech_freq_dominance": 0.5}

    def _estimate_speech_clarity(self, audio_data: np.ndarray, sample_rate: int) -> float:
        """ä¼°ç®—è¯­éŸ³æ¸…æ™°åº¦"""
        try:
            # è®¡ç®—è¯­éŸ³æ´»åŠ¨æ£€æµ‹
            frame_length = int(0.025 * sample_rate)  # 25ms
            hop_length = int(0.01 * sample_rate)     # 10ms
            
            speech_frames = 0
            total_frames = 0
            
            for i in range(0, len(audio_data) - frame_length, hop_length):
                frame = audio_data[i:i + frame_length]
                energy = np.sum(frame**2)
                zcr = np.sum(np.abs(np.diff(np.sign(frame))))
                
                # ç®€å•çš„VAD
                if energy > 0.001 and 20 < zcr < 120:
                    speech_frames += 1
                total_frames += 1
            
            if total_frames > 0:
                return float(speech_frames / total_frames)
            return 0.0
        except:
            return 0.5

    def _estimate_noise_level(self, audio_data: np.ndarray) -> float:
        """ä¼°ç®—å™ªå£°æ°´å¹³"""
        try:
            # ä½¿ç”¨å‰å1ç§’ä½œä¸ºé™éŸ³å‚è€ƒ
            silence_samples = int(1.0 * self.target_sample_rate)
            
            if len(audio_data) > 2 * silence_samples:
                start_silence = audio_data[:silence_samples]
                end_silence = audio_data[-silence_samples:]
                silence_rms = np.sqrt(np.mean(np.concatenate([start_silence, end_silence])**2))
                
                overall_rms = np.sqrt(np.mean(audio_data**2))
                
                if overall_rms > 0:
                    snr = 20 * np.log10(overall_rms / (silence_rms + 1e-10))
                    return max(0, min(100, float(snr)))
            
            return 20.0  # é»˜è®¤SNR
        except:
            return 20.0

    def _chinese_speech_analysis(self, audio_data: np.ndarray, sample_rate: int) -> float:
        """ä¸­æ–‡è¯­éŸ³ç‰¹å¾åˆ†æ"""
        try:
            # åˆ†æä¸­æ–‡è¯­éŸ³çš„ç‰¹å¾é¢‘ç‡åˆ†å¸ƒ
            freq_analysis = self._analyze_frequency_content(audio_data, sample_rate)
            
            # ä¸­æ–‡è¯­éŸ³çš„ç†æƒ³é¢‘ç‡åˆ†å¸ƒ
            ideal_mid_freq = 0.7  # ä¸­é¢‘åº”å ä¸»å¯¼
            ideal_high_freq = 0.2  # é€‚é‡é«˜é¢‘
            ideal_low_freq = 0.1   # å°‘é‡ä½é¢‘
            
            mid_score = 1.0 - abs(freq_analysis.get("mid_freq_ratio", 0.5) - ideal_mid_freq)
            high_score = 1.0 - abs(freq_analysis.get("high_freq_ratio", 0.2) - ideal_high_freq)
            low_score = 1.0 - abs(freq_analysis.get("low_freq_ratio", 0.3) - ideal_low_freq)
            
            # ç»¼åˆè¯„åˆ†
            chinese_score = (mid_score * 0.6 + high_score * 0.3 + low_score * 0.1) * 100
            return max(0, min(100, float(chinese_score)))
            
        except:
            return 70.0  # é»˜è®¤è¯„åˆ†

    def _calculate_comprehensive_score(self, metrics: Dict) -> float:
        """è®¡ç®—ç»¼åˆè´¨é‡è¯„åˆ†"""
        try:
            score = 0
            
            # é‡‡æ ·ç‡è¯„åˆ† (15%)
            if metrics["sample_rate"] >= 16000:
                score += 15
            elif metrics["sample_rate"] >= 8000:
                score += 10
            else:
                score += 5
            
            # RMSç”µå¹³è¯„åˆ† (20%)
            rms = metrics["rms_level"]
            if 0.05 <= rms <= 0.3:
                score += 20
            elif 0.01 <= rms <= 0.5:
                score += 15
            else:
                score += 8
            
            # å™ªå£°æ°´å¹³è¯„åˆ† (25%)
            noise_score = metrics["noise_level"]
            score += noise_score * 0.25
            
            # è¯­éŸ³æ¸…æ™°åº¦è¯„åˆ† (25%)
            clarity = metrics["speech_clarity"]
            score += clarity * 25
            
            # ä¸­æ–‡é€‚é…åº¦è¯„åˆ† (15%)
            chinese_score = metrics["chinese_speech_score"]
            score += chinese_score * 0.15
            
            return max(0, min(100, float(score)))
            
        except:
            return 50.0

    def _generate_recommendations(self, metrics: Dict) -> list:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        try:
            if metrics["sample_rate"] < 16000:
                recommendations.append("å»ºè®®æé«˜éŸ³é¢‘é‡‡æ ·ç‡è‡³16kHzä»¥ä¸Š")
            
            if metrics["rms_level"] < 0.01:
                recommendations.append("éŸ³é¢‘éŸ³é‡è¿‡ä½ï¼Œå»ºè®®å¢åŠ å¢ç›Š")
            elif metrics["rms_level"] > 0.5:
                recommendations.append("éŸ³é¢‘éŸ³é‡è¿‡é«˜ï¼Œå¯èƒ½å­˜åœ¨å‰Šæ³¢å¤±çœŸ")
            
            if metrics["noise_level"] < 15:
                recommendations.append("æ£€æµ‹åˆ°è¾ƒé«˜å™ªå£°ï¼Œå»ºè®®è¿›è¡Œé™å™ªå¤„ç†")
            
            if metrics["speech_clarity"] < 0.5:
                recommendations.append("è¯­éŸ³æ¸…æ™°åº¦è¾ƒä½ï¼Œå»ºè®®ä½¿ç”¨è¯­éŸ³å¢å¼º")
            
            if metrics["chinese_speech_score"] < 60:
                recommendations.append("å»ºè®®å¯ç”¨ä¸­æ–‡è¯­éŸ³ä¼˜åŒ–è®¾ç½®")
            
            freq_analysis = metrics.get("frequency_analysis", {})
            speech_dominance = freq_analysis.get("speech_freq_dominance", 0.5)
            if speech_dominance < 0.4:
                recommendations.append("è¯­éŸ³é¢‘æ®µèƒ½é‡ä¸è¶³ï¼Œå»ºè®®ä½¿ç”¨EQå¢å¼º")
                
        except:
            pass
        
        return recommendations

# ä¿æŒå‘åå…¼å®¹
class AudioPreprocessor(AdvancedAudioPreprocessor):
    """å‘åå…¼å®¹çš„éŸ³é¢‘é¢„å¤„ç†å™¨"""
    pass
