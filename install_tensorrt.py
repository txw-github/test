
#!/usr/bin/env python3
"""
TensorRTå®‰è£…å’Œä¼˜åŒ–è„šæœ¬
é€‚ç”¨äºRTX 3060 Ti 6GBæ˜¾å¡
"""

import os
import sys
import subprocess
import platform

def install_tensorrt():
    """å®‰è£…TensorRTç›¸å…³ä¾èµ–"""
    print("æ­£åœ¨å®‰è£…TensorRTå’Œç›¸å…³ä¼˜åŒ–åº“...")
    
    packages = [
        "onnx>=1.14.0",
        "onnxruntime-gpu>=1.16.0", 
        "onnxsim>=0.4.0",
        "polygraphy",
        "pycuda>=2022.1"
    ]
    
    for package in packages:
        try:
            print(f"å®‰è£… {package}...")
            subprocess.run([sys.executable, "-m", "pip", "install", package], 
                          check=True, capture_output=True)
            print(f"âœ… {package} å®‰è£…æˆåŠŸ")
        except subprocess.CalledProcessError as e:
            print(f"âŒ {package} å®‰è£…å¤±è´¥: {e}")
    
    print("\nğŸ“ TensorRTå®‰è£…è¯´æ˜:")
    print("1. TensorRTéœ€è¦NVIDIAå¼€å‘è€…è´¦å·ä¸‹è½½")
    print("2. è®¿é—®: https://developer.nvidia.com/tensorrt")
    print("3. ä¸‹è½½é€‚åˆCUDA 12.1çš„TensorRTç‰ˆæœ¬")
    print("4. è§£å‹åå°†åº“æ–‡ä»¶æ·»åŠ åˆ°ç³»ç»ŸPATH")
    print("\nğŸ’¡ æˆ–è€…å¯ä»¥ä½¿ç”¨ONNX Runtime GPUç‰ˆæœ¬ä½œä¸ºæ›¿ä»£æ–¹æ¡ˆ")

def optimize_system():
    """ç³»ç»Ÿä¼˜åŒ–è®¾ç½®"""
    print("åº”ç”¨RTX 3060 Tiä¼˜åŒ–è®¾ç½®...")
    
    # Windowsç‰¹å®šä¼˜åŒ–
    if platform.system() == "Windows":
        optimizations = [
            "set CUDA_CACHE_DISABLE=0",
            "set PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128,expandable_segments:True",
            "set CUDA_LAUNCH_BLOCKING=0",
            "set TORCH_CUDNN_V8_API_ENABLED=1"
        ]
        
        for opt in optimizations:
            print(f"è®¾ç½®: {opt}")
            os.system(opt)
    
    print("âœ… ç³»ç»Ÿä¼˜åŒ–å®Œæˆ")

if __name__ == "__main__":
    install_tensorrt()
    optimize_system()
    print("\nğŸ‰ å®‰è£…å®Œæˆï¼é‡å¯ç¨‹åºä»¥å¯ç”¨TensorRTåŠ é€Ÿ")
