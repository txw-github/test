
#!/usr/bin/env python3
"""
TensorRTå¼•æ“ç®¡ç†å·¥å…·
ç”¨äºç®¡ç†å’Œä¼˜åŒ–TensorRTå¼•æ“æ–‡ä»¶
"""

import os
import json
import time
import logging
from typing import Dict, List, Optional

logger = logging.getLogger(__name__)

# é¿å…å¾ªç¯å¯¼å…¥ï¼Œç›´æ¥åœ¨è¿™é‡Œå®šä¹‰æ‰€éœ€çš„ç±»
class Config:
    """é…ç½®ç®¡ç†ç±» - ç®€åŒ–ç‰ˆæœ¬"""
    def __init__(self):
        self.config_file = "config.json"
        self.load_config()

    def load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        default_config = {
            "models_path": "./models",
            "temp_path": "./temp",
            "output_path": "./output",
            "gpu_memory_fraction": 0.85,
            "batch_size": 4,
            "max_segment_length": 30,
            "preferred_model": "faster-base",
            "use_tensorrt": True,
            "audio_sample_rate": 16000
        }

        if os.path.exists(self.config_file):
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    for key, value in default_config.items():
                        if key not in config:
                            config[key] = value
                    self.config = config
            except Exception as e:
                logger.warning(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
                self.config = default_config
        else:
            self.config = default_config

    def get(self, key, default=None):
        return self.config.get(key, default)

# TensorRTä¼˜åŒ–å™¨ç±» - ç®€åŒ–ç‰ˆæœ¬
class TensorRTOptimizer:
    """TensorRTä¼˜åŒ–å™¨ - ç®€åŒ–ç‰ˆæœ¬"""
    
    @staticmethod
    def convert_to_tensorrt(onnx_path: str, engine_path: str, precision: str = "fp16") -> bool:
        """å°†ONNXæ¨¡å‹è½¬æ¢ä¸ºTensorRTå¼•æ“"""
        try:
            # å°è¯•å¯¼å…¥TensorRT
            try:
                import tensorrt as trt
                import pycuda.driver as cuda
                import pycuda.autoinit
            except ImportError:
                logger.warning("TensorRTä¸å¯ç”¨ï¼Œè·³è¿‡ä¼˜åŒ–")
                return False

            if not os.path.exists(onnx_path):
                logger.error(f"ONNXæ–‡ä»¶ä¸å­˜åœ¨: {onnx_path}")
                return False

            logger.info(f"å¼€å§‹è½¬æ¢TensorRTå¼•æ“: {onnx_path} -> {engine_path}")

            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(engine_path), exist_ok=True)

            # åˆ›å»ºTensorRT logger
            trt_logger = trt.Logger(trt.Logger.WARNING)

            # åˆ›å»ºbuilderå’Œnetwork
            builder = trt.Builder(trt_logger)
            config = builder.create_builder_config()

            # RTX 3060 Tiä¼˜åŒ–è®¾ç½®
            config.max_workspace_size = 1 << 30  # 1GB
            config.set_flag(trt.BuilderFlag.SPARSE_WEIGHTS)

            # å¯ç”¨ç²¾åº¦ä¼˜åŒ–
            if precision == "fp16" and builder.platform_has_fast_fp16:
                config.set_flag(trt.BuilderFlag.FP16)
                logger.info("å¯ç”¨FP16ç²¾åº¦ä¼˜åŒ–")
            elif precision == "int8" and builder.platform_has_fast_int8:
                config.set_flag(trt.BuilderFlag.INT8)
                logger.info("å¯ç”¨INT8ç²¾åº¦ä¼˜åŒ–")

            # åˆ›å»ºç½‘ç»œ
            network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))

            # è§£æONNXæ–‡ä»¶
            parser = trt.OnnxParser(network, trt_logger)

            logger.info("è§£æONNXæ¨¡å‹...")
            with open(onnx_path, 'rb') as model:
                model_data = model.read()
                if not model_data:
                    logger.error("ONNXæ–‡ä»¶ä¸ºç©º")
                    return False

                if not parser.parse(model_data):
                    logger.error("ONNXè§£æå¤±è´¥")
                    return False

            logger.info("å¼€å§‹æ„å»ºå¼•æ“...")
            serialized_engine = builder.build_serialized_network(network, config)
            if serialized_engine is None:
                logger.error("TensorRTå¼•æ“æ„å»ºå¤±è´¥")
                return False

            # ä¿å­˜å¼•æ“
            with open(engine_path, 'wb') as f:
                f.write(serialized_engine)

            if os.path.exists(engine_path):
                file_size = os.path.getsize(engine_path)
                logger.info(f"TensorRTå¼•æ“æ„å»ºæˆåŠŸ: {engine_path} ({file_size/1024/1024:.1f}MB)")
                return True
            else:
                logger.error("å¼•æ“æ–‡ä»¶ä¿å­˜å¤±è´¥")
                return False

        except Exception as e:
            logger.error(f"TensorRTè½¬æ¢å¤±è´¥: {e}")
            return False

    @staticmethod
    def create_fallback_engine(engine_path: str, model_info: Dict) -> bool:
        """åˆ›å»ºåå¤‡å¼•æ“å‚æ•°æ–‡ä»¶"""
        try:
            logger.info("åˆ›å»ºTensorRTåå¤‡å‚æ•°æ–‡ä»¶...")

            fallback_config = {
                "engine_info": {
                    "precision": "fp16",
                    "max_batch_size": 1,
                    "max_workspace_size": 1073741824,
                    "input_shapes": {
                        "audio_input": [-1, 80, -1]
                    },
                    "output_shapes": {
                        "text_output": [-1, -1]
                    }
                },
                "optimization_flags": [
                    "FP16", "SPARSE_WEIGHTS"
                ],
                "created_time": time.time(),
                "rtx_3060ti_optimized": True
            }

            config_path = engine_path.replace('.trt', '_config.json')
            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(fallback_config, f, indent=2, ensure_ascii=False)

            logger.info(f"åå¤‡é…ç½®æ–‡ä»¶åˆ›å»ºæˆåŠŸ: {config_path}")
            return True

        except Exception as e:
            logger.error(f"åå¤‡å‚æ•°æ–‡ä»¶åˆ›å»ºå¤±è´¥: {e}")
            return False

    @staticmethod
    def load_tensorrt_engine(engine_path: str):
        """åŠ è½½TensorRTå¼•æ“"""
        try:
            import tensorrt as trt
            
            if not os.path.exists(engine_path):
                logger.error(f"TensorRTå¼•æ“æ–‡ä»¶ä¸å­˜åœ¨: {engine_path}")
                return None

            trt_logger = trt.Logger(trt.Logger.WARNING)
            runtime = trt.Runtime(trt_logger)

            with open(engine_path, 'rb') as f:
                engine = runtime.deserialize_cuda_engine(f.read())

            if engine is None:
                logger.error("TensorRTå¼•æ“åŠ è½½å¤±è´¥")
                return None

            logger.info(f"TensorRTå¼•æ“åŠ è½½æˆåŠŸ: {engine_path}")
            return engine

        except Exception as e:
            logger.error(f"TensorRTå¼•æ“åŠ è½½é”™è¯¯: {e}")
            return None

class TensorRTEngineManager:
    """TensorRTå¼•æ“ç®¡ç†å™¨"""
    
    def __init__(self, config: Config = None):
        self.config = config or Config()
        self.models_path = self.config.get('models_path', './models')
        self.engines_path = os.path.join(self.models_path, 'tensorrt_engines')
        os.makedirs(self.engines_path, exist_ok=True)
        
    def list_available_engines(self) -> List[Dict]:
        """åˆ—å‡ºå¯ç”¨çš„TensorRTå¼•æ“"""
        engines = []
        
        for file in os.listdir(self.engines_path):
            if file.endswith('.trt'):
                engine_path = os.path.join(self.engines_path, file)
                config_path = engine_path.replace('.trt', '_config.json')
                
                engine_info = {
                    "name": file.replace('.trt', ''),
                    "path": engine_path,
                    "size_mb": os.path.getsize(engine_path) / 1024 / 1024,
                    "created_time": os.path.getctime(engine_path),
                    "valid": self._validate_engine(engine_path)
                }
                
                # åŠ è½½é…ç½®ä¿¡æ¯
                if os.path.exists(config_path):
                    try:
                        with open(config_path, 'r', encoding='utf-8') as f:
                            config_data = json.load(f)
                            engine_info.update(config_data.get('engine_info', {}))
                    except Exception as e:
                        logger.warning(f"é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥ {config_path}: {e}")
                
                engines.append(engine_info)
                
        return sorted(engines, key=lambda x: x['created_time'], reverse=True)
    
    def _validate_engine(self, engine_path: str) -> bool:
        """éªŒè¯å¼•æ“æ–‡ä»¶"""
        try:
            if not os.path.exists(engine_path):
                return False
            
            # åŸºæœ¬æ–‡ä»¶æ£€æŸ¥
            if os.path.getsize(engine_path) < 1024:
                return False
                
            # å°è¯•åŠ è½½å¼•æ“
            engine = TensorRTOptimizer.load_tensorrt_engine(engine_path)
            return engine is not None
            
        except Exception:
            return False
    
    def rebuild_engine(self, model_name: str, precision: str = "fp16") -> bool:
        """é‡å»ºTensorRTå¼•æ“"""
        try:
            logger.info(f"é‡å»ºTensorRTå¼•æ“: {model_name}")
            
            # æŸ¥æ‰¾ONNXæ–‡ä»¶ï¼Œæ”¯æŒå¤šç§å¯èƒ½çš„ä½ç½®
            possible_onnx_paths = [
                os.path.join(self.models_path, model_name.replace("/", "_") + ".onnx"),
                os.path.join(self.models_path, model_name + ".onnx"),
                os.path.join(self.models_path, "hub", model_name.replace("/", "_") + ".onnx"),
                os.path.join(self.models_path, "hub", model_name, "model.onnx")
            ]
            
            onnx_path = None
            for path in possible_onnx_paths:
                if os.path.exists(path):
                    onnx_path = path
                    break
            
            if not onnx_path:
                logger.warning(f"æœªæ‰¾åˆ°ONNXæ–‡ä»¶ï¼Œå°è¯•çš„è·¯å¾„: {possible_onnx_paths}")
                logger.info("å°†åˆ›å»ºåå¤‡å¼•æ“é…ç½®æ–‡ä»¶...")
                engine_path = os.path.join(self.engines_path, model_name.replace("/", "_") + ".trt")
                return TensorRTOptimizer.create_fallback_engine(engine_path, {"model": model_name})
            
            engine_path = os.path.join(self.engines_path, model_name.replace("/", "_") + ".trt")
            
            # åˆ é™¤æ—§å¼•æ“
            if os.path.exists(engine_path):
                os.remove(engine_path)
                logger.info("åˆ é™¤æ—§å¼•æ“æ–‡ä»¶")
            
            # åˆ›å»ºæ–°å¼•æ“
            success = TensorRTOptimizer.convert_to_tensorrt(onnx_path, engine_path, precision)
            
            if success:
                logger.info(f"å¼•æ“é‡å»ºæˆåŠŸ: {engine_path}")
                return True
            else:
                logger.error("å¼•æ“é‡å»ºå¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"å¼•æ“é‡å»ºå¼‚å¸¸: {e}")
            return False
    
    def clean_invalid_engines(self) -> int:
        """æ¸…ç†æ— æ•ˆçš„å¼•æ“æ–‡ä»¶"""
        cleaned = 0
        
        for file in os.listdir(self.engines_path):
            if file.endswith('.trt'):
                engine_path = os.path.join(self.engines_path, file)
                
                if not self._validate_engine(engine_path):
                    try:
                        os.remove(engine_path)
                        # åŒæ—¶åˆ é™¤é…ç½®æ–‡ä»¶
                        config_path = engine_path.replace('.trt', '_config.json')
                        if os.path.exists(config_path):
                            os.remove(config_path)
                        
                        logger.info(f"åˆ é™¤æ— æ•ˆå¼•æ“: {file}")
                        cleaned += 1
                        
                    except Exception as e:
                        logger.warning(f"åˆ é™¤å¼•æ“å¤±è´¥ {file}: {e}")
        
        return cleaned
    
    def get_engine_info(self, model_name: str) -> Optional[Dict]:
        """è·å–å¼•æ“ä¿¡æ¯"""
        engines = self.list_available_engines()
        
        for engine in engines:
            if engine['name'] == model_name.replace("/", "_"):
                return engine
        
        return None
    
    def optimize_for_rtx3060ti(self, model_name: str) -> bool:
        """ä¸ºRTX 3060 Tiä¼˜åŒ–å¼•æ“"""
        try:
            logger.info(f"ä¸ºRTX 3060 Tiä¼˜åŒ–å¼•æ“: {model_name}")
            
            # ä½¿ç”¨FP16ç²¾åº¦å’Œä¼˜åŒ–è®¾ç½®é‡å»ºå¼•æ“
            return self.rebuild_engine(model_name, precision="fp16")
            
        except Exception as e:
            logger.error(f"RTX 3060 Tiä¼˜åŒ–å¤±è´¥: {e}")
            return False
    
    def auto_optimize(self, model_name: str) -> bool:
        """è‡ªåŠ¨ä¼˜åŒ–æ¨¡å‹"""
        try:
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰å¼•æ“
            engine_info = self.get_engine_info(model_name.replace("/", "_"))
            if engine_info and engine_info.get('valid', False):
                logger.info(f"æ¨¡å‹ {model_name} å·²æœ‰æœ‰æ•ˆçš„TensorRTå¼•æ“")
                return True
            
            # å°è¯•ä¼˜åŒ–
            logger.info(f"å¼€å§‹ä¸ºæ¨¡å‹ {model_name} åˆ›å»ºTensorRTå¼•æ“...")
            return self.optimize_for_rtx3060ti(model_name)
            
        except Exception as e:
            logger.warning(f"è‡ªåŠ¨ä¼˜åŒ–å¤±è´¥: {e}")
            return False

def main():
    """å‘½ä»¤è¡Œå·¥å…·ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="TensorRTå¼•æ“ç®¡ç†å·¥å…·")
    parser.add_argument("--list", action="store_true", help="åˆ—å‡ºæ‰€æœ‰å¼•æ“")
    parser.add_argument("--rebuild", help="é‡å»ºæŒ‡å®šæ¨¡å‹çš„å¼•æ“")
    parser.add_argument("--clean", action="store_true", help="æ¸…ç†æ— æ•ˆå¼•æ“")
    parser.add_argument("--optimize", help="ä¸ºRTX 3060 Tiä¼˜åŒ–æŒ‡å®šæ¨¡å‹")
    parser.add_argument("--precision", default="fp16", choices=["fp16", "int8"], help="ç²¾åº¦è®¾ç½®")
    
    args = parser.parse_args()
    
    manager = TensorRTEngineManager()
    
    if args.list:
        engines = manager.list_available_engines()
        print("\n=== TensorRTå¼•æ“åˆ—è¡¨ ===")
        if not engines:
            print("æœªæ‰¾åˆ°ä»»ä½•å¼•æ“æ–‡ä»¶")
        else:
            for engine in engines:
                status = "âœ…" if engine['valid'] else "âŒ"
                print(f"{status} {engine['name']}")
                print(f"   æ–‡ä»¶å¤§å°: {engine['size_mb']:.1f}MB")
                print(f"   åˆ›å»ºæ—¶é—´: {time.ctime(engine['created_time'])}")
                print()
    
    elif args.rebuild:
        success = manager.rebuild_engine(args.rebuild, args.precision)
        if success:
            print(f"âœ… å¼•æ“é‡å»ºæˆåŠŸ: {args.rebuild}")
        else:
            print(f"âŒ å¼•æ“é‡å»ºå¤±è´¥: {args.rebuild}")
    
    elif args.clean:
        cleaned = manager.clean_invalid_engines()
        print(f"ğŸ§¹ æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {cleaned} ä¸ªæ— æ•ˆå¼•æ“")
    
    elif args.optimize:
        success = manager.optimize_for_rtx3060ti(args.optimize)
        if success:
            print(f"ğŸš€ RTX 3060 Tiä¼˜åŒ–å®Œæˆ: {args.optimize}")
        else:
            print(f"âŒ ä¼˜åŒ–å¤±è´¥: {args.optimize}")
    
    else:
        parser.print_help()

if __name__ == "__main__":
    main()
