
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
RTX 3060 Ti ç¯å¢ƒæµ‹è¯•è„šæœ¬ - å¢å¼ºç‰ˆ
"""

import sys
import os
import subprocess

def test_python():
    """æµ‹è¯•Pythonç‰ˆæœ¬"""
    print("ğŸ” æ£€æŸ¥Pythonç‰ˆæœ¬...")
    version = sys.version_info
    print(f"   Pythonç‰ˆæœ¬: {version.major}.{version.minor}.{version.micro}")

    if 3.8 <= version.minor <= 3.11 and version.major == 3:
        print("   âœ… Pythonç‰ˆæœ¬å…¼å®¹")
        return True
    else:
        print("   âŒ å»ºè®®ä½¿ç”¨Python 3.8-3.11")
        return False

def test_torch():
    """æµ‹è¯•PyTorchå’ŒCUDA"""
    print("\nğŸ” æ£€æŸ¥PyTorch...")
    try:
        import torch
        print(f"   PyTorchç‰ˆæœ¬: {torch.__version__}")

        if torch.cuda.is_available():
            print("   âœ… CUDAå¯ç”¨")
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            print(f"   GPU: {gpu_name}")
            print(f"   æ˜¾å­˜: {gpu_memory:.1f}GB")

            if "3060 Ti" in gpu_name:
                print("   ğŸ¯ RTX 3060 Tiæ£€æµ‹æˆåŠŸï¼")
                return True
            elif "NVIDIA" in gpu_name:
                print("   âœ… NVIDIA GPUæ£€æµ‹æˆåŠŸ")
                return True
            else:
                print("   âš ï¸  æ£€æµ‹åˆ°GPUä½†ä¸æ˜¯NVIDIA")
                return True
        else:
            print("   âš ï¸  CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
            return True

    except ImportError:
        print("   âŒ PyTorchæœªå®‰è£…")
        return False

def test_whisper():
    """æµ‹è¯•Whisperæ¨¡å‹"""
    print("\nğŸ” æ£€æŸ¥Whisper...")
    faster_available = False
    whisper_available = False
    
    try:
        from faster_whisper import WhisperModel
        print("   âœ… Faster-Whisperå¯ç”¨")
        faster_available = True
    except ImportError:
        print("   âŒ Faster-Whisperæœªå®‰è£…")
    
    try:
        import whisper
        print("   âœ… OpenAI Whisperå¯ç”¨")
        whisper_available = True
    except ImportError:
        print("   âŒ OpenAI Whisperæœªå®‰è£…")
    
    return faster_available or whisper_available

def test_video():
    """æµ‹è¯•è§†é¢‘å¤„ç†"""
    print("\nğŸ” æ£€æŸ¥è§†é¢‘å¤„ç†...")
    try:
        import moviepy
        print("   âœ… MoviePyå¯ç”¨")
        
        # æµ‹è¯•FFmpeg
        try:
            result = subprocess.run(['ffmpeg', '-version'], 
                                  capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                print("   âœ… FFmpegå¯ç”¨")
            else:
                print("   âš ï¸  FFmpegä¸å¯ç”¨ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½å—é™")
        except (subprocess.TimeoutExpired, FileNotFoundError):
            print("   âš ï¸  FFmpegä¸å¯ç”¨ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½å—é™")
        
        return True
    except ImportError:
        print("   âŒ MoviePyæœªå®‰è£…")
        return False

def test_audio():
    """æµ‹è¯•éŸ³é¢‘å¤„ç†"""
    print("\nğŸ” æ£€æŸ¥éŸ³é¢‘å¤„ç†...")
    try:
        import librosa
        import soundfile
        import scipy
        print("   âœ… é«˜çº§éŸ³é¢‘å¤„ç†åº“å¯ç”¨")
        return True
    except ImportError:
        print("   âš ï¸  é«˜çº§éŸ³é¢‘å¤„ç†åº“æœªå®Œå…¨å®‰è£…")
        return False

def test_chinese():
    """æµ‹è¯•ä¸­æ–‡å¤„ç†"""
    print("\nğŸ” æ£€æŸ¥ä¸­æ–‡å¤„ç†...")
    try:
        import jieba
        import jieba.posseg
        print("   âœ… Jiebaåˆ†è¯å¯ç”¨")
        
        # æµ‹è¯•åŸºæœ¬åˆ†è¯
        test_text = "è¿™æ˜¯ä¸€ä¸ªä¸­æ–‡æµ‹è¯•å¥å­"
        words = list(jieba.cut(test_text))
        print(f"   æµ‹è¯•åˆ†è¯: {' / '.join(words)}")
        
        return True
    except ImportError:
        print("   âŒ Jiebaæœªå®‰è£…ï¼Œä¸­æ–‡ä¼˜åŒ–åŠŸèƒ½ä¸å¯ç”¨")
        return False

def test_tensorrt():
    """æµ‹è¯•TensorRT"""
    print("\nğŸ” æ£€æŸ¥TensorRT...")
    try:
        import tensorrt as trt
        import pycuda.driver as cuda
        print(f"   âœ… TensorRTå¯ç”¨ (ç‰ˆæœ¬: {trt.__version__})")
        return True
    except ImportError:
        print("   âš ï¸  TensorRTæœªå®‰è£… (å¯é€‰åŠŸèƒ½)")
        return False

def test_model_download():
    """æµ‹è¯•æ¨¡å‹ä¸‹è½½èƒ½åŠ›"""
    print("\nğŸ” æ£€æŸ¥æ¨¡å‹ä¸‹è½½...")
    try:
        from huggingface_hub import HfApi
        api = HfApi()
        print("   âœ… Hugging Face Hubå¯ç”¨")
        return True
    except ImportError:
        print("   âš ï¸  Hugging Face Hubæœªå®‰è£…")
        return False

def run_performance_test():
    """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
    print("\nğŸ” è¿è¡Œæ€§èƒ½æµ‹è¯•...")
    try:
        import torch
        if torch.cuda.is_available():
            # ç®€å•çš„GPUæ€§èƒ½æµ‹è¯•
            device = torch.device('cuda')
            x = torch.randn(1000, 1000, device=device)
            y = torch.randn(1000, 1000, device=device)
            
            import time
            start_time = time.time()
            for _ in range(100):
                z = torch.mm(x, y)
            torch.cuda.synchronize()
            end_time = time.time()
            
            gpu_time = (end_time - start_time) * 10  # ms per operation
            print(f"   GPUæ€§èƒ½: {gpu_time:.2f}ms/æ“ä½œ")
            
            if gpu_time < 50:
                print("   âœ… GPUæ€§èƒ½ä¼˜ç§€")
                return True
            elif gpu_time < 100:
                print("   âš ï¸  GPUæ€§èƒ½ä¸€èˆ¬")
                return True
            else:
                print("   âŒ GPUæ€§èƒ½è¾ƒå·®")
                return False
        else:
            print("   âš ï¸  æ— GPUï¼Œè·³è¿‡æ€§èƒ½æµ‹è¯•")
            return True
    except Exception as e:
        print(f"   âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 50)
    print("RTX 3060 Ti è§†é¢‘è½¬å­—å¹•å·¥å…· - ç¯å¢ƒæµ‹è¯•")
    print("=" * 50)

    results = []
    results.append(("Pythonç¯å¢ƒ", test_python()))
    results.append(("PyTorch&CUDA", test_torch()))
    results.append(("Whisperæ¨¡å‹", test_whisper()))
    results.append(("è§†é¢‘å¤„ç†", test_video()))
    results.append(("éŸ³é¢‘å¤„ç†", test_audio()))
    results.append(("ä¸­æ–‡å¤„ç†", test_chinese()))
    results.append(("TensorRT", test_tensorrt()))
    results.append(("æ¨¡å‹ä¸‹è½½", test_model_download()))
    results.append(("æ€§èƒ½æµ‹è¯•", run_performance_test()))

    print("\n" + "=" * 50)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 50)

    for name, result in results:
        status = "âœ…" if result else "âŒ"
        print(f"{status} {name}")

    # è®¡ç®—é€šè¿‡ç‡
    essential_tests = results[:4]  # å‰4ä¸ªæ˜¯å¿…éœ€çš„
    optional_tests = results[4:]   # åé¢çš„æ˜¯å¯é€‰çš„
    
    essential_passed = sum(1 for _, result in essential_tests if result)
    optional_passed = sum(1 for _, result in optional_tests if result)
    
    print(f"\nå¿…éœ€åŠŸèƒ½: {essential_passed}/{len(essential_tests)} é€šè¿‡")
    print(f"å¯é€‰åŠŸèƒ½: {optional_passed}/{len(optional_tests)} é€šè¿‡")

    if essential_passed >= 3:  # è‡³å°‘3ä¸ªæ ¸å¿ƒåŠŸèƒ½é€šè¿‡
        print("\nğŸ‰ ç¯å¢ƒé…ç½®åŸºæœ¬æ­£å¸¸ï¼å¯ä»¥å¼€å§‹ä½¿ç”¨ã€‚")
        print("\næ¨èä½¿ç”¨æ–¹æ³•:")
        print("  python main.py è§†é¢‘.mp4")
        print("  python main.py --input-dir ./videos --output-dir ./subtitles")
        print("\næ¨èæ¨¡å‹ (RTX 3060 Ti):")
        print("  --model faster-base    (æ¨è)")
        print("  --model base           (æ ‡å‡†)")
        print("  --model faster-small   (å¿«é€Ÿ)")
        print("\nä¸­æ–‡ç”µè§†å‰§ä¼˜åŒ–:")
        print("  --chinese-tv-optimized")
        print("  --enable-all-optimizations")
    else:
        print("\nâŒ ç¯å¢ƒé…ç½®æœ‰ä¸¥é‡é—®é¢˜ï¼Œè¯·é‡æ–°å®‰è£…ä¾èµ–")
        print("è¿è¡Œ: install_dependencies.bat")

    if optional_passed < len(optional_tests) // 2:
        print(f"\nğŸ’¡ æç¤º: å®‰è£…å¯é€‰ç»„ä»¶å¯ä»¥è·å¾—æ›´å¥½çš„ä½“éªŒ")
        print("   pip install librosa soundfile scipy  # éŸ³é¢‘å¢å¼º")
        print("   pip install jieba zhon              # ä¸­æ–‡ä¼˜åŒ–")
        print("   pip install tensorrt pycuda        # TensorRTåŠ é€Ÿ")

    input("\næŒ‰å›è½¦é”®é€€å‡º...")

if __name__ == "__main__":
    # æ·»åŠ numpyå¯¼å…¥ç”¨äºæ€§èƒ½æµ‹è¯•
    try:
        import numpy as np
    except ImportError:
        pass
    
    main()
