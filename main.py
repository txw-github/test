import os
import sys
import time
import torch
import argparse
import traceback
import subprocess
import platform
from datetime import timedelta
from typing import List, Dict, Any, Optional
import logging
import re
import numpy as np
import soundfile as sf
import gc
from tqdm import tqdm
import psutil
import json
from text_postprocessor import TextPostProcessor

# TensorRTç®¡ç†å™¨é›†æˆåˆ°ä¸»ç¨‹åºä¸­
TENSORRT_MANAGER_AVAILABLE = True
try:
    import tensorrt as trt
    import pycuda.driver as cuda
    import pycuda.autoinit
    logger.info("TensorRT Managerç»„ä»¶å°±ç»ª")
except ImportError as e:
    TENSORRT_MANAGER_AVAILABLE = False
    logger.warning(f"TensorRTç»„ä»¶ä¸å¯ç”¨: {e}")
    logger.info("å°†ä½¿ç”¨æ ‡å‡†æ¨¡å¼è¿è¡Œ")

# é…ç½®æ—¥å¿— - ä¿®å¤Windowsç¼–ç é—®é¢˜
import locale
import sys

# è®¾ç½®æ§åˆ¶å°ç¼–ç ä¸ºUTF-8
if sys.platform.startswith('win'):
    try:
        # å°è¯•è®¾ç½®æ§åˆ¶å°ä¸ºUTF-8
        import io
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
    except:
        pass

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler("video_subtitle.log", encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# æ›¿æ¢emojiå­—ç¬¦ä»¥é¿å…ç¼–ç é—®é¢˜
def safe_log_message(message):
    """å®‰å…¨çš„æ—¥å¿—æ¶ˆæ¯ï¼Œæ›¿æ¢å¯èƒ½å¯¼è‡´ç¼–ç é—®é¢˜çš„å­—ç¬¦"""
    emoji_map = {
        'ğŸ¬': '[VIDEO]',
        'ğŸ¤–': '[MODEL]', 
        'ğŸ’»': '[DEVICE]',
        'âœ…': '[OK]',
        'âŒ': '[ERROR]',
        'âš ï¸': '[WARNING]',
        'ğŸš€': '[START]',
        'ğŸ”„': '[LOADING]',
        'ğŸ“Š': '[INFO]',
        'ğŸ§¹': '[CLEANUP]',
        'ğŸ—‘ï¸': '[DELETE]',
        'ğŸ“': '[SAVE]',
        'ğŸ¯': '[TARGET]',
        'ğŸ”': '[CHECK]',
        'âœ¨': '[ENHANCE]',
        'ğŸ‰': '[SUCCESS]'
    }
    for emoji, replacement in emoji_map.items():
        message = message.replace(emoji, replacement)
    return message

# é‡å†™loggeræ–¹æ³•
original_info = logger.info
original_warning = logger.warning
original_error = logger.error

def safe_info(message, *args, **kwargs):
    return original_info(safe_log_message(str(message)), *args, **kwargs)

def safe_warning(message, *args, **kwargs):
    return original_warning(safe_log_message(str(message)), *args, **kwargs)

def safe_error(message, *args, **kwargs):
    return original_error(safe_log_message(str(message)), *args, **kwargs)

logger.info = safe_info
logger.warning = safe_warning
logger.error = safe_error

# è®¾ç½®CUDAç¯å¢ƒå˜é‡ä¼˜åŒ–RTX 3060 Ti
os.environ['CUDA_LAZY_LOADING'] = '1'
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True,garbage_collection_threshold:0.8'
os.environ['CUDA_VISIBLE_DEVICES'] = '0'

# è®¾ç½®FFmpegè·¯å¾„
ffmpeg_path = os.environ.get("FFMPEG_PATH", r"D:\code\ffmpeg\bin")
if os.path.exists(ffmpeg_path):
    os.environ["PATH"] += os.pathsep + ffmpeg_path
    logger.info(f"[OK] FFmpegè·¯å¾„å·²è®¾ç½®: {ffmpeg_path}")

# å°è¯•å¯¼å…¥ä¾èµ–
try:
    import whisper
    from faster_whisper import WhisperModel
    WHISPER_AVAILABLE = True
except ImportError:
    WHISPER_AVAILABLE = False
    logger.warning("Whisperåº“æœªå®‰è£…")

try:
    from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline
    HF_AVAILABLE = True
except ImportError:
    HF_AVAILABLE = False
    logger.warning("Transformersåº“æœªå®‰è£…")

try:
    import tensorrt as trt
    import pycuda.driver as cuda
    import pycuda.autoinit
    import onnx
    import onnxruntime as ort
    TENSORRT_AVAILABLE = True
    ONNX_AVAILABLE = True
except ImportError:
    TENSORRT_AVAILABLE = False
    ONNX_AVAILABLE = False
    logger.warning("TensorRT/ONNXä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨PyTorchåŠ é€Ÿ")

try:
    from moviepy.editor import VideoFileClip
    MOVIEPY_AVAILABLE = True
except ImportError:
    MOVIEPY_AVAILABLE = False
    logger.warning("MoviePyæœªå®‰è£…ï¼Œå°†ä½¿ç”¨FFmpegå¤„ç†éŸ³é¢‘")

# æ–°å¢FunASRå¯¼å…¥
try:
    from funasr import AutoModel
    FUNASR_AVAILABLE = True
    logger.info("FunASRåº“å¯¼å…¥æˆåŠŸ")
except ImportError:
    FUNASR_AVAILABLE = False
    AutoModel = None
    logger.warning("æœªæ‰¾åˆ°FunASRåº“ï¼Œè¯·ç¡®ä¿å·²å®‰è£…: pip install funasr")

# æ–°å¢FireRedASRå¯¼å…¥
try:
    import fireredasr
    FIREREDASR_AVAILABLE = True
    logger.info("FireRedASRåº“å¯¼å…¥æˆåŠŸ")
except ImportError:
    FIREREDASR_AVAILABLE = False
    logger.warning("FireRedASRåº“æœªå®‰è£…ï¼Œè·³è¿‡æ­¤æ¨¡å‹")

# æ–°å¢SenseVoiceå¯¼å…¥
try:
    from sensevoice import SenseVoiceSmall, SenseVoiceLarge
    SENSEVOICE_AVAILABLE = True
    logger.info("SenseVoiceåº“å¯¼å…¥æˆåŠŸ")
except ImportError:
    SENSEVOICE_AVAILABLE = False
    logger.warning("SenseVoiceåº“æœªå®‰è£…ï¼Œè·³è¿‡æ­¤æ¨¡å‹")

class Config:
    """é…ç½®ç®¡ç†ç±»"""
    def __init__(self):
        self.config_file = "config.json"
        self.load_config()

    def load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        default_config = {
            "models_path": "./models",
            "temp_path": "./temp",
            "output_path": "./output",
            "gpu_memory_fraction": 0.85,
            "batch_size": 4,
            "max_segment_length": 30,
            "preferred_model": "faster-base",
            "use_tensorrt": True,
            "audio_sample_rate": 16000,
            "chinese_optimization": {
                "enable": True,
                "context_window": 5,
                "confidence_threshold": 0.7,
                "multi_pass_correction": True
            },
            "text_enhancement": {
                "professional_terms": True,
                "polyphone_correction": True,
                "punctuation_smart": True,
                "context_aware": True
            }
        }

        if os.path.exists(self.config_file):
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    # åˆå¹¶é»˜è®¤é…ç½®å’Œç”¨æˆ·é…ç½®
                    for key, value in default_config.items():
                        if key not in config:
                            config[key] = value
                    self.config = config
            except Exception as e:
                logger.warning(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
                self.config = default_config
        else:
            self.config = default_config
            self.save_config()

    def save_config(self):
        """ä¿å­˜é…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(self.config, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"é…ç½®æ–‡ä»¶ä¿å­˜å¤±è´¥: {e}")

    def get(self, key, default=None):
        return self.config.get(key, default)

    def set(self, key, value):
        self.config[key] = value
        self.save_config()

class Timer:
    """è®¡æ—¶å™¨ç±»"""
    def __init__(self, name="ä»»åŠ¡"):
        self.name = name

    def __enter__(self):
        self.start_time = time.time()
        print(f"[START] å¼€å§‹ {self.name}...")
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        end_time = time.time()
        duration = end_time - self.start_time
        print(f"[OK] {self.name} å®Œæˆï¼Œè€—æ—¶: {duration:.2f} ç§’")

class ProgressTracker:
    """è¿›åº¦è·Ÿè¸ªå™¨"""
    def __init__(self, total_steps=100, description="å¤„ç†ä¸­"):
        self.total_steps = total_steps
        self.current_step = 0
        self.description = description
        self.pbar = tqdm(total=total_steps, desc=description, unit="step")

    def update(self, steps=1, description=None):
        if description:
            self.pbar.set_description(description)
        self.pbar.update(steps)
        self.current_step += steps

    def set_progress(self, current, total=None, description=None):
        if total:
            self.pbar.total = total
        if description:
            self.pbar.set_description(description)
        self.pbar.n = current
        self.pbar.refresh()

    def close(self):
        self.pbar.close()

class RTX3060TiOptimizer:
    """RTX 3060 Tiæ˜¾å¡ä¼˜åŒ–å™¨"""

    @staticmethod
    def setup_gpu_memory(memory_fraction=0.85):
        """é…ç½®GPUæ˜¾å­˜ç®¡ç†"""
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            try:
                total_memory = torch.cuda.get_device_properties(0).total_memory
                max_memory = int(total_memory * memory_fraction)
                torch.cuda.set_per_process_memory_fraction(memory_fraction)

                # å¯ç”¨å†…å­˜æ± ä¼˜åŒ–
                os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128,expandable_segments:True'

                logger.info(f"GPUæ˜¾å­˜ä¼˜åŒ–å®Œæˆï¼Œæ€»æ˜¾å­˜: {total_memory/1024**3:.1f}GBï¼Œé¢„ç•™ä½¿ç”¨: {max_memory/1024**3:.1f}GB")
            except Exception as e:
                logger.warning(f"æ˜¾å­˜ä¼˜åŒ–å¤±è´¥: {e}")

    @staticmethod
    def get_optimal_batch_size():
        """è·å–æœ€ä¼˜æ‰¹å¤„ç†å¤§å°"""
        if torch.cuda.is_available():
            total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            if total_memory > 5.5:  # 6GBæ˜¾å¡
                return 4
            else:
                return 2
        return 1

    @staticmethod
    def optimize_cuda_settings():
        """ä¼˜åŒ–CUDAè®¾ç½®"""
        if torch.cuda.is_available():
            # å¯ç”¨TensorRTä¼˜åŒ–
            torch.backends.cudnn.benchmark = True
            torch.backends.cudnn.deterministic = False
            torch.backends.cudnn.enabled = True

            # è®¾ç½®CUDAæµä¼˜åŒ–
            torch.cuda.synchronize()

            # å†…å­˜ä¼˜åŒ–
            torch.cuda.empty_cache()

            logger.info("CUDAä¼˜åŒ–è®¾ç½®å®Œæˆ")

class SystemChecker:
    """ç³»ç»Ÿæ£€æŸ¥å™¨"""
    @staticmethod
    def check_cuda():
        """æ£€æŸ¥CUDAç¯å¢ƒ"""
        if not torch.cuda.is_available():
            logger.error("[ERROR] CUDAä¸å¯ç”¨ï¼è¯·æ£€æŸ¥NVIDIAé©±åŠ¨å’ŒCUDAå®‰è£…")
            return False

        cuda_version = torch.version.cuda
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3

        logger.info(f"[OK] CUDAç‰ˆæœ¬: {cuda_version}")
        logger.info(f"[OK] GPU: {gpu_name}")
        logger.info(f"[OK] GPUæ˜¾å­˜: {gpu_memory:.2f} GB")

        if "3060 Ti" in gpu_name:
            logger.info("[TARGET] æ£€æµ‹åˆ°RTX 3060 Tiï¼Œå·²å¯ç”¨ä¼˜åŒ–é…ç½®")
            RTX3060TiOptimizer.setup_gpu_memory()

        return True

    @staticmethod
    def check_dependencies():
        """æ£€æŸ¥ä¾èµ–æ˜¯å¦å®‰è£…"""
        deps = {
            "torch": True,
            "whisper": WHISPER_AVAILABLE,
            "transformers": HF_AVAILABLE,
            "tensorrt": TENSORRT_AVAILABLE,
            "moviepy": MOVIEPY_AVAILABLE,
            "funasr": FUNASR_AVAILABLE,
            "fireredasr": FIREREDASR_AVAILABLE,
            "sensevoice": SENSEVOICE_AVAILABLE
        }

        missing = [name for name, available in deps.items() if not available]
        if missing:
            logger.warning(f"[WARNING] å¯é€‰ä¾èµ–ç¼ºå¤±: {', '.join(missing)}")

        required = ["torch", "whisper"]
        missing_required = [name for name in required if not deps.get(name, False)]
        if missing_required:
            logger.error(f"[ERROR] ç¼ºå°‘å¿…éœ€ä¾èµ–: {', '.join(missing_required)}")
            return False
        return True

class EnhancedVideoSubtitleExtractor:
    """å¢å¼ºç‰ˆè§†é¢‘å­—å¹•æå–å™¨ - ä¸“é—¨ä¼˜åŒ–ä¸­æ–‡è¯†åˆ«"""

    def __init__(self, model_id: str = "faster-base", device: str = "cuda", config: Config = None, **kwargs):
        self.config = config or Config()
        self.device = device
        self.kwargs = kwargs
        self.text_processor = TextPostProcessor()

        # æ£€æŸ¥ç³»ç»Ÿ
        if not SystemChecker.check_cuda():
            self.device = "cpu"
            logger.warning("[WARNING] CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPUæ¨¡å¼")

        # åˆå§‹åŒ–æ¨¡å‹
        self.model_wrapper = self._create_model(model_id)

        # åˆå§‹åŒ–å¤šæ¨¡å‹èåˆï¼ˆå¦‚æœå¯ç”¨ï¼‰
        self.enable_ensemble = kwargs.get('enable_ensemble', False)
        self.ensemble_models = []
        if self.enable_ensemble:
            self._init_ensemble_models()

    def _create_model(self, model_id: str):
        """åˆ›å»ºæ¨¡å‹å®ä¾‹"""
        if model_id in ["tiny", "base", "small", "medium", "large", "faster-base", "faster-large"]:
            return WhisperModelWrapper(model_id, self.device, self.config, **self.kwargs)
        elif model_id in ["funasr-paraformer", "funasr-conformer"]:
            if not FUNASR_AVAILABLE:
                raise ValueError("FunASRåº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install funasr")
            return FunASRModelWrapper(model_id, self.device, self.config, **self.kwargs)
        elif model_id.startswith("fireredasr"):
            if not FIREREDASR_AVAILABLE:
                raise ValueError("FireRedASRåº“æœªå®‰è£…")
            return FireRedASRModelWrapper(model_id, self.device, self.config, **self.kwargs)
        elif model_id.startswith("sensevoice"):
            if not SENSEVOICE_AVAILABLE:
                raise ValueError("SenseVoiceåº“æœªå®‰è£…")
            return SenseVoiceModelWrapper(model_id, self.device, self.config, **self.kwargs)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_id}")

    def _init_ensemble_models(self):
        """åˆå§‹åŒ–æ¨¡å‹èåˆ"""
        try:
            # ä¸ºRTX 3060 Tiä¼˜åŒ–çš„æ¨¡å‹ç»„åˆ
            ensemble_configs = [
                {"model": "faster-base", "weight": 0.6},
                {"model": "funasr-paraformer", "weight": 0.4}
            ]

            available_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            if available_memory < 4.0:
                logger.info("[INFO] æ˜¾å­˜ä¸è¶³ï¼Œç¦ç”¨æ¨¡å‹èåˆ")
                self.enable_ensemble = False
                return

            for config in ensemble_configs:
                try:
                    model = self._create_model(config["model"])
                    self.ensemble_models.append({
                        "model": model,
                        "weight": config["weight"]
                    })
                    logger.info(f"[OK] èåˆæ¨¡å‹åŠ è½½: {config['model']}")
                except Exception as e:
                    logger.warning(f"[WARNING] èåˆæ¨¡å‹åŠ è½½å¤±è´¥: {config['model']}, {e}")

        except Exception as e:
            logger.warning(f"[WARNING] æ¨¡å‹èåˆåˆå§‹åŒ–å¤±è´¥: {e}")
            self.enable_ensemble = False

    def extract_audio(self, video_path: str, audio_path: str = None, enable_preprocessing: bool = True, audio_quality: str = "balanced") -> Optional[str]:
        """ä»è§†é¢‘æå–éŸ³é¢‘ï¼Œæ”¯æŒé«˜çº§é¢„å¤„ç†"""
        if not audio_path:
            base_name = os.path.splitext(os.path.basename(video_path))[0]
            temp_path = self.config.get('temp_path', './temp')
            os.makedirs(temp_path, exist_ok=True)
            audio_path = os.path.join(temp_path, f"{base_name}_audio.wav")

        if not os.path.exists(video_path):
            logger.error(f"[ERROR] è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            return None

        try:
            progress = ProgressTracker(100, "æå–å’Œå¤„ç†éŸ³é¢‘")
            raw_audio_path = None

            with Timer("éŸ³é¢‘æå–å’Œé¢„å¤„ç†"):
                progress.update(10, "æ£€æŸ¥è§†é¢‘æ–‡ä»¶...")

                # å¦‚æœå¯ç”¨é¢„å¤„ç†ï¼Œå…ˆæå–åˆ°ä¸´æ—¶æ–‡ä»¶
                if enable_preprocessing:
                    raw_audio_path = os.path.join(os.path.dirname(audio_path), f"raw_{os.path.basename(audio_path)}")
                    actual_output = raw_audio_path
                else:
                    actual_output = audio_path

                if MOVIEPY_AVAILABLE:
                    progress.update(15, "ä½¿ç”¨MoviePyæå–éŸ³é¢‘...")
                    video = VideoFileClip(video_path)
                    audio = video.audio
                    progress.update(15, "å†™å…¥éŸ³é¢‘æ–‡ä»¶...")
                    audio.write_audiofile(
                        actual_output, 
                        fps=self.config.get('audio_sample_rate', 16000), 
                        verbose=False, 
                        logger=None
                    )
                    progress.update(10, "æ¸…ç†èµ„æº...")
                    video.close()
                    audio.close()
                else:
                    progress.update(15, "ä½¿ç”¨FFmpegæå–éŸ³é¢‘...")
                    cmd = [
                        "ffmpeg", "-y", "-i", video_path,
                        "-vn", "-acodec", "pcm_s16le", 
                        "-ar", str(self.config.get('audio_sample_rate', 16000)), 
                        "-ac", "1", actual_output, "-loglevel", "error"
                    ]
                    subprocess.run(cmd, check=True, capture_output=True)
                    progress.update(25, "éŸ³é¢‘æå–å®Œæˆ")

                # å¦‚æœå¯ç”¨é¢„å¤„ç†ï¼Œè¿›è¡Œé«˜çº§éŸ³é¢‘å¤„ç†
                if enable_preprocessing and os.path.exists(raw_audio_path):
                    progress.update(20, f"å¼€å§‹{audio_quality}è´¨é‡éŸ³é¢‘é¢„å¤„ç†...")

class WhisperModelWrapper:
    """Whisperæ¨¡å‹åŒ…è£…å™¨"""
    def __init__(self, model_id: str, device: str = "cuda", config: Config = None, **kwargs):
        self.model_id = model_id
        self.device = device
        self.config = config or Config()
        self.model = None
        self.use_tensorrt = kwargs.get('use_tensorrt', False)

    def load_model(self):
        """åŠ è½½Whisperæ¨¡å‹"""
        try:
            logger.info(f"[LOADING] åŠ è½½Whisperæ¨¡å‹: {self.model_id}")
            
            if self.model_id.startswith("faster-"):
                model_size = self.model_id.replace("faster-", "")
                self.model = WhisperModel(
                    model_size, 
                    device=self.device,
                    compute_type="float16" if self.device == "cuda" else "float32"
                )
            else:
                self.model = whisper.load_model(self.model_id, device=self.device)
            
            logger.info(f"[OK] Whisperæ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            logger.error(f"[ERROR] Whisperæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise

    def transcribe(self, audio_path: str, **kwargs) -> Dict[str, Any]:
        """Whisperè½¬å½•"""
        try:
            if self.model_id.startswith("faster-"):
                # Faster-Whisper
                segments, info = self.model.transcribe(
                    audio_path, 
                    beam_size=5,
                    language=kwargs.get('language', 'zh'),
                    temperature=kwargs.get('temperature', 0.0)
                )
                
                segment_list = []
                for segment in segments:
                    segment_list.append({
                        "start": segment.start,
                        "end": segment.end,
                        "text": segment.text
                    })
                
                return {
                    "segments": segment_list,
                    "language": info.language,
                    "text": " ".join([s["text"] for s in segment_list])
                }
            else:
                # OpenAI Whisper
                result = self.model.transcribe(
                    audio_path,
                    language=kwargs.get('language', 'zh'),
                    temperature=kwargs.get('temperature', 0.0)
                )
                return result
                
        except Exception as e:
            logger.error(f"[ERROR] Whisperè½¬å½•å¤±è´¥: {e}")
            raise

    def get_gpu_memory_usage(self) -> float:
        """è·å–GPUæ˜¾å­˜ä½¿ç”¨é‡"""
        if torch.cuda.is_available():
            return torch.cuda.memory_allocated() / 1024 / 1024
        return 0.0


class FunASRModelWrapper:
    """FunASRæ¨¡å‹åŒ…è£…å™¨"""
    def __init__(self, model_id: str, device: str = "cuda", config: Config = None, **kwargs):
        self.model_id = model_id
        self.device = device
        self.config = config or Config()
        self.model = None

    def load_model(self):
        """åŠ è½½FunASRæ¨¡å‹"""
        try:
            if not FUNASR_AVAILABLE:
                raise ImportError("FunASRåº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install funasr")

            logger.info(f"[LOADING] åŠ è½½FunASRæ¨¡å‹: {self.model_id}")
            
            if "paraformer" in self.model_id:
                model_name = "iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch"
            else:
                model_name = "iic/speech_conformer_asr_nat-zh-cn-16k-aishell1-vocab4234-pytorch"
            
            self.model = AutoModel(
                model=model_name,
                device=self.device
            )
            
            logger.info(f"[OK] FunASRæ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            logger.error(f"[ERROR] FunASRæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise

    def transcribe(self, audio_path: str, **kwargs) -> Dict[str, Any]:
        """FunASRè½¬å½•"""
        try:
            result = self.model.generate(input=audio_path)
            
            # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
            if result and len(result) > 0:
                text = result[0]["text"] if isinstance(result[0], dict) else str(result[0])
                
                # ç®€å•çš„æ—¶é—´æˆ³ç”Ÿæˆï¼ˆFunASRå¯èƒ½ä¸æä¾›è¯¦ç»†æ—¶é—´æˆ³ï¼‰
                import soundfile as sf
                audio_data, sample_rate = sf.read(audio_path)
                duration = len(audio_data) / sample_rate
                
                segments = [{
                    "start": 0.0,
                    "end": duration,
                    "text": text
                }]
                
                return {
                    "segments": segments,
                    "language": "zh",
                    "text": text
                }
            else:
                return {"segments": [], "language": "zh", "text": ""}
                
        except Exception as e:
            logger.error(f"[ERROR] FunASRè½¬å½•å¤±è´¥: {e}")
            raise

    def get_gpu_memory_usage(self) -> float:
        """è·å–GPUæ˜¾å­˜ä½¿ç”¨é‡"""
        if torch.cuda.is_available():
            return torch.cuda.memory_allocated() / 1024 / 1024
        return 0.0



                    try:
                        from audio_preprocessor import AdvancedAudioPreprocessor
                        preprocessor = AdvancedAudioPreprocessor(
                            target_sample_rate=self.config.get('audio_sample_rate', 16000)
                        )

                        # è¿›è¡Œé«˜çº§é¢„å¤„ç†
                        processed_path = preprocessor.preprocess_audio(
                            raw_audio_path, 
                            audio_path, 
                            quality=audio_quality
                        )

                        progress.update(30, "éŸ³é¢‘é¢„å¤„ç†å®Œæˆ")

                        # æ¸…ç†åŸå§‹éŸ³é¢‘æ–‡ä»¶
                        if os.path.exists(raw_audio_path):
                            os.remove(raw_audio_path)

                        logger.info(f"[ENHANCE] éŸ³é¢‘é¢„å¤„ç†å®Œæˆï¼Œè´¨é‡ç­‰çº§: {audio_quality}")

                    except Exception as e:
                        logger.warning(f"éŸ³é¢‘é¢„å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹éŸ³é¢‘: {e}")
                        # é¢„å¤„ç†å¤±è´¥æ—¶ï¼Œå°†åŸå§‹æ–‡ä»¶é‡å‘½åä¸ºæœ€ç»ˆæ–‡ä»¶
                        if os.path.exists(raw_audio_path):
                            if os.path.exists(audio_path):
                                os.remove(audio_path)
                            os.rename(raw_audio_path, audio_path)

                progress.update(10, "éªŒè¯éŸ³é¢‘æ–‡ä»¶...")
                if os.path.exists(audio_path):
                    file_size = os.path.getsize(audio_path) / 1024 / 1024
                    progress.close()
                    logger.info(f"[OK] éŸ³é¢‘å¤„ç†æˆåŠŸ: {audio_path} ({file_size:.1f}MB)")
                    return audio_path
                else:
                    progress.close()
                    logger.error("[ERROR] éŸ³é¢‘å¤„ç†å¤±è´¥")
                    return None

        except Exception as e:
            logger.error(f"[ERROR] éŸ³é¢‘å¤„ç†å‡ºé”™: {e}")
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if raw_audio_path and os.path.exists(raw_audio_path):
                try:
                    os.remove(raw_audio_path)
                except:
                    pass
            return None

    def transcribe_audio(self, audio_path: str, **kwargs) -> Dict[str, Any]:
        """è½¬å½•éŸ³é¢‘ - æ”¯æŒæ¨¡å‹èåˆå’Œæ™ºèƒ½çº é”™"""
        if not os.path.exists(audio_path):
            logger.error(f"[ERROR] éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
            return {"segments": [], "language": None}

        try:
            # åŠ è½½æ¨¡å‹
            if self.model_wrapper.model is None:
                self.model_wrapper.load_model()

            with Timer("éŸ³é¢‘è½¬å½•"):
                # å•æ¨¡å‹æ¨ç†
                result = self.model_wrapper.transcribe(audio_path, **kwargs)

                # æ¨¡å‹èåˆæ¨ç†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if self.enable_ensemble and len(self.ensemble_models) > 0:
                    result = self._ensemble_transcribe(audio_path, result, **kwargs)

                # æ™ºèƒ½æ–‡æœ¬åå¤„ç†
                if self.config.get('text_enhancement', {}).get('context_aware', True):
                    result = self._enhanced_text_processing(result)

                segment_count = len(result.get('segments', []))
                logger.info(f"[OK] è½¬å½•å®Œæˆï¼Œè¯†åˆ«åˆ° {segment_count} ä¸ªç‰‡æ®µ")

                if self.device == "cuda":
                    memory_usage = self.model_wrapper.get_gpu_memory_usage()
                    logger.info(f"[INFO] è½¬å½•åæ˜¾å­˜ä½¿ç”¨: {memory_usage:.1f}MB")

                return result

        except Exception as e:
            logger.error(f"[ERROR] éŸ³é¢‘è½¬å½•å¤±è´¥: {e}")
            return {"segments": [], "language": None}

    def _ensemble_transcribe(self, audio_path: str, primary_result: Dict, **kwargs) -> Dict[str, Any]:
        """æ¨¡å‹èåˆè½¬å½•"""
        try:
            logger.info("[INFO] å¼€å§‹æ¨¡å‹èåˆæ¨ç†...")
            ensemble_results = [primary_result]

            for model_config in self.ensemble_models:
                try:
                    model = model_config["model"]
                    if model.model is None:
                        model.load_model()

                    result = model.transcribe(audio_path, **kwargs)
                    ensemble_results.append(result)

                except Exception as e:
                    logger.warning(f"[WARNING] èåˆæ¨¡å‹æ¨ç†å¤±è´¥: {e}")

            # èåˆç»“æœ
            return self._merge_results(ensemble_results)

        except Exception as e:
            logger.warning(f"[WARNING] æ¨¡å‹èåˆå¤±è´¥ï¼Œä½¿ç”¨å•æ¨¡å‹ç»“æœ: {e}")
            return primary_result

    def _merge_results(self, results: List[Dict]) -> Dict[str, Any]:
        """èåˆå¤šä¸ªæ¨¡å‹çš„ç»“æœ"""
        if len(results) <= 1:
            return results[0] if results else {"segments": [], "language": None}

        # ä»¥ç¬¬ä¸€ä¸ªç»“æœä¸ºåŸºå‡†
        merged_result = results[0].copy()

        # å¯¹æ¯ä¸ªç‰‡æ®µè¿›è¡ŒæŠ•ç¥¨èåˆ
        segments = merged_result.get("segments", [])
        for i, segment in enumerate(segments):
            texts = [segment["text"]]

            # æ”¶é›†å…¶ä»–æ¨¡å‹å¯¹åº”ç‰‡æ®µçš„æ–‡æœ¬
            for result in results[1:]:
                other_segments = result.get("segments", [])
                if i < len(other_segments):
                    texts.append(other_segments[i]["text"])

            # é€‰æ‹©æœ€ä½³æ–‡æœ¬ï¼ˆè¿™é‡Œç®€åŒ–ä¸ºé€‰æ‹©æœ€é•¿çš„ï¼‰
            best_text = max(texts, key=len)
            segments[i]["text"] = best_text

        logger.info(f"[OK] æ¨¡å‹èåˆå®Œæˆï¼Œä½¿ç”¨äº† {len(results)} ä¸ªæ¨¡å‹çš„ç»“æœ")
        return merged_result

    def _enhanced_text_processing(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """å¢å¼ºæ–‡æœ¬å¤„ç†"""
        try:
            segments = result.get("segments", [])
            if not segments:
                return result

            logger.info("[ENHANCE] å¼€å§‹æ™ºèƒ½æ–‡æœ¬å¤„ç†...")

            # å…¨æ–‡ä¸Šä¸‹æ–‡å¤„ç†
            full_text = " ".join([seg["text"] for seg in segments])

            # åº”ç”¨é«˜çº§æ–‡æœ¬åå¤„ç†
            processed_full_text = self.text_processor.post_process(full_text)

            # å°†å¤„ç†åçš„æ–‡æœ¬é‡æ–°åˆ†é…åˆ°å„ä¸ªç‰‡æ®µ
            processed_segments = self._redistribute_text(segments, processed_full_text)

            result["segments"] = processed_segments
            result["enhanced"] = True

            logger.info("[OK] æ™ºèƒ½æ–‡æœ¬å¤„ç†å®Œæˆ")
            return result
        except Exception as e:
            logger.warning(f"[WARNING] æ™ºèƒ½æ–‡æœ¬å¤„ç†å¤±è´¥: {e}")
            return result

    def _redistribute_text(self, original_segments: List[Dict], processed_text: str) -> List[Dict]:
        """å°†å¤„ç†åçš„æ–‡æœ¬é‡æ–°åˆ†é…åˆ°ç‰‡æ®µ"""
        import jieba

        # å¯¹å¤„ç†åçš„æ–‡æœ¬è¿›è¡Œåˆ†è¯
        words = list(jieba.cut(processed_text))

        # è®¡ç®—æ¯ä¸ªåŸå§‹ç‰‡æ®µçš„è¯æ•°æ¯”ä¾‹
        original_words = []
        for seg in original_segments:
            seg_words = list(jieba.cut(seg["text"]))
            original_words.append(seg_words)

        total_original_words = sum(len(words) for words in original_words)

        # æŒ‰æ¯”ä¾‹é‡æ–°åˆ†é…
        processed_segments = []
        word_index = 0

        for i, seg in enumerate(original_segments):
            original_word_count = len(original_words[i])
            if total_original_words > 0:
                proportion = original_word_count / total_original_words
                target_word_count = max(1, int(len(words) * proportion))
            else:
                target_word_count = 1

            # æå–å¯¹åº”çš„è¯
            segment_words = words[word_index:word_index + target_word_count]
            word_index += target_word_count

            # åˆ›å»ºæ–°ç‰‡æ®µ
            new_segment = seg.copy()
            new_segment["text"] = "".join(segment_words)
            processed_segments.append(new_segment)

        return processed_segments

    def create_srt_file(self, segments: List[Dict], output_path: str = "output.srt", enable_postprocess: bool = True) -> str:
        """åˆ›å»ºSRTå­—å¹•æ–‡ä»¶"""
        try:
            progress = ProgressTracker(len(segments) + 10, "ç”Ÿæˆå­—å¹•æ–‡ä»¶")

            output_dir = self.config.get('output_path', './output')
            os.makedirs(output_dir, exist_ok=True)

            if not output_path.startswith(output_dir):
                output_path = os.path.join(output_dir, os.path.basename(output_path))

            # åˆå§‹åŒ–æ–‡æœ¬åå¤„ç†å™¨
            if enable_postprocess:
                progress.update(5, "åˆå§‹åŒ–æ–‡æœ¬åå¤„ç†å™¨...")

                # ç»Ÿè®¡åŸå§‹é”™è¯¯
                total_text = " ".join([seg["text"] for seg in segments])
                original_stats = self.text_processor.get_correction_stats(total_text)
                logger.info(f"[CHECK] æ£€æµ‹åˆ°æ½œåœ¨é”™è¯¯: ä¸“ä¸šåè¯ {original_stats['professional_terms']} å¤„, "
                          f"å¤šéŸ³å­— {original_stats['polyphone_errors']} å¤„, "
                          f"æ•°å­—å•ä½ {original_stats['number_units']} å¤„")

            with open(output_path, "w", encoding="utf-8") as f:
                for i, segment in enumerate(segments, 1):
                    start_time = self._format_time(segment["start"])
                    end_time = self._format_time(segment["end"])
                    text = segment["text"].strip()

                    # åº”ç”¨æ–‡æœ¬åå¤„ç†
                    if enable_postprocess:
                        corrected_text = self.text_processor.post_process(text)
                        if corrected_text != text:
                            logger.debug(f"ç‰‡æ®µ {i} æ–‡æœ¬çº é”™: '{text}' -> '{corrected_text}'")
                        text = corrected_text

                    f.write(f"{i}\n")
                    f.write(f"{start_time} --> {end_time}\n")
                    f.write(f"{text}\n\n")

                    progress.update(1, f"å†™å…¥ç‰‡æ®µ {i}/{len(segments)}")

            # ä¿å­˜åŸå§‹ç‰ˆæœ¬ï¼ˆå¯é€‰ï¼‰
            if enable_postprocess:
                progress.update(3, "ä¿å­˜åŸå§‹ç‰ˆæœ¬...")
                original_path = output_path.replace(".srt", "_original.srt")
                with open(original_path, "w", encoding="utf-8") as f:
                    for i, segment in enumerate(segments, 1):
                        start_time = self._format_time(segment["start"])
                        end_time = self._format_time(segment["end"])
                        text = segment["text"].strip()
                        f.write(f"{i}\n")
                        f.write(f"{start_time} --> {end_time}\n")
                        f.write(f"{text}\n\n")
                logger.info(f"[SAVE] åŸå§‹å­—å¹•ä¿å­˜è‡³: {original_path}")

                # ç»Ÿè®¡å¤„ç†ç»“æœ
                total_text = " ".join([seg["text"] for seg in segments])
                processed_text = self.text_processor.post_process(total_text)

                # ç»Ÿè®¡æ ‡ç‚¹ç¬¦å·
                punctuation_count = len(re.findall(r'[ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š]', processed_text))
                sentence_count = len(re.findall(r'[ã€‚ï¼ï¼Ÿ]', processed_text))

                logger.info(f"[INFO] æ–‡æœ¬å¤„ç†ç»Ÿè®¡: æ·»åŠ äº† {punctuation_count} ä¸ªæ ‡ç‚¹ç¬¦å·, {sentence_count} ä¸ªå¥å­")

            progress.update(2, "å®Œæˆå­—å¹•ç”Ÿæˆ...")
            progress.close()
            logger.info(f"[OK] SRTæ–‡ä»¶ä¿å­˜æˆåŠŸ: {output_path}")

            if enable_postprocess:
                logger.info("[TARGET] æ–‡æœ¬åå¤„ç†åŠŸèƒ½å·²å¯ç”¨ï¼Œå·²æ·»åŠ æ ‡ç‚¹ç¬¦å·å¹¶ä¿®æ­£é”™åˆ«å­—")

            return output_path

        except Exception as e:
            logger.error(f"[ERROR] SRTæ–‡ä»¶åˆ›å»ºå¤±è´¥: {e}")
            return None

    def _format_time(self, seconds: float) -> str:
        """æ ¼å¼åŒ–æ—¶é—´ä¸ºSRTæ ¼å¼"""
        hours, remainder = divmod(seconds, 3600)
        minutes, seconds = divmod(remainder, 60)
        milliseconds = int((seconds - int(seconds)) * 1000)
        return f"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d},{milliseconds:03d}"

    def cleanup(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶å’Œæ˜¾å­˜"""
        try:
            temp_path = self.config.get('temp_path', './temp')
            if os.path.exists(temp_path):
                temp_files = [f for f in os.listdir(temp_path) if f.endswith("_audio.wav")]
                for file in temp_files:
                    file_path = os.path.join(temp_path, file)
                    try:
                        os.remove(file_path)
                        logger.info(f"[DELETE] åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {file}")
                    except Exception as e:
                        logger.warning(f"[WARNING] åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥ {file}: {e}")

            # æ¸…ç†GPUæ˜¾å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                gc.collect()
                logger.info("[CLEANUP] GPUæ˜¾å­˜æ¸…ç†å®Œæˆ")

        except Exception as e:
            logger.warning(f"[WARNING] æ¸…ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")

# æ¨¡å‹åŒ…è£…å™¨ç±»å®šä¹‰

# æ–°å¢FireRedASRæ¨¡å‹åŒ…è£…å™¨
class FireRedASRModelWrapper:
    """FireRedASRæ¨¡å‹åŒ…è£…å™¨"""
    def __init__(self, model_id: str, device: str = "cuda", config: Config = None, **kwargs):
        self.model_id = model_id
        self.device = device
        self.config = config or Config()
        self.model = None

    def load_model(self):
        """åŠ è½½FireRedASRæ¨¡å‹"""
        try:
            if not FIREREDASR_AVAILABLE:
                raise ImportError("FireRedASRåº“æœªå®‰è£…")

            logger.info(f"[LOADING] åŠ è½½FireRedASRæ¨¡å‹: {self.model_id}")
            # è¿™é‡Œåº”è¯¥æ˜¯å®é™…çš„FireRedASRåŠ è½½ä»£ç 
            # self.model = fireredasr.load_model(self.model_id)
            logger.info(f"[OK] FireRedASRæ¨¡å‹åŠ è½½æˆåŠŸ")

        except Exception as e:
            logger.error(f"[ERROR] FireRedASRæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise

    def transcribe(self, audio_path: str, **kwargs) -> Dict[str, Any]:
        """FireRedASRè½¬å½•"""
        try:
            # å®é™…çš„FireRedASRæ¨ç†ä»£ç 
            # result = self.model.transcribe(audio_path)

            # ä¸´æ—¶è¿”å›æ ¼å¼
            return {
                "segments": [],
                "language": "zh",
                "text": ""
            }

        except Exception as e:
            logger.error(f"[ERROR] FireRedASRè½¬å½•å¤±è´¥: {e}")
            raise

    def get_gpu_memory_usage(self) -> float:
        """è·å–GPUæ˜¾å­˜ä½¿ç”¨é‡"""
        if torch.cuda.is_available():
            return torch.cuda.memory_allocated() / 1024 / 1024
        return 0.0

# æ–°å¢SenseVoiceæ¨¡å‹åŒ…è£…å™¨
class SenseVoiceModelWrapper:
    """SenseVoiceæ¨¡å‹åŒ…è£…å™¨"""
    def __init__(self, model_id: str, device: str = "cuda", config: Config = None, **kwargs):
        self.model_id = model_id
        self.device = device
        self.config = config or Config()
        self.model = None

    def load_model(self):
        """åŠ è½½SenseVoiceæ¨¡å‹"""
        try:
            if not SENSEVOICE_AVAILABLE:
                raise ImportError("SenseVoiceåº“æœªå®‰è£…")

            logger.info(f"[LOADING] åŠ è½½SenseVoiceæ¨¡å‹: {self.model_id}")

            if "small" in self.model_id:
                self.model = SenseVoiceSmall.from_pretrained("iic/SenseVoiceSmall")
            else:
                self.model = SenseVoiceLarge.from_pretrained("iic/SenseVoiceLarge")

            logger.info(f"[OK] SenseVoiceæ¨¡å‹åŠ è½½æˆåŠŸ")

        except Exception as e:
            logger.error(f"[ERROR] SenseVoiceæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise

    def transcribe(self, audio_path: str, **kwargs) -> Dict[str, Any]:
        """SenseVoiceè½¬å½•"""
        try:
            # å®é™…çš„SenseVoiceæ¨ç†ä»£ç 
            # result = self.model(audio_path)

            # ä¸´æ—¶è¿”å›æ ¼å¼
            return {
                "segments": [],
                "language": "zh", 
                "text": ""
            }

        except Exception as e:
            logger.error(f"[ERROR] SenseVoiceè½¬å½•å¤±è´¥: {e}")
            raise

    def get_gpu_memory_usage(self) -> float:
        """è·å–GPUæ˜¾å­˜ä½¿ç”¨é‡"""
        if torch.cuda.is_available():
            return torch.cuda.memory_allocated() / 1024 / 1024
        return 0.0

def main():
    parser = argparse.ArgumentParser(description="ä¸­æ–‡ç”µè§†å‰§éŸ³é¢‘è½¬æ–‡å­—å·¥å…· - RTX 3060 Tiä¼˜åŒ–ç‰ˆ")
    parser.add_argument("video_path", nargs='?', default="test.mp4", help="è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output", "-o", default="output.srt", help="è¾“å‡ºå­—å¹•æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--model", "-m", default="faster-base",
                        choices=["tiny", "base", "small", "medium", "large", "faster-base", "faster-large", 
                                "funasr-paraformer", "funasr-conformer", "fireredasr-small", "fireredasr-base", 
                                "fireredasr-large", "sensevoice-small", "sensevoice-large"],
                        help="æ¨¡å‹é€‰æ‹© (æ¨èRTX 3060 Tiä½¿ç”¨faster-baseæˆ–funasr-paraformer)")
    parser.add_argument("--device", "-d", default="cuda", choices=["cuda", "cpu"], help="è¿è¡Œè®¾å¤‡")
    parser.add_argument("--language", "-l", default="zh", help="è¯­è¨€è®¾ç½®")
    parser.add_argument("--keep-temp", action="store_true", help="ä¿ç•™ä¸´æ—¶æ–‡ä»¶")
    parser.add_argument("--config", "-c", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--no-postprocess", action="store_true", help="ç¦ç”¨æ–‡æœ¬åå¤„ç†")
    parser.add_argument("--add-term", nargs=2, metavar=('CORRECT', 'WRONG'), 
                        help="æ·»åŠ è‡ªå®šä¹‰çº é”™è¯æ±‡: --add-term 'æ­£ç¡®è¯' 'é”™è¯¯è¯'")
    parser.add_argument("--audio-quality", choices=["fast", "balanced", "high"], default="balanced",
                        help="éŸ³é¢‘é¢„å¤„ç†è´¨é‡ (fast/balanced/high)")
    parser.add_argument("--enable-audio-preprocessing", action="store_true", default=True,
                        help="å¯ç”¨é«˜çº§éŸ³é¢‘é¢„å¤„ç†")
    parser.add_argument("--precision", choices=["fp16", "fp32"], default="fp16",
                        help="æ¨¡å‹ç²¾åº¦é€‰æ‹© (fp16æ›´å¿«ï¼Œfp32æ›´ç²¾ç¡®)")
    parser.add_argument("--analyze-audio", action="store_true", 
                        help="åˆ†æéŸ³é¢‘è´¨é‡å¹¶æä¾›ä¼˜åŒ–å»ºè®®")
    parser.add_argument("--analyze-text", action="store_true",
                        help="åˆ†ææ–‡æœ¬è´¨é‡å¹¶æä¾›ä¼˜åŒ–å»ºè®®")
    parser.add_argument("--enable-ensemble", action="store_true",
                        help="å¯ç”¨å¤šæ¨¡å‹èåˆæ¨ç†ï¼ˆéœ€è¦æ›´å¤šæ˜¾å­˜ï¼‰")

    args = parser.parse_args()

    # åŠ è½½é…ç½®
    config = Config()
    if args.config and os.path.exists(args.config):
        config.config_file = args.config
        config.load_config()

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.video_path):
        logger.error(f"[ERROR] è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {args.video_path}")
        return

    # æ£€æŸ¥ä¾èµ–
    if not SystemChecker.check_dependencies():
        logger.error("[ERROR] è¯·å…ˆè¿è¡Œinstall_dependencies.batå®‰è£…ç¼ºå°‘çš„ä¾èµ–")
        return

    logger.info(f"[VIDEO] å¼€å§‹å¤„ç†è§†é¢‘: {args.video_path}")
    logger.info(f"[MODEL] ä½¿ç”¨æ¨¡å‹: {args.model}")
    logger.info(f"[DEVICE] è¿è¡Œè®¾å¤‡: {args.device}")

    if args.model in ["medium", "large"] and args.device == "cuda":
        logger.warning("[WARNING] RTX 3060 Tiæ˜¾å­˜å¯èƒ½ä¸è¶³ä»¥è¿è¡Œmedium/largeæ¨¡å‹ï¼Œå»ºè®®ä½¿ç”¨faster-base")

    if args.model in ["funasr-paraformer", "funasr-conformer"]:
        logger.warning("[WARNING] FunASRæ¨¡å‹å†…å­˜å ç”¨è¾ƒå¤§ï¼Œå¦‚é‡åˆ°å†…å­˜ä¸è¶³è¯·è€ƒè™‘ä½¿ç”¨faster-baseæ¨¡å‹")
        # æ£€æŸ¥å¯ç”¨å†…å­˜
        memory = psutil.virtual_memory()
        if memory.available < 4 * 1024**3:  # å°äº4GBå¯ç”¨å†…å­˜
            logger.warning(f"[WARNING] å¯ç”¨å†…å­˜ä¸è¶³({memory.available/1024**3:.1f}GB)ï¼Œå»ºè®®å…³é—­å…¶ä»–ç¨‹åºæˆ–ä½¿ç”¨smalleræ¨¡å‹")

    extractor = None
    try:
        # åˆ›å»ºå¢å¼ºç‰ˆæå–å™¨
        extractor = EnhancedVideoSubtitleExtractor(
            model_id=args.model,
            device=args.device,
            config=config,
            enable_ensemble=args.enable_ensemble
        )

        # æå–éŸ³é¢‘ï¼ˆæ”¯æŒé¢„å¤„ç†ï¼‰
        audio_path = extractor.extract_audio(
            args.video_path,
            enable_preprocessing=args.enable_audio_preprocessing,
            audio_quality=args.audio_quality
        )
        if not audio_path:
            logger.error("[ERROR] éŸ³é¢‘æå–å¤±è´¥")
            return

        # éŸ³é¢‘è´¨é‡åˆ†æï¼ˆå¯é€‰ï¼‰
        if args.analyze_audio:
            try:
                from audio_preprocessor import AdvancedAudioPreprocessor
                preprocessor = AdvancedAudioPreprocessor()
                audio_metrics = preprocessor.analyze_audio_quality(audio_path)

                if audio_metrics:
                    logger.info(f"[INFO] éŸ³é¢‘è´¨é‡åˆ†æç»“æœ:")
                    logger.info(f"   - ç»¼åˆè¯„åˆ†: {audio_metrics.get('overall_score', 0):.1f}/100")
                    logger.info(f"   - ä¸­æ–‡é€‚é…åº¦: {audio_metrics.get('chinese_speech_score', 0):.1f}/100")
                    logger.info(f"   - è¯­éŸ³æ¸…æ™°åº¦: {audio_metrics.get('speech_clarity', 0):.2f}")
                    logger.info(f"   - å™ªå£°æ°´å¹³: {audio_metrics.get('noise_level', 0):.1f}")

                    recommendations = audio_metrics.get('recommendations', [])
                    if recommendations:
                        logger.info("[SAVE] ä¼˜åŒ–å»ºè®®:")
                        for rec in recommendations:
                            logger.info(f"   - {rec}")
            except Exception as e:
                logger.warning(f"éŸ³é¢‘è´¨é‡åˆ†æå¤±è´¥: {e}")

        # è½¬å½•éŸ³é¢‘
        result = extractor.transcribe_audio(
            audio_path,
            language=args.language,
            temperature=0.0 if args.precision == "fp16" else 0.1
        )

        if not result["segments"]:
            logger.warning("[WARNING] æœªè¯†åˆ«åˆ°ä»»ä½•è¯­éŸ³å†…å®¹")
            return

        # åˆ›å»ºå­—å¹•æ–‡ä»¶
        enable_postprocess = not args.no_postprocess
        srt_path = extractor.create_srt_file(result["segments"], args.output, enable_postprocess)
        if srt_path:
            logger.info(f"[SUCCESS] å­—å¹•æå–å®Œæˆï¼æ–‡ä»¶ä¿å­˜è‡³: {srt_path}")
            logger.info(f"[SAVE] å…±è¯†åˆ«åˆ° {len(result['segments'])} ä¸ªå­—å¹•ç‰‡æ®µ")
            if enable_postprocess:
                logger.info("[ENHANCE] å·²åº”ç”¨æ™ºèƒ½æ–‡æœ¬çº é”™")
            if args.enable_ensemble:
                logger.info("[ENHANCE] å·²åº”ç”¨å¤šæ¨¡å‹èåˆæ¨ç†")

            # æ–‡æœ¬è´¨é‡åˆ†æï¼ˆå¯é€‰ï¼‰
            if args.analyze_text:
                try:
                    text_analysis = extractor.text_processor.analyze_text_quality(
                        " ".join([seg["text"] for seg in result["segments"]])
                    )

                    logger.info(f"[INFO] æ–‡æœ¬è´¨é‡åˆ†æç»“æœ:")
                    logger.info(f"   - è´¨é‡è¯„åˆ†: {text_analysis['quality_score']}")
                    logger.info(f"   - é”™è¯¯ç‡: {text_analysis['error_rate']}%")

                    error_stats = text_analysis['error_statistics']
                    logger.info(f"   - æ½œåœ¨åŒéŸ³å­—é”™è¯¯: {error_stats['sound_alike_errors']} å¤„")
                    logger.info(f"   - ä¸“ä¸šæœ¯è¯­é”™è¯¯: {error_stats['professional_terms']} å¤„")
                    logger.info(f"   - è¯­æ°”è¯å†—ä½™: {error_stats['filler_words']} å¤„")

                    recommendations = text_analysis['recommendations']
                    if recommendations:
                        logger.info("[SAVE] æ–‡æœ¬ä¼˜åŒ–å»ºè®®:")
                        for rec in recommendations:
                            logger.info(f"   - {rec}")
                except Exception as e:
                    logger.warning(f"æ–‡æœ¬è´¨é‡åˆ†æå¤±è´¥: {e}")
        else:
            logger.error("[ERROR] å­—å¹•æ–‡ä»¶åˆ›å»ºå¤±è´¥")

        # å¤„ç†è‡ªå®šä¹‰è¯æ±‡æ·»åŠ 
        if args.add_term:
            extractor.text_processor.add_custom_correction(args.add_term[0], [args.add_term[1]])
            logger.info(f"[OK] å·²æ·»åŠ è‡ªå®šä¹‰çº é”™è¯æ±‡: {args.add_term[0]} <- {args.add_term[1]}")

    except Exception as e:
        logger.error(f"[ERROR] å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        traceback.print_exc()

    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶å’Œæ˜¾å­˜
        try:
            if extractor is not None and not args.keep_temp:
                extractor.cleanup()
        except Exception as e:
            logger.warning(f"[WARNING] æ¸…ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")

if __name__ == "__main__":
    main()