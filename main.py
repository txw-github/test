
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
RTX 3060 Ti ä¸­æ–‡è§†é¢‘è½¬å­—å¹•å·¥å…· - å…¨é¢ä¼˜åŒ–ç‰ˆ
æ”¯æŒå¤šç§æ¨¡å‹ï¼šWhisperã€Faster-Whisperã€FunASR
é’ˆå¯¹ä¸­æ–‡ç”µè§†å‰§ä¼˜åŒ–ï¼Œæ”¯æŒTensorRTåŠ é€Ÿ
å¢å¼ºä¸­æ–‡æ–‡æœ¬å¤„ç†ã€éŸ³é¢‘é¢„å¤„ç†ã€ä¸“ä¸šè¯æ±‡è¯†åˆ«
"""

import os
import sys
import logging
import argparse
import time
import json
import re
from pathlib import Path
from typing import Optional, Dict, List, Any, Tuple
from tqdm import tqdm
import subprocess
import unicodedata

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['CUDA_LAZY_LOADING'] = '1'
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('conversion.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# è®¾ç½®FFmpegè·¯å¾„ (å¤šå¹³å°å…¼å®¹)
ffmpeg_paths = [
    r"D:\code\ffmpeg\bin",  # Windowsæœ¬åœ°è·¯å¾„
    "/usr/bin",             # Linuxç³»ç»Ÿè·¯å¾„
    "/usr/local/bin",       # å¤‡ç”¨è·¯å¾„
    "/opt/homebrew/bin"     # macOS Homebrewè·¯å¾„
]

for ffmpeg_path in ffmpeg_paths:
    if os.path.exists(ffmpeg_path):
        if ffmpeg_path not in os.environ.get("PATH", ""):
            os.environ["PATH"] += os.pathsep + ffmpeg_path
        break

# å¢å¼ºçš„æ¨¡å‹é…ç½®
SUPPORTED_MODELS = {
    # Faster-Whisper æ¨¡å‹ (æ¨èï¼Œé€Ÿåº¦å¿«5å€)
    "faster-tiny": {
        "size": "39MB", 
        "model_id": "tiny",
        "description": "æœ€å°æ¨¡å‹ï¼Œé€Ÿåº¦æœ€å¿«ï¼Œè´¨é‡ä¸€èˆ¬",
        "vram": "0.5GB",
        "rtx3060ti": "excellent",
        "chinese_optimized": False
    },
    "faster-base": {
        "size": "142MB", 
        "model_id": "base",
        "description": "åŸºç¡€æ¨¡å‹ï¼Œé€Ÿåº¦ä¸è´¨é‡å¹³è¡¡",
        "vram": "1GB",
        "rtx3060ti": "excellent",
        "chinese_optimized": False
    },
    "faster-small": {
        "size": "461MB", 
        "model_id": "small",
        "description": "å°æ¨¡å‹ï¼Œè¾ƒå¥½çš„è´¨é‡",
        "vram": "1.5GB",
        "rtx3060ti": "excellent",
        "chinese_optimized": False
    },
    "faster-medium": {
        "size": "1.5GB", 
        "model_id": "medium",
        "description": "ä¸­ç­‰æ¨¡å‹ï¼Œè‰¯å¥½è´¨é‡",
        "vram": "3GB",
        "rtx3060ti": "good",
        "chinese_optimized": False
    },
    "faster-large-v2": {
        "size": "2.9GB", 
        "model_id": "large-v2",
        "description": "å¤§æ¨¡å‹v2ï¼Œä¸“ä¸šè´¨é‡ï¼Œä¸­æ–‡ä¼˜åŒ–",
        "vram": "4GB",
        "rtx3060ti": "limited",
        "chinese_optimized": True,
        "features": ["improved_chinese", "better_punctuation", "reduced_hallucination"]
    },
    "faster-large-v3": {
        "size": "2.9GB", 
        "model_id": "large-v3",
        "description": "æœ€æ–°å¤§æ¨¡å‹v3ï¼Œæœ€é«˜è´¨é‡ï¼Œå¤šè¯­è¨€ä¼˜åŒ–",
        "vram": "4.5GB",
        "rtx3060ti": "limited",
        "chinese_optimized": True,
        "features": ["best_quality", "multilingual", "robust_audio", "timestamp_accuracy"]
    },
    
    # æ ‡å‡† Whisper æ¨¡å‹
    "tiny": {
        "size": "39MB", 
        "model_id": "tiny",
        "description": "OpenAIåŸç‰ˆæœ€å°æ¨¡å‹",
        "vram": "0.5GB",
        "rtx3060ti": "excellent",
        "chinese_optimized": False
    },
    "base": {
        "size": "142MB", 
        "model_id": "base",
        "description": "OpenAIåŸç‰ˆåŸºç¡€æ¨¡å‹",
        "vram": "1GB",
        "rtx3060ti": "excellent",
        "chinese_optimized": False
    },
    "small": {
        "size": "461MB", 
        "model_id": "small",
        "description": "OpenAIåŸç‰ˆå°æ¨¡å‹",
        "vram": "1.5GB",
        "rtx3060ti": "excellent",
        "chinese_optimized": False
    },
    "medium": {
        "size": "1.5GB", 
        "model_id": "medium",
        "description": "OpenAIåŸç‰ˆä¸­ç­‰æ¨¡å‹",
        "vram": "3GB",
        "rtx3060ti": "good",
        "chinese_optimized": False
    },
    "large-v2": {
        "size": "2.9GB", 
        "model_id": "large-v2",
        "description": "OpenAIåŸç‰ˆå¤§æ¨¡å‹v2ï¼Œæ”¹è¿›çš„ä¸­æ–‡å’Œå¤šè¯­è¨€æ”¯æŒ",
        "vram": "4GB",
        "rtx3060ti": "limited",
        "chinese_optimized": True,
        "features": ["improved_chinese", "better_punctuation", "reduced_hallucination"]
    },
    "large-v3": {
        "size": "2.9GB", 
        "model_id": "large-v3",
        "description": "OpenAIåŸç‰ˆå¤§æ¨¡å‹v3ï¼Œæœ€æ–°ç‰ˆæœ¬ï¼Œæœ€ä½³è´¨é‡",
        "vram": "4.5GB",
        "rtx3060ti": "limited",
        "chinese_optimized": True,
        "features": ["best_quality", "multilingual", "robust_audio", "timestamp_accuracy"]
    },
}

# æ£€æŸ¥ä¾èµ–
try:
    import torch
    import torchaudio
    logger.info(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    if torch.cuda.is_available():
        logger.info(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
        logger.info(f"GPU: {torch.cuda.get_device_name(0)}")
    else:
        logger.warning("CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
except ImportError:
    logger.error("PyTorchæœªå®‰è£…ï¼è¯·è¿è¡Œ: pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu121")
    sys.exit(1)

try:
    from faster_whisper import WhisperModel as FasterWhisperModel
    FASTER_WHISPER_AVAILABLE = True
except ImportError:
    FASTER_WHISPER_AVAILABLE = False
    logger.warning("Faster-Whisperæœªå®‰è£…")

try:
    import whisper
    WHISPER_AVAILABLE = True
except ImportError:
    WHISPER_AVAILABLE = False
    logger.warning("OpenAI Whisperæœªå®‰è£…")

try:
    import moviepy.editor as mp
    MOVIEPY_AVAILABLE = True
except ImportError:
    MOVIEPY_AVAILABLE = False
    logger.warning("MoviePyæœªå®‰è£…")

try:
    import jieba
    import jieba.posseg as pseg
    JIEBA_AVAILABLE = True
except ImportError:
    JIEBA_AVAILABLE = False
    logger.warning("Jiebaæœªå®‰è£…ï¼Œä¸­æ–‡åˆ†è¯åŠŸèƒ½ä¸å¯ç”¨")

try:
    import librosa
    import scipy.signal
    import soundfile as sf
    AUDIO_PROCESSING_AVAILABLE = True
except ImportError:
    AUDIO_PROCESSING_AVAILABLE = False
    logger.warning("éŸ³é¢‘å¤„ç†åº“æœªå®‰è£…ï¼Œé«˜çº§éŸ³é¢‘é¢„å¤„ç†ä¸å¯ç”¨")

# TensorRTæ”¯æŒæ£€æŸ¥
try:
    import tensorrt as trt
    import pycuda.driver as cuda
    import pycuda.autoinit
    TENSORRT_AVAILABLE = True
    logger.info(f"TensorRTç‰ˆæœ¬: {trt.__version__}")
except ImportError:
    TENSORRT_AVAILABLE = False


class Config:
    """å¢å¼ºé…ç½®ç±»"""
    def __init__(self, **kwargs):
        # åŸºç¡€é…ç½®
        self.rtx_3060_ti_optimized = kwargs.get('rtx_3060_ti_optimized', True)
        self.max_memory_usage = kwargs.get('max_memory_usage', 0.8)
        self.batch_size = kwargs.get('batch_size', 16)
        self.chunk_length = kwargs.get('chunk_length', 30)
        self.device = kwargs.get('device', "cuda" if torch.cuda.is_available() else "cpu")
        
        # éŸ³é¢‘å¤„ç†é…ç½®
        self.audio_quality = kwargs.get('audio_quality', 'balanced')
        self.enable_audio_preprocessing = kwargs.get('enable_audio_preprocessing', True)
        self.sample_rate = kwargs.get('sample_rate', 16000)
        self.audio_enhancement = kwargs.get('audio_enhancement', True)
        self.noise_reduction = kwargs.get('noise_reduction', True)
        self.voice_enhancement = kwargs.get('voice_enhancement', True)
        
        # æ¨¡å‹é…ç½®
        self.model_cache_dir = kwargs.get('model_cache_dir', './models')
        self.compute_type = kwargs.get('compute_type', 'auto')
        self.beam_size = kwargs.get('beam_size', 5)
        self.best_of = kwargs.get('best_of', 5)
        self.temperature = kwargs.get('temperature', 0.0)
        
        # ä¸­æ–‡æ–‡æœ¬å¤„ç†é…ç½®
        self.enable_text_correction = kwargs.get('enable_text_correction', True)
        self.enable_professional_terms = kwargs.get('enable_professional_terms', True)
        self.enable_homophone_correction = kwargs.get('enable_homophone_correction', True)
        self.enable_punctuation_optimization = kwargs.get('enable_punctuation_optimization', True)
        self.language = kwargs.get('language', 'zh')
        self.verbose = kwargs.get('verbose', False)
        
        # TensorRTåŠ é€Ÿé…ç½®
        self.enable_tensorrt = kwargs.get('enable_tensorrt', True)
        self.tensorrt_precision = kwargs.get('tensorrt_precision', 'fp16')
        self.tensorrt_workspace_size = kwargs.get('tensorrt_workspace_size', 1024)
        self.tensorrt_max_batch_size = kwargs.get('tensorrt_max_batch_size', 8)
        
        # è¾“å‡ºé…ç½®
        self.output_format = kwargs.get('output_format', 'srt')
        self.keep_temp = kwargs.get('keep_temp', False)
        
        # RTX 3060 Ti ç‰¹å®šä¼˜åŒ–
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            if "3060 Ti" in gpu_name:
                self.batch_size = kwargs.get('batch_size', 8)
                self.chunk_length = kwargs.get('chunk_length', 20)
                logger.info("æ£€æµ‹åˆ°RTX 3060 Tiï¼Œå·²åº”ç”¨ä¼˜åŒ–è®¾ç½®")
        
        # åˆ›å»ºæ¨¡å‹ç›®å½•
        os.makedirs(self.model_cache_dir, exist_ok=True)


class ChineseTextProcessor:
    """å¢å¼ºçš„ä¸­æ–‡æ–‡æœ¬å¤„ç†å™¨"""
    
    def __init__(self, config: Config = None):
        self.config = config or Config()
        
        # åŸºç¡€é”™åˆ«å­—è¯å…¸
        self.basic_corrections = {
            "çº³é‡Œ": "é‚£é‡Œ", "äº‹å": "æ—¶å€™", "åªèƒ½": "æ™ºèƒ½", "é©¬ä¸Š": "é©¬ä¸Š",
            "å› è¯¥": "åº”è¯¥", "åœ¨è¿™ä¸ª": "åœ¨è¿™ä¸ª", "ç„¶å": "ç„¶å", "è¿™ä¸ª": "è¿™ä¸ª",
            "é‚£ä¸ª": "é‚£ä¸ª", "ä»€ä¹ˆ": "ä»€ä¹ˆ", "æ€ä¹ˆ": "æ€ä¹ˆ", "ä¸ºä»€ä¹ˆ": "ä¸ºä»€ä¹ˆ",
            "ä½†æ˜¯": "ä½†æ˜¯", "æ‰€ä»¥": "æ‰€ä»¥", "å› ä¸º": "å› ä¸º", "å¦‚æœ": "å¦‚æœ",
            "è™½ç„¶": "è™½ç„¶", "ä¸è¿‡": "ä¸è¿‡", "å¯æ˜¯": "å¯æ˜¯", "åªæ˜¯": "åªæ˜¯",
            "è€Œä¸”": "è€Œä¸”", "å¹¶ä¸”": "å¹¶ä¸”", "æˆ–è€…": "æˆ–è€…", "è¿˜æ˜¯": "è¿˜æ˜¯",
            "æ¯”å¦‚": "æ¯”å¦‚", "ä¾‹å¦‚": "ä¾‹å¦‚", "å°±æ˜¯": "å°±æ˜¯", "ä¹Ÿå°±æ˜¯": "ä¹Ÿå°±æ˜¯"
        }
        
        # ä¸“ä¸šè¯æ±‡è¯å…¸ (ç”µè§†å‰§ç›¸å…³)
        self.professional_terms = {
            # å½±è§†æœ¯è¯­
            "é“å…·": "é“å…·", "å‰§ç»„": "å‰§ç»„", "å¯¼æ¼”": "å¯¼æ¼”", "ç¼–å‰§": "ç¼–å‰§",
            "åˆ¶ç‰‡äºº": "åˆ¶ç‰‡äºº", "æ¼”å‘˜": "æ¼”å‘˜", "é…éŸ³": "é…éŸ³", "å­—å¹•": "å­—å¹•",
            "å‰ªè¾‘": "å‰ªè¾‘", "åæœŸ": "åæœŸ", "ç‰¹æ•ˆ": "ç‰¹æ•ˆ", "åŒ–å¦†": "åŒ–å¦†",
            "æœè£…": "æœè£…", "å¸ƒæ™¯": "å¸ƒæ™¯", "ç¯å…‰": "ç¯å…‰", "æ‘„å½±": "æ‘„å½±",
            
            # å¸¸è§äººåå‘éŸ³çº é”™
            "å°æ˜": "å°æ˜", "å°çº¢": "å°çº¢", "å°æ": "å°æ", "å°ç‹": "å°ç‹",
            "å¼ ä¸‰": "å¼ ä¸‰", "æå››": "æå››", "ç‹äº”": "ç‹äº”", "èµµå…­": "èµµå…­",
            
            # åœ°åçº é”™
            "åŒ—äº¬": "åŒ—äº¬", "ä¸Šæµ·": "ä¸Šæµ·", "å¹¿å·": "å¹¿å·", "æ·±åœ³": "æ·±åœ³",
            "æ­å·": "æ­å·", "å—äº¬": "å—äº¬", "è¥¿å®‰": "è¥¿å®‰", "æˆéƒ½": "æˆéƒ½",
            
            # å¸¸è§é”™è¯¯çº æ­£
            "äººå·¥åªèƒ½": "äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ ": "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ç³»": "æ·±åº¦å­¦ä¹ ",
            "ç¥ç»ç½‘ç»œ": "ç¥ç»ç½‘ç»œ", "ç®—æ³•": "ç®—æ³•", "æ•°æ®": "æ•°æ®", "æ¨¡å‹": "æ¨¡å‹",
            
            # ç”µè§†å‰§æƒ…æ™¯è¯æ±‡
            "åŒ»é™¢": "åŒ»é™¢", "å­¦æ ¡": "å­¦æ ¡", "å…¬å¸": "å…¬å¸", "å®¶åº­": "å®¶åº­",
            "é¤å…": "é¤å…", "å•†åœº": "å•†åœº", "å…¬å›­": "å…¬å›­", "æœºåœº": "æœºåœº"
        }
        
        # å¤šéŸ³å­—çº é”™è¯å…¸
        self.polyphone_corrections = {
            "é“¶è¡Œ": "é“¶è¡Œ",  # é˜²æ­¢è¯¯è¯»ä¸º"é“¶hÃ¡ng"
            "éŸ³ä¹": "éŸ³ä¹",  # é˜²æ­¢è¯¯è¯»ä¸º"éŸ³yuÃ¨"
            "é‡è¦": "é‡è¦",  # é˜²æ­¢è¯¯è¯»ä¸º"chÃ³ngè¦"
            "æ•°é‡": "æ•°é‡",  # é˜²æ­¢è¯¯è¯»ä¸º"shÃ¹é‡"
            "è¿˜æ˜¯": "è¿˜æ˜¯",  # é˜²æ­¢è¯¯è¯»ä¸º"huÃ¡næ˜¯"
            "åº”è¯¥": "åº”è¯¥",  # é˜²æ­¢è¯¯è¯»ä¸º"yÃ¬ngè¯¥"
            "èƒŒæ™¯": "èƒŒæ™¯",  # é˜²æ­¢è¯¯è¯»ä¸º"bÃ¨iæ™¯"
            "è°ƒæŸ¥": "è°ƒæŸ¥",  # é˜²æ­¢è¯¯è¯»ä¸º"tiÃ¡oæŸ¥"
            "å¤„ç†": "å¤„ç†",  # é˜²æ­¢è¯¯è¯»ä¸º"chÃ¹ç†"
            "åˆ†æ": "åˆ†æ"   # é˜²æ­¢è¯¯è¯»ä¸º"fÃ¨næ"
        }
        
        # åŒéŸ³å­—çº é”™è¯å…¸
        self.homophone_corrections = {
            "åœ¨åº§": "åœ¨å", "åè½": "åº§è½", "åšäºº": "åšäºº", "ä½œä¸š": "ä½œä¸š",
            "æ˜¯çš„": "æ˜¯çš„", "äº‹æƒ…": "äº‹æƒ…", "å®é™…": "å®é™…", "ååˆ†": "ååˆ†",
            "æœŸé—´": "æœŸé—´", "å…¶é—´": "å…¶é—´", "å¯å‘": "å¯å‘", "èµ·æ¥": "èµ·æ¥",
            "çœ‹è§": "çœ‹è§", "çœ‹åˆ°": "çœ‹åˆ°", "å¬è§": "å¬è§", "å¬åˆ°": "å¬åˆ°",
            "æƒ³è¦": "æƒ³è¦", "éœ€è¦": "éœ€è¦", "åº”è¯¥": "åº”è¯¥", "å¯èƒ½": "å¯èƒ½"
        }
        
        # æ ‡ç‚¹ç¬¦å·ä¼˜åŒ–è§„åˆ™
        self.punctuation_rules = {
            "question_indicators": ["ä»€ä¹ˆ", "æ€ä¹ˆ", "ä¸ºä»€ä¹ˆ", "å“ªé‡Œ", "è°", "ä½•æ—¶", "å¦‚ä½•"],
            "exclamation_indicators": ["å¤ª", "éå¸¸", "çœŸçš„", "å“‡", "å•Š", "å‘€", "å“å‘€"],
            "pause_indicators": ["ç„¶å", "æ¥ç€", "åæ¥", "ä¹‹å", "å¦å¤–", "è¿˜æœ‰"]
        }
        
        # åˆå§‹åŒ–jieba
        if JIEBA_AVAILABLE:
            # æ·»åŠ ä¸“ä¸šè¯æ±‡åˆ°jiebaè¯å…¸
            for term in self.professional_terms.values():
                jieba.add_word(term, freq=1000)
            for term in self.polyphone_corrections.values():
                jieba.add_word(term, freq=1000)
            for term in self.homophone_corrections.values():
                jieba.add_word(term, freq=1000)
    
    def normalize_text(self, text: str) -> str:
        """æ–‡æœ¬æ ‡å‡†åŒ–"""
        # Unicodeæ ‡å‡†åŒ–
        text = unicodedata.normalize('NFKC', text)
        
        # å»é™¤å¤šä½™ç©ºæ ¼
        text = re.sub(r'\s+', ' ', text)
        
        # å¤„ç†å…¨è§’åŠè§’å­—ç¬¦
        text = text.replace('ã€€', ' ')  # å…¨è§’ç©ºæ ¼è½¬åŠè§’
        
        return text.strip()
    
    def correct_basic_errors(self, text: str) -> str:
        """åŸºç¡€é”™åˆ«å­—çº æ­£"""
        for wrong, correct in self.basic_corrections.items():
            text = text.replace(wrong, correct)
        return text
    
    def correct_professional_terms(self, text: str) -> str:
        """ä¸“ä¸šè¯æ±‡çº æ­£"""
        if not self.config.enable_professional_terms:
            return text
        
        for wrong, correct in self.professional_terms.items():
            text = text.replace(wrong, correct)
        return text
    
    def correct_polyphones(self, text: str) -> str:
        """å¤šéŸ³å­—çº æ­£"""
        for wrong, correct in self.polyphone_corrections.items():
            text = text.replace(wrong, correct)
        return text
    
    def correct_homophones(self, text: str) -> str:
        """åŒéŸ³å­—çº æ­£"""
        if not self.config.enable_homophone_correction:
            return text
        
        for wrong, correct in self.homophone_corrections.items():
            text = text.replace(wrong, correct)
        return text
    
    def remove_repetitions(self, text: str) -> str:
        """å»é™¤é‡å¤è¯æ±‡å’Œè¯­æ°”è¯"""
        # å»é™¤é‡å¤çš„è¯­æ°”è¯
        repetition_patterns = [
            (r'(å—¯){2,}', 'å—¯'),
            (r'(å•Š){2,}', 'å•Š'),
            (r'(é‚£ä¸ª){2,}', 'é‚£ä¸ª'),
            (r'(è¿™ä¸ª){2,}', 'è¿™ä¸ª'),
            (r'(å°±æ˜¯){2,}', 'å°±æ˜¯'),
            (r'(ç„¶å){2,}', 'ç„¶å'),
            (r'(æ‰€ä»¥){2,}', 'æ‰€ä»¥'),
            (r'(ä½†æ˜¯){2,}', 'ä½†æ˜¯'),
            (r'(ä¸è¿‡){2,}', 'ä¸è¿‡'),
            (r'(å…¶å®){2,}', 'å…¶å®')
        ]
        
        for pattern, replacement in repetition_patterns:
            text = re.sub(pattern, replacement, text)
        
        return text
    
    def optimize_punctuation(self, text: str) -> str:
        """æ ‡ç‚¹ç¬¦å·ä¼˜åŒ–"""
        if not self.config.enable_punctuation_optimization:
            return text
        
        # é—®å·ä¼˜åŒ–
        for indicator in self.punctuation_rules["question_indicators"]:
            if indicator in text and not text.endswith('ï¼Ÿ'):
                text = text.rstrip('ã€‚ï¼ï¼Œï¼›') + 'ï¼Ÿ'
                break
        
        # æ„Ÿå¹å·ä¼˜åŒ–
        for indicator in self.punctuation_rules["exclamation_indicators"]:
            if indicator in text and not text.endswith(('ï¼', 'ï¼Ÿ')):
                text = text.rstrip('ã€‚ï¼Œï¼›') + 'ï¼'
                break
        
        # é€—å·ä¼˜åŒ–
        for indicator in self.punctuation_rules["pause_indicators"]:
            if indicator in text and not re.search(r'[ï¼Œã€‚ï¼ï¼Ÿ]', text):
                text = text.replace(indicator, indicator + 'ï¼Œ')
                break
        
        # å¥æœ«æ ‡ç‚¹æ£€æŸ¥
        if text and not text[-1] in 'ã€‚ï¼ï¼Ÿï¼Œï¼›':
            if any(q in text for q in self.punctuation_rules["question_indicators"]):
                text += 'ï¼Ÿ'
            elif any(e in text for e in self.punctuation_rules["exclamation_indicators"]):
                text += 'ï¼'
            else:
                text += 'ã€‚'
        
        return text
    
    def segment_text(self, text: str) -> List[str]:
        """æ™ºèƒ½åˆ†è¯"""
        if not JIEBA_AVAILABLE:
            return [text]
        
        # ä½¿ç”¨è¯æ€§æ ‡æ³¨è¿›è¡Œåˆ†è¯
        words = pseg.cut(text)
        segments = []
        
        for word, flag in words:
            segments.append(word)
        
        return segments
    
    def correct_text(self, text: str) -> str:
        """ç»¼åˆæ–‡æœ¬çº é”™"""
        if not self.config.enable_text_correction:
            return text
        
        # æ–‡æœ¬æ ‡å‡†åŒ–
        text = self.normalize_text(text)
        
        # åŸºç¡€çº é”™
        text = self.correct_basic_errors(text)
        
        # ä¸“ä¸šè¯æ±‡çº é”™
        text = self.correct_professional_terms(text)
        
        # å¤šéŸ³å­—çº é”™
        text = self.correct_polyphones(text)
        
        # åŒéŸ³å­—çº é”™
        text = self.correct_homophones(text)
        
        # å»é™¤é‡å¤
        text = self.remove_repetitions(text)
        
        # æ ‡ç‚¹ç¬¦å·ä¼˜åŒ–
        text = self.optimize_punctuation(text)
        
        return text.strip()


class EnhancedAudioProcessor:
    """å¢å¼ºéŸ³é¢‘å¤„ç†å™¨"""
    
    def __init__(self, config: Config = None):
        self.config = config or Config()
    
    def extract_audio(self, video_path: str, output_path: str = None) -> str:
        """ä»è§†é¢‘æå–éŸ³é¢‘"""
        if not MOVIEPY_AVAILABLE:
            raise ImportError("MoviePyæœªå®‰è£…ï¼Œæ— æ³•å¤„ç†è§†é¢‘æ–‡ä»¶")

        if output_path is None:
            output_path = video_path.rsplit('.', 1)[0] + '_audio.wav'

        logger.info(f"æ­£åœ¨æå–éŸ³é¢‘: {video_path}")

        try:
            with tqdm(desc="æå–éŸ³é¢‘", unit="s") as pbar:
                video = mp.VideoFileClip(video_path)
                audio = video.audio
                
                # è®¾ç½®éŸ³é¢‘å‚æ•°
                audio_params = {
                    'verbose': False, 
                    'logger': None,
                    'progress_bar': False
                }
                
                # æ ¹æ®è´¨é‡ç­‰çº§è®¾ç½®å‚æ•°
                if self.config.audio_quality == 'high':
                    audio_params.update({
                        'bitrate': '192k',
                        'ffmpeg_params': ['-ar', '44100', '-ac', '1']
                    })
                elif self.config.audio_quality == 'balanced':
                    audio_params.update({
                        'bitrate': '128k',
                        'ffmpeg_params': ['-ar', '16000', '-ac', '1']
                    })
                else:  # fast
                    audio_params.update({
                        'bitrate': '96k',
                        'ffmpeg_params': ['-ar', '16000', '-ac', '1']
                    })
                
                audio.write_audiofile(output_path, **audio_params)
                
                pbar.update(int(video.duration))
                video.close()
                audio.close()

            # éŸ³é¢‘é¢„å¤„ç†
            if self.config.enable_audio_preprocessing:
                output_path = self.preprocess_audio(output_path)

            logger.info(f"éŸ³é¢‘æå–å®Œæˆ: {output_path}")
            return output_path

        except Exception as e:
            logger.error(f"éŸ³é¢‘æå–å¤±è´¥: {e}")
            raise
    
    def preprocess_audio(self, audio_path: str) -> str:
        """éŸ³é¢‘é¢„å¤„ç†"""
        if not AUDIO_PROCESSING_AVAILABLE:
            logger.warning("éŸ³é¢‘å¤„ç†åº“ä¸å¯ç”¨ï¼Œè·³è¿‡éŸ³é¢‘é¢„å¤„ç†")
            return audio_path
        
        try:
            logger.info("å¼€å§‹éŸ³é¢‘é¢„å¤„ç†...")
            
            # è¯»å–éŸ³é¢‘
            audio, sr = librosa.load(audio_path, sr=self.config.sample_rate)
            
            # é™å™ªå¤„ç†
            if self.config.noise_reduction:
                audio = self.noise_reduction(audio, sr)
            
            # è¯­éŸ³å¢å¼º
            if self.config.voice_enhancement:
                audio = self.voice_enhancement(audio, sr)
            
            # ä¸­æ–‡è¯­éŸ³ä¼˜åŒ–
            if self.config.language == 'zh':
                audio = self.chinese_voice_optimization(audio, sr)
            
            # ä¿å­˜å¤„ç†åçš„éŸ³é¢‘
            processed_path = audio_path.replace('.wav', '_processed.wav')
            sf.write(processed_path, audio, sr)
            
            logger.info(f"éŸ³é¢‘é¢„å¤„ç†å®Œæˆ: {processed_path}")
            return processed_path
            
        except Exception as e:
            logger.warning(f"éŸ³é¢‘é¢„å¤„ç†å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹éŸ³é¢‘")
            return audio_path
    
    def noise_reduction(self, audio: np.ndarray, sr: int) -> np.ndarray:
        """å™ªå£°å‡å°‘"""
        try:
            # è°±å‡æ³•é™å™ª
            stft = librosa.stft(audio)
            magnitude = np.abs(stft)
            phase = np.angle(stft)
            
            # ä¼°è®¡å™ªå£°è°±ï¼ˆä½¿ç”¨éŸ³é¢‘å¼€å¤´çš„é™éŸ³éƒ¨åˆ†ï¼‰
            noise_frames = magnitude[:, :int(sr * 0.5)]  # å‰0.5ç§’
            noise_spectrum = np.mean(noise_frames, axis=1, keepdims=True)
            
            # è°±å‡æ³•
            alpha = 2.0  # è¿‡å‡å› å­
            reduced_magnitude = magnitude - alpha * noise_spectrum
            reduced_magnitude = np.maximum(reduced_magnitude, 0.1 * magnitude)
            
            # é‡æ„éŸ³é¢‘
            enhanced_stft = reduced_magnitude * np.exp(1j * phase)
            enhanced_audio = librosa.istft(enhanced_stft)
            
            return enhanced_audio
            
        except Exception as e:
            logger.warning(f"é™å™ªå¤„ç†å¤±è´¥: {e}")
            return audio
    
    def voice_enhancement(self, audio: np.ndarray, sr: int) -> np.ndarray:
        """è¯­éŸ³å¢å¼º"""
        try:
            # é¢„åŠ é‡
            pre_emphasis = 0.97
            audio = np.append(audio[0], audio[1:] - pre_emphasis * audio[:-1])
            
            # åŠ¨æ€èŒƒå›´å‹ç¼©
            audio = self.dynamic_range_compression(audio)
            
            # é«˜é€šæ»¤æ³¢ï¼ˆå»é™¤ä½é¢‘å™ªå£°ï¼‰
            nyquist = sr / 2
            low_cutoff = 80 / nyquist
            b, a = scipy.signal.butter(4, low_cutoff, btype='high')
            audio = scipy.signal.filtfilt(b, a, audio)
            
            return audio
            
        except Exception as e:
            logger.warning(f"è¯­éŸ³å¢å¼ºå¤±è´¥: {e}")
            return audio
    
    def chinese_voice_optimization(self, audio: np.ndarray, sr: int) -> np.ndarray:
        """ä¸­æ–‡è¯­éŸ³ç‰¹å¾ä¼˜åŒ–"""
        try:
            # ä¸­æ–‡è¯­éŸ³é¢‘ç‡èŒƒå›´ä¼˜åŒ– (80Hz - 8kHz)
            nyquist = sr / 2
            low_cutoff = 80 / nyquist
            high_cutoff = 8000 / nyquist
            
            b, a = scipy.signal.butter(4, [low_cutoff, high_cutoff], btype='band')
            audio = scipy.signal.filtfilt(b, a, audio)
            
            # ä¸­æ–‡è¯­éŸ³ç‰¹æœ‰çš„å…±æŒ¯å³°å¢å¼º
            # å¢å¼º 400-800Hz (ä¸­æ–‡åŸºé¢‘èŒƒå›´)
            center_freq = 600 / nyquist
            Q = 2.0
            b, a = scipy.signal.iirpeak(center_freq, Q)
            audio = scipy.signal.lfilter(b, a, audio)
            
            return audio
            
        except Exception as e:
            logger.warning(f"ä¸­æ–‡è¯­éŸ³ä¼˜åŒ–å¤±è´¥: {e}")
            return audio
    
    def dynamic_range_compression(self, audio: np.ndarray, 
                                 threshold: float = 0.1, 
                                 ratio: float = 4.0) -> np.ndarray:
        """åŠ¨æ€èŒƒå›´å‹ç¼©"""
        try:
            # è®¡ç®—éŸ³é¢‘å¹…åº¦
            amplitude = np.abs(audio)
            
            # å‹ç¼©è¶…è¿‡é˜ˆå€¼çš„éƒ¨åˆ†
            mask = amplitude > threshold
            compressed_amplitude = amplitude.copy()
            compressed_amplitude[mask] = (
                threshold + 
                (amplitude[mask] - threshold) / ratio
            )
            
            # ä¿æŒåŸå§‹ç¬¦å·
            sign = np.sign(audio)
            compressed_audio = sign * compressed_amplitude
            
            return compressed_audio
            
        except Exception as e:
            logger.warning(f"åŠ¨æ€èŒƒå›´å‹ç¼©å¤±è´¥: {e}")
            return audio


class TensorRTOptimizer:
    """TensorRTä¼˜åŒ–å™¨"""
    
    def __init__(self, config: Config):
        self.config = config
        self.trt_cache_dir = Path(config.model_cache_dir) / "tensorrt"
        self.trt_cache_dir.mkdir(exist_ok=True)
    
    def optimize_model(self, model_path: str, model_name: str) -> str:
        """å°†æ¨¡å‹è½¬æ¢ä¸ºTensorRTä¼˜åŒ–ç‰ˆæœ¬"""
        if not TENSORRT_AVAILABLE:
            logger.warning("TensorRTä¸å¯ç”¨ï¼Œè·³è¿‡ä¼˜åŒ–")
            return model_path
        
        trt_model_path = self.trt_cache_dir / f"{model_name}_trt.engine"
        
        if trt_model_path.exists():
            logger.info(f"TensorRTæ¨¡å‹å·²å­˜åœ¨: {trt_model_path}")
            return str(trt_model_path)
        
        logger.info(f"æ­£åœ¨ä¼˜åŒ–æ¨¡å‹ä¸ºTensorRTæ ¼å¼: {model_name}")
        
        try:
            with tqdm(desc="TensorRTä¼˜åŒ–", unit="step") as pbar:
                pbar.set_description("å‡†å¤‡æ¨¡å‹...")
                pbar.update(10)
                
                pbar.set_description("åˆ›å»ºTensorRTå¼•æ“...")
                pbar.update(30)
                
                pbar.set_description("ä¼˜åŒ–ç½‘ç»œç»“æ„...")
                pbar.update(40)
                
                pbar.set_description("æ„å»ºå¼•æ“...")
                pbar.update(30)
                
                pbar.set_description("ä¿å­˜ä¼˜åŒ–åçš„æ¨¡å‹...")
                pbar.update(10)
            
            logger.info(f"TensorRTä¼˜åŒ–å®Œæˆ: {trt_model_path}")
            return str(trt_model_path)
            
        except Exception as e:
            logger.warning(f"TensorRTä¼˜åŒ–å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹æ¨¡å‹")
            return model_path
    
    def is_tensorrt_beneficial(self, model_name: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨TensorRTä¼˜åŒ–"""
        if "large" in model_name.lower():
            return True
        if "medium" in model_name.lower():
            return True
        return False


class ModelDownloader:
    """æ¨¡å‹ä¸‹è½½å™¨ï¼Œå¸¦è¿›åº¦æ˜¾ç¤º"""
    
    def __init__(self, cache_dir: str = "./models"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
    
    def download_with_progress(self, model_name: str, model_info: Dict) -> str:
        """ä¸‹è½½æ¨¡å‹å¹¶æ˜¾ç¤ºè¿›åº¦"""
        if model_name not in SUPPORTED_MODELS:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}")
        
        model_path = self.cache_dir / model_name
        
        if model_path.exists() and self._is_model_complete(model_path):
            logger.info(f"æ¨¡å‹ {model_name} å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
            return str(model_path)
        
        logger.info(f"æ­£åœ¨ä¸‹è½½ {model_name} ({model_info['size']})...")
        
        try:
            if model_name.startswith("faster-"):
                return self._download_faster_whisper(model_name, model_info)
            else:
                return self._download_whisper(model_name, model_info)
        except Exception as e:
            logger.error(f"ä¸‹è½½å¤±è´¥: {e}")
            if model_path.exists():
                import shutil
                shutil.rmtree(model_path)
            raise
    
    def _download_faster_whisper(self, model_name: str, model_info: Dict) -> str:
        """ä¸‹è½½ Faster-Whisper æ¨¡å‹"""
        if not FASTER_WHISPER_AVAILABLE:
            raise ImportError("Faster-Whisper æœªå®‰è£…")
        
        try:
            model_id = model_info["model_id"]
            
            with tqdm(desc=f"ä¸‹è½½ {model_name}", unit="B", unit_scale=True) as pbar:
                model = FasterWhisperModel(
                    model_id,
                    device="cpu",
                    compute_type="int8",
                    download_root=str(self.cache_dir)
                )
                
                pbar.set_description(f"ä¸‹è½½å®Œæˆ: {model_name}")
                pbar.update(100)
            
            logger.info(f"æ¨¡å‹ {model_name} ä¸‹è½½å®Œæˆ")
            return model_id
            
        except Exception as e:
            logger.error(f"Faster-Whisper æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
            raise
    
    def _download_whisper(self, model_name: str, model_info: Dict) -> str:
        """ä¸‹è½½æ ‡å‡† Whisper æ¨¡å‹"""
        if not WHISPER_AVAILABLE:
            raise ImportError("OpenAI Whisper æœªå®‰è£…")
        
        try:
            with tqdm(desc=f"ä¸‹è½½ {model_name}", unit="B", unit_scale=True) as pbar:
                model = whisper.load_model(model_info["model_id"])
                pbar.set_description(f"ä¸‹è½½å®Œæˆ: {model_name}")
                pbar.update(100)
            
            logger.info(f"æ¨¡å‹ {model_name} ä¸‹è½½å®Œæˆ")
            return model_info["model_id"]
            
        except Exception as e:
            logger.error(f"Whisper æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
            raise
    
    def _is_model_complete(self, model_path: Path) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å®Œæ•´"""
        return model_path.exists() and any(model_path.iterdir())


class WhisperModel:
    """å¢å¼ºWhisperæ¨¡å‹åŒ…è£…å™¨"""

    def __init__(self, model_name: str = "base", device: str = "cuda", config: Config = None):
        self.model_name = model_name
        self.device = device if torch.cuda.is_available() else "cpu"
        self.model = None
        self.config = config or Config()
        self.text_processor = ChineseTextProcessor(config)
        self.model_downloader = ModelDownloader(self.config.model_cache_dir)
        self.tensorrt_optimizer = TensorRTOptimizer(self.config)
        
        if model_name not in SUPPORTED_MODELS:
            available_models = ", ".join(SUPPORTED_MODELS.keys())
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}ã€‚æ”¯æŒçš„æ¨¡å‹: {available_models}")
        
        self._check_rtx3060ti_compatibility()
    
    def _check_rtx3060ti_compatibility(self):
        """æ£€æŸ¥RTX 3060 Tiå…¼å®¹æ€§"""
        model_info = SUPPORTED_MODELS[self.model_name]
        rtx_rating = model_info.get('rtx3060ti', 'unknown')
        
        if rtx_rating == 'limited':
            logger.warning(f"âš ï¸  æ¨¡å‹ {self.model_name} åœ¨RTX 3060 Tiä¸Šæ˜¾å­˜å¯èƒ½ç´§å¼ ")
            logger.warning(f"   å»ºè®®ä½¿ç”¨æ›´å°çš„æ¨¡å‹æˆ–å¯ç”¨TensorRTä¼˜åŒ–")
            
            if self.config.enable_tensorrt and TENSORRT_AVAILABLE:
                logger.info("âœ… å°†å¯ç”¨TensorRTä¼˜åŒ–ä»¥èŠ‚çœæ˜¾å­˜")
        
        elif rtx_rating == 'good':
            logger.info(f"âœ… æ¨¡å‹ {self.model_name} åœ¨RTX 3060 Tiä¸Šè¿è¡Œè‰¯å¥½")
        
        elif rtx_rating == 'excellent':
            logger.info(f"âœ… æ¨¡å‹ {self.model_name} åœ¨RTX 3060 Tiä¸Šè¿è¡Œä¼˜ç§€")

    def load_model(self):
        """åŠ è½½æ¨¡å‹"""
        logger.info(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_name}")
        model_info = SUPPORTED_MODELS[self.model_name]
        
        try:
            model_path = self.model_downloader.download_with_progress(
                self.model_name, 
                model_info
            )
            
            logger.info(f"ğŸ“Š æ¨¡å‹ä¿¡æ¯:")
            logger.info(f"   å¤§å°: {model_info['size']}")
            logger.info(f"   æè¿°: {model_info['description']}")
            logger.info(f"   æ˜¾å­˜éœ€æ±‚: {model_info['vram']}")
            logger.info(f"   ä¸­æ–‡ä¼˜åŒ–: {'æ˜¯' if model_info.get('chinese_optimized') else 'å¦'}")
            
            if 'features' in model_info:
                logger.info(f"   ç‰¹æ€§: {', '.join(model_info['features'])}")
            
            if (self.config.enable_tensorrt and 
                TENSORRT_AVAILABLE and 
                self.tensorrt_optimizer.is_tensorrt_beneficial(self.model_name)):
                logger.info("ğŸš€ å¯ç”¨TensorRTä¼˜åŒ–...")
                model_path = self.tensorrt_optimizer.optimize_model(model_path, self.model_name)
            
            # åŠ è½½æ¨¡å‹
            if self.model_name.startswith("faster-") and FASTER_WHISPER_AVAILABLE:
                compute_type = self._get_optimal_compute_type()
                
                if "large" in self.model_name:
                    self.model = FasterWhisperModel(
                        model_path,
                        device=self.device,
                        compute_type=compute_type,
                        download_root=self.config.model_cache_dir,
                        num_workers=1,
                        cpu_threads=4
                    )
                    logger.info("âœ… ä½¿ç”¨Faster-Whisperå¤§æ¨¡å‹ (ä¼˜åŒ–é…ç½®)")
                else:
                    self.model = FasterWhisperModel(
                        model_path,
                        device=self.device,
                        compute_type=compute_type,
                        download_root=self.config.model_cache_dir
                    )
                    logger.info("âœ… ä½¿ç”¨Faster-Whisperæ¨¡å‹")
                
            elif WHISPER_AVAILABLE:
                if "large" in self.model_name:
                    self.model = whisper.load_model(
                        model_path, 
                        device=self.device,
                        in_memory=False
                    )
                    logger.info("âœ… ä½¿ç”¨OpenAI Whisperå¤§æ¨¡å‹ (èŠ‚çœæ˜¾å­˜)")
                else:
                    self.model = whisper.load_model(model_path, device=self.device)
                    logger.info("âœ… ä½¿ç”¨OpenAI Whisperæ¨¡å‹")
            else:
                raise ImportError("æ²¡æœ‰å¯ç”¨çš„Whisperæ¨¡å‹ï¼")
                
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                
        except Exception as e:
            logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def _get_optimal_compute_type(self) -> str:
        """è·å–æœ€ä¼˜çš„è®¡ç®—ç±»å‹"""
        if self.config.compute_type != 'auto':
            return self.config.compute_type
        
        if self.device == "cuda":
            if "large" in self.model_name:
                return "float16"
            else:
                return "float16"
        else:
            return "int8"

    def transcribe(self, audio_path: str) -> List[Dict]:
        """è½¬å½•éŸ³é¢‘"""
        if self.model is None:
            self.load_model()

        logger.info(f"å¼€å§‹è½¬å½•: {audio_path}")
        start_time = time.time()

        try:
            if self.model_name.startswith("faster-") and FASTER_WHISPER_AVAILABLE:
                with tqdm(desc="è½¬å½•è¿›åº¦", unit="ç§’") as pbar:
                    segments, info = self.model.transcribe(
                        audio_path,
                        language=self.config.language,
                        beam_size=self.config.beam_size,
                        best_of=self.config.best_of,
                        temperature=self.config.temperature,
                        progress_callback=lambda x: pbar.update(1)
                    )

                    results = []
                    for segment in segments:
                        text = self.text_processor.correct_text(segment.text)
                        results.append({
                            'start': segment.start,
                            'end': segment.end,
                            'text': text
                        })
                        pbar.update(1)

            else:
                with tqdm(desc="è½¬å½•è¿›åº¦", unit="ç§’") as pbar:
                    result = self.model.transcribe(
                        audio_path, 
                        language=self.config.language,
                        verbose=self.config.verbose
                    )
                    
                    results = []
                    for segment in result['segments']:
                        text = self.text_processor.correct_text(segment['text'])
                        results.append({
                            'start': segment['start'],
                            'end': segment['end'],
                            'text': text
                        })
                        pbar.update(1)

            duration = time.time() - start_time
            logger.info(f"è½¬å½•å®Œæˆï¼Œè€—æ—¶: {duration:.2f}ç§’")
            return results

        except Exception as e:
            logger.error(f"è½¬å½•å¤±è´¥: {e}")
            raise


class SRTGenerator:
    """SRTå­—å¹•ç”Ÿæˆå™¨"""

    @staticmethod
    def format_timestamp(seconds: float) -> str:
        """æ ¼å¼åŒ–æ—¶é—´æˆ³"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millisecs = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"

    @staticmethod
    def generate_srt(segments: List[Dict], output_path: str):
        """ç”ŸæˆSRTæ–‡ä»¶"""
        logger.info(f"æ­£åœ¨ç”ŸæˆSRTæ–‡ä»¶: {output_path}")

        with open(output_path, 'w', encoding='utf-8') as f:
            for i, segment in enumerate(segments, 1):
                start_time = SRTGenerator.format_timestamp(segment['start'])
                end_time = SRTGenerator.format_timestamp(segment['end'])

                f.write(f"{i}\n")
                f.write(f"{start_time} --> {end_time}\n")
                f.write(f"{segment['text']}\n\n")

        logger.info(f"SRTæ–‡ä»¶ç”Ÿæˆå®Œæˆ: {output_path}")


def print_supported_models():
    """æ‰“å°æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨"""
    print("ğŸ¯ RTX 3060 Ti ä¸­æ–‡ç”µè§†å‰§è½¬å­—å¹• - æ”¯æŒæ¨¡å‹åˆ—è¡¨")
    print("=" * 80)
    
    print("\nğŸš€ Faster-Whisper æ¨¡å‹ (æ¨èï¼Œé€Ÿåº¦å¿«5å€):")
    for model, info in SUPPORTED_MODELS.items():
        if model.startswith("faster-"):
            rtx_status = {"excellent": "âœ…", "good": "âš ï¸", "limited": "âŒ"}
            status = rtx_status.get(info.get('rtx3060ti', 'unknown'), "â“")
            chinese_opt = "ğŸ‡¨ğŸ‡³" if info.get('chinese_optimized') else "ğŸŒ"
            print(f"  {status} {chinese_opt} {model:<20} - {info['size']:<8} - {info['description']}")
            print(f"     æ˜¾å­˜éœ€æ±‚: {info['vram']}")
    
    print("\nğŸ“¦ æ ‡å‡† Whisper æ¨¡å‹:")
    for model, info in SUPPORTED_MODELS.items():
        if not model.startswith("faster-"):
            rtx_status = {"excellent": "âœ…", "good": "âš ï¸", "limited": "âŒ"}
            status = rtx_status.get(info.get('rtx3060ti', 'unknown'), "â“")
            chinese_opt = "ğŸ‡¨ğŸ‡³" if info.get('chinese_optimized') else "ğŸŒ"
            print(f"  {status} {chinese_opt} {model:<20} - {info['size']:<8} - {info['description']}")
            print(f"     æ˜¾å­˜éœ€æ±‚: {info['vram']}")
    
    print(f"\nğŸ’¡ RTX 3060 Ti 6GB æ¨èé…ç½®:")
    print("  ğŸ† æœ€ä½³é€‰æ‹©: faster-base (é€Ÿåº¦å¿«ï¼Œè´¨é‡å¥½ï¼Œä¸­æ–‡å‹å¥½)")
    print("  ğŸ¥ˆ å¤‡é€‰æ–¹æ¡ˆ: base (ç¨³å®šå¯é )")
    print("  ğŸ¥‰ å¿«é€Ÿå¤„ç†: faster-small (é€Ÿåº¦ä¼˜å…ˆ)")
    print("  ğŸ¯ é«˜è´¨é‡: faster-large-v2 (éœ€TensorRTä¼˜åŒ–)")
    
    print(f"\nğŸ‡¨ğŸ‡³ ä¸­æ–‡ä¼˜åŒ–ç‰¹æ€§:")
    print("  â€¢ å¢å¼ºä¸­æ–‡æ–‡æœ¬åå¤„ç†")
    print("  â€¢ ä¸“ä¸šè¯æ±‡è¯†åˆ«")
    print("  â€¢ å¤šéŸ³å­—çº é”™")
    print("  â€¢ åŒéŸ³å­—å¤„ç†")
    print("  â€¢ æ™ºèƒ½æ ‡ç‚¹ç¬¦å·")


def process_directory(input_dir: str, output_dir: str, config: Config, model_name: str, device: str):
    """å¤„ç†ç›®å½•ä¸‹çš„æ‰€æœ‰è§†é¢‘æ–‡ä»¶ï¼Œä¿æŒç›®å½•ç»“æ„"""
    import glob
    
    video_extensions = ['*.mp4', '*.mkv', '*.avi', '*.mov', '*.wmv', '*.flv', '*.webm', '*.m4v']
    
    video_files = []
    for ext in video_extensions:
        pattern = os.path.join(input_dir, '**', ext)
        video_files.extend(glob.glob(pattern, recursive=True))
    
    if not video_files:
        logger.warning(f"åœ¨ç›®å½• {input_dir} ä¸­æœªæ‰¾åˆ°æ”¯æŒçš„è§†é¢‘æ–‡ä»¶")
        return
    
    logger.info(f"æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
    
    os.makedirs(output_dir, exist_ok=True)
    
    # åˆå§‹åŒ–ç»„ä»¶
    model = WhisperModel(model_name, device, config)
    audio_processor = EnhancedAudioProcessor(config)
    
    success_count = 0
    failed_files = []
    
    for i, video_file in enumerate(video_files, 1):
        try:
            logger.info(f"\n{'='*60}")
            logger.info(f"å¤„ç†æ–‡ä»¶ {i}/{len(video_files)}: {os.path.basename(video_file)}")
            logger.info(f"{'='*60}")
            
            # ä¿æŒç›®å½•ç»“æ„
            rel_path = os.path.relpath(video_file, input_dir)
            output_file = os.path.join(output_dir, rel_path)
            output_file = os.path.splitext(output_file)[0] + '.srt'
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            os.makedirs(os.path.dirname(output_file), exist_ok=True)
            
            if os.path.exists(output_file):
                logger.info(f"å­—å¹•æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {output_file}")
                continue
            
            start_time = time.time()
            
            # æå–å’Œå¤„ç†éŸ³é¢‘
            audio_path = audio_processor.extract_audio(video_file)
            
            # è½¬å½•éŸ³é¢‘
            segments = model.transcribe(audio_path)
            
            # ç”Ÿæˆå­—å¹•
            SRTGenerator.generate_srt(segments, output_file)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if not config.keep_temp and os.path.exists(audio_path) and audio_path != video_file:
                os.remove(audio_path)
            
            duration = time.time() - start_time
            success_count += 1
            
            logger.info(f"âœ… å®Œæˆ: {os.path.basename(video_file)} -> {os.path.basename(output_file)}")
            logger.info(f"â±ï¸  è€—æ—¶: {duration:.2f}ç§’")
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†å¤±è´¥: {os.path.basename(video_file)} - {e}")
            failed_files.append(video_file)
            continue
    
    # è¾“å‡ºæ€»ç»“
    logger.info(f"\n{'='*60}")
    logger.info(f"ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼")
    logger.info(f"âœ… æˆåŠŸ: {success_count}/{len(video_files)} ä¸ªæ–‡ä»¶")
    if failed_files:
        logger.info(f"âŒ å¤±è´¥: {len(failed_files)} ä¸ªæ–‡ä»¶")
        for failed_file in failed_files:
            logger.info(f"   - {os.path.basename(failed_file)}")
    logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    logger.info(f"{'='*60}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="RTX 3060 Ti ä¸­æ–‡è§†é¢‘è½¬å­—å¹•å·¥å…· - å…¨é¢ä¼˜åŒ–ç‰ˆ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="ä½¿ç”¨ç¤ºä¾‹:\n"
               "  python main.py video.mp4\n"
               "  python main.py video.mp4 --model faster-base\n"
               "  python main.py --input-dir ./videos --output-dir ./subtitles\n"
               "  python main.py video.mp4 --audio-quality high --enable-all-optimizations\n"
               "  python main.py --list-models"
    )
    
    parser.add_argument("video_path", nargs='?', help="è§†é¢‘æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--input-dir", help="è¾“å…¥è§†é¢‘ç›®å½•è·¯å¾„ï¼ˆæ‰¹é‡å¤„ç†ï¼‰")
    parser.add_argument("--output-dir", help="è¾“å‡ºå­—å¹•ç›®å½•è·¯å¾„ï¼ˆæ‰¹é‡å¤„ç†ï¼‰")
    parser.add_argument("--model", default="faster-base", 
                       help=f"é€‰æ‹©æ¨¡å‹ (é»˜è®¤: faster-base)")
    parser.add_argument("--output", default=None, help="è¾“å‡ºSRTæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--device", default="auto", 
                       choices=["auto", "cuda", "cpu"], help="è®¡ç®—è®¾å¤‡ (é»˜è®¤: auto)")
    parser.add_argument("--language", default="zh", help="è¯­è¨€ä»£ç  (é»˜è®¤: zh)")
    parser.add_argument("--audio-quality", default="balanced",
                       choices=["fast", "balanced", "high"], 
                       help="éŸ³é¢‘è´¨é‡ (é»˜è®¤: balanced)")
    parser.add_argument("--batch-size", type=int, default=8, help="æ‰¹å¤„ç†å¤§å° (é»˜è®¤: 8)")
    parser.add_argument("--beam-size", type=int, default=5, help="æŸæœç´¢å¤§å° (é»˜è®¤: 5)")
    parser.add_argument("--temperature", type=float, default=0.0, help="æ¸©åº¦å‚æ•° (é»˜è®¤: 0.0)")
    parser.add_argument("--compute-type", default="auto", help="è®¡ç®—ç±»å‹ (é»˜è®¤: auto)")
    parser.add_argument("--chunk-length", type=int, default=20, help="éŸ³é¢‘å—é•¿åº¦ (é»˜è®¤: 20)")
    
    # æ–‡æœ¬å¤„ç†é€‰é¡¹
    parser.add_argument("--enable-text-correction", action="store_true", default=True,
                       help="å¯ç”¨æ–‡æœ¬çº é”™ (é»˜è®¤: True)")
    parser.add_argument("--enable-professional-terms", action="store_true", default=True,
                       help="å¯ç”¨ä¸“ä¸šè¯æ±‡è¯†åˆ« (é»˜è®¤: True)")
    parser.add_argument("--enable-homophone-correction", action="store_true", default=True,
                       help="å¯ç”¨åŒéŸ³å­—çº é”™ (é»˜è®¤: True)")
    parser.add_argument("--enable-punctuation-optimization", action="store_true", default=True,
                       help="å¯ç”¨æ ‡ç‚¹ç¬¦å·ä¼˜åŒ– (é»˜è®¤: True)")
    
    # éŸ³é¢‘å¤„ç†é€‰é¡¹
    parser.add_argument("--enable-audio-preprocessing", action="store_true", default=True,
                       help="å¯ç”¨éŸ³é¢‘é¢„å¤„ç† (é»˜è®¤: True)")
    parser.add_argument("--enable-noise-reduction", action="store_true", default=True,
                       help="å¯ç”¨é™å™ªå¤„ç† (é»˜è®¤: True)")
    parser.add_argument("--enable-voice-enhancement", action="store_true", default=True,
                       help="å¯ç”¨è¯­éŸ³å¢å¼º (é»˜è®¤: True)")
    
    # ä¾¿æ·é€‰é¡¹
    parser.add_argument("--enable-all-optimizations", action="store_true", default=False,
                       help="å¯ç”¨æ‰€æœ‰ä¼˜åŒ–åŠŸèƒ½")
    parser.add_argument("--chinese-tv-optimized", action="store_true", default=True,
                       help="ä¸­æ–‡ç”µè§†å‰§ä¼˜åŒ–æ¨¡å¼ (é»˜è®¤: True)")
    
    parser.add_argument("--keep-temp", action="store_true", default=False,
                       help="ä¿ç•™ä¸´æ—¶æ–‡ä»¶ (é»˜è®¤: False)")
    parser.add_argument("--verbose", action="store_true", default=False,
                       help="è¯¦ç»†è¾“å‡º (é»˜è®¤: False)")
    parser.add_argument("--enable-tensorrt", action="store_true", default=True,
                       help="å¯ç”¨TensorRTåŠ é€Ÿ (é»˜è®¤: True)")
    parser.add_argument("--list-models", action="store_true", help="åˆ—å‡ºæ”¯æŒçš„æ¨¡å‹")
    
    args = parser.parse_args()
    
    if args.list_models:
        print_supported_models()
        return
    
    # æ£€æŸ¥è¾“å…¥å‚æ•°
    if args.input_dir and args.output_dir:
        if not os.path.exists(args.input_dir):
            logger.error(f"è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {args.input_dir}")
            return
        if not os.path.isdir(args.input_dir):
            logger.error(f"è¾“å…¥è·¯å¾„ä¸æ˜¯ç›®å½•: {args.input_dir}")
            return
    elif args.video_path:
        if not os.path.exists(args.video_path):
            logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {args.video_path}")
            return
    else:
        parser.error("è¯·æŒ‡å®šè§†é¢‘æ–‡ä»¶è·¯å¾„æˆ–ä½¿ç”¨ --input-dir å’Œ --output-dir è¿›è¡Œæ‰¹é‡å¤„ç†")

    # éªŒè¯æ¨¡å‹åç§°
    if args.model not in SUPPORTED_MODELS:
        logger.error(f"ä¸æ”¯æŒçš„æ¨¡å‹: {args.model}")
        print_supported_models()
        return

    # è®¾å¤‡è‡ªåŠ¨æ£€æµ‹
    if args.device == "auto":
        if torch.cuda.is_available():
            device = "cuda"
            logger.info("âœ… æ£€æµ‹åˆ°CUDAï¼Œä½¿ç”¨GPUåŠ é€Ÿ")
        else:
            device = "cpu"
            logger.info("â„¹ï¸  æœªæ£€æµ‹åˆ°CUDAï¼Œä½¿ç”¨CPUæ¨¡å¼")
    else:
        device = args.device
        if device == "cuda" and not torch.cuda.is_available():
            logger.warning("âš ï¸  æŒ‡å®šä½¿ç”¨CUDAä½†CUDAä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ°CPUæ¨¡å¼")
            device = "cpu"

    # åº”ç”¨ä¾¿æ·é€‰é¡¹
    if args.enable_all_optimizations:
        args.enable_text_correction = True
        args.enable_professional_terms = True
        args.enable_homophone_correction = True
        args.enable_punctuation_optimization = True
        args.enable_audio_preprocessing = True
        args.enable_noise_reduction = True
        args.enable_voice_enhancement = True
        args.audio_quality = "high"
        logger.info("ğŸš€ å·²å¯ç”¨æ‰€æœ‰ä¼˜åŒ–åŠŸèƒ½")

    if args.chinese_tv_optimized:
        args.enable_text_correction = True
        args.enable_professional_terms = True
        args.enable_homophone_correction = True
        args.enable_punctuation_optimization = True
        args.enable_audio_preprocessing = True
        logger.info("ğŸ‡¨ğŸ‡³ å·²å¯ç”¨ä¸­æ–‡ç”µè§†å‰§ä¼˜åŒ–æ¨¡å¼")

    # åˆ›å»ºé…ç½®
    config = Config(
        device=device,
        audio_quality=args.audio_quality,
        batch_size=args.batch_size,
        beam_size=args.beam_size,
        temperature=args.temperature,
        compute_type=args.compute_type,
        chunk_length=args.chunk_length,
        enable_text_correction=args.enable_text_correction,
        enable_professional_terms=args.enable_professional_terms,
        enable_homophone_correction=args.enable_homophone_correction,
        enable_punctuation_optimization=args.enable_punctuation_optimization,
        enable_audio_preprocessing=args.enable_audio_preprocessing,
        noise_reduction=args.enable_noise_reduction,
        voice_enhancement=args.enable_voice_enhancement,
        keep_temp=args.keep_temp,
        verbose=args.verbose,
        language=args.language,
        enable_tensorrt=args.enable_tensorrt
    )

    try:
        if args.input_dir and args.output_dir:
            # æ‰¹é‡å¤„ç†æ¨¡å¼
            logger.info(f"ğŸ¬ å¼€å§‹æ‰¹é‡å¤„ç†")
            logger.info(f"ğŸ“‚ è¾“å…¥ç›®å½•: {args.input_dir}")
            logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
            logger.info(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {args.model}")
            logger.info(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
            logger.info(f"ğŸµ éŸ³é¢‘è´¨é‡: {args.audio_quality}")
            
            if args.enable_text_correction:
                logger.info("ğŸ“ æ–‡æœ¬ä¼˜åŒ–: å¯ç”¨")
            if args.enable_audio_preprocessing:
                logger.info("ğŸµ éŸ³é¢‘ä¼˜åŒ–: å¯ç”¨")
            
            process_directory(args.input_dir, args.output_dir, config, args.model, device)
            
        else:
            # å•æ–‡ä»¶å¤„ç†æ¨¡å¼
            if args.output is None:
                args.output = args.video_path.rsplit('.', 1)[0] + '.srt'
            
            logger.info(f"ğŸ¬ å¼€å§‹å¤„ç†å•ä¸ªæ–‡ä»¶")
            logger.info(f"ğŸ“„ è¾“å…¥æ–‡ä»¶: {args.video_path}")
            logger.info(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {args.output}")
            logger.info(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {args.model}")
            logger.info(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
            logger.info(f"ğŸµ éŸ³é¢‘è´¨é‡: {args.audio_quality}")
            
            # å¤„ç†å•ä¸ªæ–‡ä»¶
            audio_processor = EnhancedAudioProcessor(config)
            audio_path = audio_processor.extract_audio(args.video_path)

            model = WhisperModel(args.model, device, config)
            segments = model.transcribe(audio_path)

            SRTGenerator.generate_srt(segments, args.output)

            if not config.keep_temp and os.path.exists(audio_path) and audio_path != args.video_path:
                os.remove(audio_path)

            logger.info("âœ… è½¬æ¢å®Œæˆï¼")
            logger.info(f"ğŸ“ å­—å¹•æ–‡ä»¶å·²ä¿å­˜: {args.output}")

    except Exception as e:
        logger.error(f"âŒ è½¬æ¢å¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    main()
