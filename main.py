import os
import sys
import time
import torch
import argparse
import traceback
import subprocess
import platform
from datetime import timedelta
from typing import List, Dict, Any, Optional
import logging
import re
import numpy as np
import soundfile as sf
import gc
from tqdm import tqdm
import psutil
import json
from text_postprocessor import TextPostProcessor

# é…ç½®æ—¥å¿— - ä¿®å¤Windowsç¼–ç é—®é¢˜
import locale
import sys

# è®¾ç½®æ§åˆ¶å°ç¼–ç ä¸ºUTF-8
if sys.platform.startswith('win'):
    try:
        # å°è¯•è®¾ç½®æ§åˆ¶å°ä¸ºUTF-8
        import io
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
    except:
        pass

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler("video_subtitle.log", encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# æ›¿æ¢emojiå­—ç¬¦ä»¥é¿å…ç¼–ç é—®é¢˜
def safe_log_message(message):
    """å®‰å…¨çš„æ—¥å¿—æ¶ˆæ¯ï¼Œæ›¿æ¢å¯èƒ½å¯¼è‡´ç¼–ç é—®é¢˜çš„å­—ç¬¦"""
    emoji_map = {
        'ğŸ¬': '[VIDEO]',
        'ğŸ¤–': '[MODEL]', 
        'ğŸ’»': '[DEVICE]',
        'âœ…': '[OK]',
        'âŒ': '[ERROR]',
        'âš ï¸': '[WARNING]',
        'ğŸš€': '[START]',
        'ğŸ”„': '[LOADING]',
        'ğŸ“Š': '[INFO]',
        'ğŸ§¹': '[CLEANUP]',
        'ğŸ—‘ï¸': '[DELETE]',
        'ğŸ“': '[SAVE]',
        'ğŸ¯': '[TARGET]',
        'ğŸ”': '[CHECK]',
        'âœ¨': '[ENHANCE]',
        'ğŸ‰': '[SUCCESS]'
    }
    for emoji, replacement in emoji_map.items():
        message = message.replace(emoji, replacement)
    return message

# é‡å†™loggeræ–¹æ³•
original_info = logger.info
original_warning = logger.warning
original_error = logger.error

def safe_info(message, *args, **kwargs):
    return original_info(safe_log_message(str(message)), *args, **kwargs)

def safe_warning(message, *args, **kwargs):
    return original_warning(safe_log_message(str(message)), *args, **kwargs)

def safe_error(message, *args, **kwargs):
    return original_error(safe_log_message(str(message)), *args, **kwargs)

logger.info = safe_info
logger.warning = safe_warning
logger.error = safe_error

# è®¾ç½®CUDAç¯å¢ƒå˜é‡ä¼˜åŒ–RTX 3060 Ti
os.environ['CUDA_LAZY_LOADING'] = '1'
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True,garbage_collection_threshold:0.8'
os.environ['CUDA_VISIBLE_DEVICES'] = '0'

# å°è¯•å¯¼å…¥ä¾èµ–
try:
    import whisper
    from faster_whisper import WhisperModel
    WHISPER_AVAILABLE = True
except ImportError:
    WHISPER_AVAILABLE = False
    logger.warning("Whisperåº“æœªå®‰è£…")

try:
    from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline
    HF_AVAILABLE = True
except ImportError:
    HF_AVAILABLE = False
    logger.warning("Transformersåº“æœªå®‰è£…")

try:
    import tensorrt as trt
    import pycuda.driver as cuda
    import pycuda.autoinit
    TENSORRT_AVAILABLE = True
except ImportError:
    TENSORRT_AVAILABLE = False
    logger.warning("TensorRTä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨PyTorchåŠ é€Ÿ")

try:
    from moviepy.editor import VideoFileClip
    MOVIEPY_AVAILABLE = True
except ImportError:
    MOVIEPY_AVAILABLE = False
    logger.warning("MoviePyæœªå®‰è£…ï¼Œå°†ä½¿ç”¨FFmpegå¤„ç†éŸ³é¢‘")

# æ–°å¢FunASRå¯¼å…¥
try:
    from funasr import AutoModel
    FUNASR_AVAILABLE = True
    logger.info("FunASRåº“å¯¼å…¥æˆåŠŸ")
except ImportError:
    FUNASR_AVAILABLE = False
    AutoModel = None
    logger.warning("æœªæ‰¾åˆ°FunASRåº“ï¼Œè¯·ç¡®ä¿å·²å®‰è£…: pip install funasr")

class Config:
    """é…ç½®ç®¡ç†ç±»"""
    def __init__(self):
        self.config_file = "config.json"
        self.load_config()

    def load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        default_config = {
            "models_path": "./models",
            "temp_path": "./temp",
            "output_path": "./output",
            "gpu_memory_fraction": 0.85,
            "batch_size": 4,
            "max_segment_length": 30,
            "preferred_model": "faster-base",
            "use_tensorrt": True,
            "audio_sample_rate": 16000
        }

        if os.path.exists(self.config_file):
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    # åˆå¹¶é»˜è®¤é…ç½®å’Œç”¨æˆ·é…ç½®
                    for key, value in default_config.items():
                        if key not in config:
                            config[key] = value
                    self.config = config
            except Exception as e:
                logger.warning(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
                self.config = default_config
        else:
            self.config = default_config
            self.save_config()

    def save_config(self):
        """ä¿å­˜é…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(self.config, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"é…ç½®æ–‡ä»¶ä¿å­˜å¤±è´¥: {e}")

    def get(self, key, default=None):
        return self.config.get(key, default)

    def set(self, key, value):
        self.config[key] = value
        self.save_config()

class Timer:
    """è®¡æ—¶å™¨ç±»"""
    def __init__(self, name="ä»»åŠ¡"):
        self.name = name

    def __enter__(self):
        self.start_time = time.time()
        print(f"ğŸš€ å¼€å§‹ {self.name}...")
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        end_time = time.time()
        duration = end_time - self.start_time
        print(f"âœ… {self.name} å®Œæˆï¼Œè€—æ—¶: {duration:.2f} ç§’")

class ProgressTracker:
    """è¿›åº¦è·Ÿè¸ªå™¨"""
    def __init__(self, total_steps=100, description="å¤„ç†ä¸­"):
        self.total_steps = total_steps
        self.current_step = 0
        self.description = description
        self.pbar = tqdm(total=total_steps, desc=description, unit="step")

    def update(self, steps=1, description=None):
        if description:
            self.pbar.set_description(description)
        self.pbar.update(steps)
        self.current_step += steps

    def set_progress(self, current, total=None, description=None):
        if total:
            self.pbar.total = total
        if description:
            self.pbar.set_description(description)
        self.pbar.n = current
        self.pbar.refresh()

    def close(self):
        self.pbar.close()

class RTX3060TiOptimizer:
    """RTX 3060 Tiæ˜¾å¡ä¼˜åŒ–å™¨"""

    @staticmethod
    def setup_gpu_memory(memory_fraction=0.85):
        """é…ç½®GPUæ˜¾å­˜ç®¡ç†"""
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            try:
                total_memory = torch.cuda.get_device_properties(0).total_memory
                max_memory = int(total_memory * memory_fraction)
                torch.cuda.set_per_process_memory_fraction(memory_fraction)
                logger.info(f"GPUæ˜¾å­˜ä¼˜åŒ–å®Œæˆï¼Œæ€»æ˜¾å­˜: {total_memory/1024**3:.1f}GBï¼Œé¢„ç•™ä½¿ç”¨: {max_memory/1024**3:.1f}GB")
            except Exception as e:
                logger.warning(f"æ˜¾å­˜ä¼˜åŒ–å¤±è´¥: {e}")

    @staticmethod
    def get_optimal_batch_size():
        """è·å–æœ€ä¼˜æ‰¹å¤„ç†å¤§å°"""
        if torch.cuda.is_available():
            total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            if total_memory > 5.5:  # 6GBæ˜¾å¡
                return 4
            else:
                return 2
        return 1

class SystemChecker:
    """ç³»ç»Ÿæ£€æŸ¥å™¨"""
    @staticmethod
    def check_cuda():
        """æ£€æŸ¥CUDAç¯å¢ƒ"""
        if not torch.cuda.is_available():
            logger.error("âŒ CUDAä¸å¯ç”¨ï¼è¯·æ£€æŸ¥NVIDIAé©±åŠ¨å’ŒCUDAå®‰è£…")
            return False

        cuda_version = torch.version.cuda
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3

        logger.info(f"âœ… CUDAç‰ˆæœ¬: {cuda_version}")
        logger.info(f"âœ… GPU: {gpu_name}")
        logger.info(f"âœ… GPUæ˜¾å­˜: {gpu_memory:.2f} GB")

        if "3060 Ti" in gpu_name:
            logger.info("ğŸ¯ æ£€æµ‹åˆ°RTX 3060 Tiï¼Œå·²å¯ç”¨ä¼˜åŒ–é…ç½®")
            RTX3060TiOptimizer.setup_gpu_memory()

        return True

    @staticmethod
    def check_dependencies():
        """æ£€æŸ¥ä¾èµ–æ˜¯å¦å®‰è£…"""
        deps = {
            "torch": True,
            "whisper": WHISPER_AVAILABLE,
            "transformers": HF_AVAILABLE,
            "tensorrt": TENSORRT_AVAILABLE,
            "moviepy": MOVIEPY_AVAILABLE
        }

        missing = [name for name, available in deps.items() if not available]
        if missing:
            logger.warning(f"âš ï¸ å¯é€‰ä¾èµ–ç¼ºå¤±: {', '.join(missing)}")

        required = ["torch", "whisper"]
        missing_required = [name for name in required if not deps.get(name, False)]
        if missing_required:
            logger.error(f"âŒ ç¼ºå°‘å¿…éœ€ä¾èµ–: {', '.join(missing_required)}")
            return False
        return True

class ModelWrapper:
    """æ¨¡å‹åŒ…è£…åŸºç±»"""
    def __init__(self, model_id: str, device: str = "cuda", config: Config = None, **kwargs):
        self.model_id = model_id
        self.device = device
        self.config = config or Config()
        self.kwargs = kwargs
        self.model = None
        self.progress_tracker = None

    def load_model(self):
        raise NotImplementedError

    def transcribe(self, audio_path: str, **kwargs) -> Dict[str, Any]:
        raise NotImplementedError

    def get_gpu_memory_usage(self) -> float:
        """è·å–GPUæ˜¾å­˜ä½¿ç”¨é‡ï¼ˆMBï¼‰"""
        if torch.cuda.is_available():
            return torch.cuda.memory_allocated() / 1024 / 1024
        return 0.0

class WhisperModelWrapper(ModelWrapper):
    """Whisperæ¨¡å‹åŒ…è£…"""
    def load_model(self) -> None:
        """åŠ è½½æ¨¡å‹"""
        try:
            self.progress_tracker = ProgressTracker(100, f"åŠ è½½{self.model_id}æ¨¡å‹")

            if self.device == "cuda" and torch.cuda.is_available():
                RTX3060TiOptimizer.setup_gpu_memory(self.config.get('gpu_memory_fraction', 0.85))

            models_path = self.config.get('models_path', './models')
            os.makedirs(models_path, exist_ok=True)

            self.progress_tracker.update(20, "ä¸‹è½½æ¨¡å‹æ–‡ä»¶...")

            if self.model_id in ["faster-base", "faster-large"]:
                model_mapping = {
                    "faster-base": "base",
                    "faster-large": "large"
                }
                actual_model = model_mapping[self.model_id]
                logger.info(f"ğŸ”„ åŠ è½½Faster-Whisperæ¨¡å‹: {self.model_id} -> {actual_model}")

                self.progress_tracker.update(30, "åˆå§‹åŒ–Faster-Whisper...")
                self.model = WhisperModel(
                    actual_model,
                    device=self.device,
                    compute_type="float16" if self.device == "cuda" else "int8",
                    cpu_threads=4,
                    download_root=models_path
                )
            else:
                logger.info(f"ğŸ”„ åŠ è½½æ ‡å‡†Whisperæ¨¡å‹: {self.model_id}")
                self.progress_tracker.update(30, "åˆå§‹åŒ–Whisper...")
                import whisper
                self.model = whisper.load_model(self.model_id, download_root=models_path)

                if self.device == "cuda":
                    self.model = self.model.cuda()

            self.progress_tracker.update(50, "æ¨¡å‹åŠ è½½å®Œæˆ")
            self.progress_tracker.close()
            logger.info(f"âœ… æ¨¡å‹ {self.model_id} åŠ è½½æˆåŠŸ")

        except Exception as e:
            if self.progress_tracker:
                self.progress_tracker.close()
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise

    def transcribe(self, audio_path: str, **kwargs) -> Dict[str, Any]:
        """è½¬å½•éŸ³é¢‘"""
        try:
            progress = ProgressTracker(100, "éŸ³é¢‘è½¬å½•ä¸­")

            if self.model_id in ["faster-base", "faster-large"]:
                progress.update(10, "å¼€å§‹Faster-Whisperè½¬å½•...")
                segments, info = self.model.transcribe(
                    audio_path,
                    language="zh",
                    beam_size=1,
                    best_of=1,
                    temperature=0.0,
                    compression_ratio_threshold=2.4,
                    log_prob_threshold=-1.0,
                    no_speech_threshold=0.6,
                    condition_on_previous_text=False,
                    vad_filter=True,
                    vad_parameters=dict(min_silence_duration_ms=500)
                )

                progress.update(60, "å¤„ç†è½¬å½•ç»“æœ...")
                result = {
                    "text": "",
                    "segments": [],
                    "language": info.language
                }

                for i, segment in enumerate(segments):
                    result["segments"].append({
                        "start": segment.start,
                        "end": segment.end,
                        "text": segment.text.strip()
                    })
                    result["text"] += segment.text.strip() + " "
                    if i % 10 == 0:
                        progress.update(2, f"å¤„ç†ç‰‡æ®µ {i+1}")

            else:
                progress.update(10, "å¼€å§‹æ ‡å‡†Whisperè½¬å½•...")
                result = self.model.transcribe(
                    audio_path,
                    language="zh",
                    fp16=torch.cuda.is_available(),
                    verbose=False
                )
                progress.update(80, "è½¬å½•å®Œæˆ")

            progress.close()
            return result

        except Exception as e:
            logger.error(f"âŒ è½¬å½•å¤±è´¥: {e}")
            raise

class FunASRModelWrapper(ModelWrapper):
    """FunASRæ¨¡å‹åŒ…è£… - RTX 3060 Tiä¼˜åŒ–ç‰ˆ"""
    def load_model(self) -> None:
        """åŠ è½½æ¨¡å‹"""
        try:
            self.progress_tracker = ProgressTracker(100, f"åŠ è½½FunASRæ¨¡å‹")
            
            # å¼ºåˆ¶å†…å­˜æ¸…ç†
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                # ä¸ºFunASRæ¨¡å‹è®¾ç½®æ›´ä¿å®ˆçš„æ˜¾å­˜å ç”¨
                RTX3060TiOptimizer.setup_gpu_memory(0.7)  # é™ä½åˆ°70%

            models_path = self.config.get('models_path', './models')
            os.makedirs(models_path, exist_ok=True)

            self.progress_tracker.update(20, "ä¸‹è½½FunASRæ¨¡å‹æ–‡ä»¶...")

            # ä½¿ç”¨è¾ƒå°çš„FunASRæ¨¡å‹ï¼Œé€‚é…RTX 3060 Ti
            model_mapping = {
                "funasr-paraformer": "damo/speech_paraformer_asr-zh-cn-16k-common-vocab8404-onnx",  # ä½¿ç”¨ONNXç‰ˆæœ¬ï¼Œå†…å­˜å ç”¨æ›´å°
                "funasr-conformer": "damo/speech_conformer_asr_nat-zh-cn-16k-common-vocab8404-pytorch"
            }
            
            actual_model = model_mapping.get(self.model_id, model_mapping["funasr-paraformer"])
            
            self.progress_tracker.update(30, "åˆå§‹åŒ–FunASR...")
            
            # ä¸ºRTX 3060 Tiä¼˜åŒ–çš„å‚æ•°
            model_kwargs = {
                "model": actual_model,
                "cache_dir": models_path,
                "disable_update": True,
                "model_revision": "v2.0.4"  # ä½¿ç”¨ç¨³å®šç‰ˆæœ¬
            }
            
            # åªåœ¨æ˜¾å­˜å……è¶³æ—¶ä½¿ç”¨GPU
            if self.device == "cuda" and torch.cuda.is_available():
                available_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
                if available_memory >= 5.0:  # è‡³å°‘5GBå¯ç”¨æ˜¾å­˜
                    model_kwargs["device"] = "cuda"
                else:
                    logger.warning("æ˜¾å­˜ä¸è¶³ï¼ŒFunASRå°†ä½¿ç”¨CPUæ¨¡å¼")
                    model_kwargs["device"] = "cpu"
                    self.device = "cpu"
            else:
                model_kwargs["device"] = "cpu"
                self.device = "cpu"
            
            self.model = AutoModel(**model_kwargs)

            self.progress_tracker.update(50, "æ¨¡å‹åŠ è½½å®Œæˆ")
            self.progress_tracker.close()
            logger.info(f"[OK] FunASRæ¨¡å‹ {self.model_id} åŠ è½½æˆåŠŸï¼Œè¿è¡Œè®¾å¤‡: {self.device}")

        except Exception as e:
            if self.progress_tracker:
                self.progress_tracker.close()
            logger.error(f"[ERROR] FunASRæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            # å°è¯•é™çº§åˆ°CPUæ¨¡å¼
            if self.device == "cuda":
                logger.info("å°è¯•ä½¿ç”¨CPUæ¨¡å¼é‡æ–°åŠ è½½...")
                self.device = "cpu"
                try:
                    self.model = AutoModel(
                        model="damo/speech_paraformer_asr-zh-cn-16k-common-vocab8404-onnx",
                        device="cpu",
                        cache_dir=models_path,
                        disable_update=True
                    )
                    logger.info("[OK] FunASRæ¨¡å‹å·²åœ¨CPUæ¨¡å¼ä¸‹åŠ è½½æˆåŠŸ")
                except Exception as cpu_e:
                    logger.error(f"[ERROR] CPUæ¨¡å¼ä¹Ÿå¤±è´¥: {cpu_e}")
                    raise
            else:
                raise

    def transcribe(self, audio_path: str, **kwargs) -> Dict[str, Any]:
        """è½¬å½•éŸ³é¢‘ - RTX 3060 Tiä¼˜åŒ–ç‰ˆ"""
        try:
            progress = ProgressTracker(100, "FunASRéŸ³é¢‘è½¬å½•ä¸­")

            progress.update(10, "å¼€å§‹FunASRè½¬å½•...")
            
            # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶å¤§å°ï¼Œå¦‚æœå¤ªå¤§åˆ™åˆ†æ®µå¤„ç†
            file_size_mb = os.path.getsize(audio_path) / (1024 * 1024)
            if file_size_mb > 100:  # å¤§äº100MBçš„éŸ³é¢‘æ–‡ä»¶åˆ†æ®µå¤„ç†
                logger.info(f"éŸ³é¢‘æ–‡ä»¶è¾ƒå¤§({file_size_mb:.1f}MB)ï¼Œå°†åˆ†æ®µå¤„ç†ä»¥èŠ‚çœå†…å­˜")
                return self._transcribe_large_file(audio_path, progress)
            
            # å¼ºåˆ¶å†…å­˜æ¸…ç†
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            # FunASRè½¬å½• - ä½¿ç”¨ä¿å®ˆçš„å‚æ•°
            result = self.model.generate(
                input=audio_path,
                cache={},
                language="zh",
                use_itn=True,
                batch_size_s=60,  # å‡å°æ‰¹å¤„ç†å¤§å°ï¼Œé™ä½å†…å­˜å ç”¨
                batch_size=1     # å•ä¸ªæ‰¹æ¬¡å¤„ç†
            )

            progress.update(60, "å¤„ç†è½¬å½•ç»“æœ...")
            
            # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            formatted_result = {
                "text": "",
                "segments": [],
                "language": "zh"
            }

            if result and len(result) > 0:
                for i, res in enumerate(result):
                    text = res.get("text", "")
                    if text:
                        # FunASRé€šå¸¸è¿”å›æ•´æ®µæ–‡æœ¬ï¼Œéœ€è¦æ‰‹åŠ¨åˆ†æ®µ
                        start_time = i * 30.0  # å‡è®¾æ¯æ®µ30ç§’
                        end_time = (i + 1) * 30.0
                        
                        formatted_result["segments"].append({
                            "start": start_time,
                            "end": end_time,
                            "text": text.strip()
                        })
                        formatted_result["text"] += text.strip() + " "
                        
                        # æ¯å¤„ç†10ä¸ªç‰‡æ®µæ¸…ç†ä¸€æ¬¡å†…å­˜
                        if i % 10 == 0:
                            gc.collect()

            progress.close()
            
            # è½¬å½•å®Œæˆåæ¸…ç†å†…å­˜
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                
            return formatted_result

        except Exception as e:
            logger.error(f"[ERROR] FunASRè½¬å½•å¤±è´¥: {e}")
            # å†…å­˜ä¸è¶³æ—¶çš„é”™è¯¯å¤„ç†
            if "out of memory" in str(e).lower() or "cuda" in str(e).lower():
                logger.warning("æ˜¾å­˜ä¸è¶³ï¼Œå°è¯•åˆ‡æ¢åˆ°CPUæ¨¡å¼...")
                try:
                    # é‡æ–°åŠ è½½ä¸ºCPUæ¨¡å¼
                    self.device = "cpu"
                    self.load_model()
                    return self.transcribe(audio_path, **kwargs)
                except Exception as cpu_e:
                    logger.error(f"[ERROR] CPUæ¨¡å¼ä¹Ÿå¤±è´¥: {cpu_e}")
            raise
    
    def _transcribe_large_file(self, audio_path: str, progress: ProgressTracker) -> Dict[str, Any]:
        """åˆ†æ®µå¤„ç†å¤§éŸ³é¢‘æ–‡ä»¶"""
        try:
            import librosa
            
            # åŠ è½½éŸ³é¢‘å¹¶åˆ†æ®µ
            audio, sr = librosa.load(audio_path, sr=16000)
            duration = len(audio) / sr
            segment_length = 300  # 5åˆ†é’Ÿä¸€æ®µ
            
            formatted_result = {
                "text": "",
                "segments": [],
                "language": "zh"
            }
            
            progress.update(20, f"åˆ†æ®µå¤„ç†éŸ³é¢‘ï¼Œæ€»æ—¶é•¿: {duration:.1f}ç§’")
            
            for start_sec in range(0, int(duration), segment_length):
                end_sec = min(start_sec + segment_length, duration)
                
                # æå–éŸ³é¢‘æ®µ
                start_sample = int(start_sec * sr)
                end_sample = int(end_sec * sr)
                segment_audio = audio[start_sample:end_sample]
                
                # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
                temp_path = f"temp_segment_{start_sec}.wav"
                sf.write(temp_path, segment_audio, sr)
                
                try:
                    # è½¬å½•è¯¥æ®µ
                    segment_result = self.model.generate(
                        input=temp_path,
                        cache={},
                        language="zh",
                        use_itn=True,
                        batch_size_s=60,
                        batch_size=1
                    )
                    
                    if segment_result and len(segment_result) > 0:
                        for res in segment_result:
                            text = res.get("text", "")
                            if text:
                                formatted_result["segments"].append({
                                    "start": start_sec,
                                    "end": end_sec,
                                    "text": text.strip()
                                })
                                formatted_result["text"] += text.strip() + " "
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶å’Œå†…å­˜
                    os.remove(temp_path)
                    gc.collect()
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                        
                except Exception as e:
                    logger.warning(f"æ®µ {start_sec}-{end_sec} å¤„ç†å¤±è´¥: {e}")
                    if os.path.exists(temp_path):
                        os.remove(temp_path)
                
                progress.update(60 * (end_sec - start_sec) / duration, f"å¤„ç†è¿›åº¦: {end_sec:.0f}/{duration:.0f}ç§’")
            
            return formatted_result
            
        except Exception as e:
            logger.error(f"[ERROR] å¤§æ–‡ä»¶åˆ†æ®µå¤„ç†å¤±è´¥: {e}")
            raise

class VideoSubtitleExtractor:
    """è§†é¢‘å­—å¹•æå–å™¨"""
    def __init__(self, model_id: str = "faster-base", device: str = "cuda", config: Config = None, **kwargs):
        self.config = config or Config()
        self.device = device
        self.kwargs = kwargs

        # æ£€æŸ¥ç³»ç»Ÿ
        if not SystemChecker.check_cuda():
            self.device = "cpu"
            logger.warning("âš ï¸ CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPUæ¨¡å¼")

        # åˆå§‹åŒ–æ¨¡å‹
        self.model_wrapper = self._create_model(model_id)

    def _create_model(self, model_id: str):
        """åˆ›å»ºæ¨¡å‹å®ä¾‹"""
        if model_id in ["tiny", "base", "small", "medium", "large", "faster-base", "faster-large"]:
            return WhisperModelWrapper(model_id, self.device, self.config, **self.kwargs)
        elif model_id in ["funasr-paraformer", "funasr-conformer"]:
            if not FUNASR_AVAILABLE:
                raise ValueError("FunASRåº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install funasr")
            return FunASRModelWrapper(model_id, self.device, self.config, **self.kwargs)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_id}")

    def extract_audio(self, video_path: str, audio_path: str = None) -> Optional[str]:
        """ä»è§†é¢‘æå–éŸ³é¢‘"""
        if not audio_path:
            base_name = os.path.splitext(os.path.basename(video_path))[0]
            temp_path = self.config.get('temp_path', './temp')
            os.makedirs(temp_path, exist_ok=True)
            audio_path = os.path.join(temp_path, f"{base_name}_audio.wav")

        if not os.path.exists(video_path):
            logger.error(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            return None

        try:
            progress = ProgressTracker(100, "æå–éŸ³é¢‘")

            with Timer("éŸ³é¢‘æå–"):
                progress.update(10, "æ£€æŸ¥è§†é¢‘æ–‡ä»¶...")

                if MOVIEPY_AVAILABLE:
                    progress.update(20, "ä½¿ç”¨MoviePyæå–éŸ³é¢‘...")
                    video = VideoFileClip(video_path)
                    audio = video.audio
                    progress.update(30, "å†™å…¥éŸ³é¢‘æ–‡ä»¶...")
                    audio.write_audiofile(
                        audio_path, 
                        fps=self.config.get('audio_sample_rate', 16000), 
                        verbose=False, 
                        logger=None
                    )
                    progress.update(30, "æ¸…ç†èµ„æº...")
                    video.close()
                    audio.close()
                else:
                    progress.update(20, "ä½¿ç”¨FFmpegæå–éŸ³é¢‘...")
                    cmd = [
                        "ffmpeg", "-y", "-i", video_path,
                        "-vn", "-acodec", "pcm_s16le", 
                        "-ar", str(self.config.get('audio_sample_rate', 16000)), 
                        "-ac", "1", audio_path
                    ]
                    subprocess.run(cmd, check=True, capture_output=True)
                    progress.update(60, "éŸ³é¢‘æå–å®Œæˆ")

                progress.update(10, "éªŒè¯éŸ³é¢‘æ–‡ä»¶...")
                if os.path.exists(audio_path):
                    file_size = os.path.getsize(audio_path) / 1024 / 1024
                    progress.close()
                    logger.info(f"âœ… éŸ³é¢‘æå–æˆåŠŸ: {audio_path} ({file_size:.1f}MB)")
                    return audio_path
                else:
                    progress.close()
                    logger.error("âŒ éŸ³é¢‘æå–å¤±è´¥")
                    return None

        except Exception as e:
            logger.error(f"âŒ éŸ³é¢‘æå–å‡ºé”™: {e}")
            return None

    def transcribe_audio(self, audio_path: str, **kwargs) -> Dict[str, Any]:
        """è½¬å½•éŸ³é¢‘"""
        if not os.path.exists(audio_path):
            logger.error(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
            return {"segments": [], "language": None}

        try:
            # åŠ è½½æ¨¡å‹
            if self.model_wrapper.model is None:
                self.model_wrapper.load_model()

            with Timer("éŸ³é¢‘è½¬å½•"):
                result = self.model_wrapper.transcribe(audio_path, **kwargs)
                segment_count = len(result.get('segments', []))
                logger.info(f"âœ… è½¬å½•å®Œæˆï¼Œè¯†åˆ«åˆ° {segment_count} ä¸ªç‰‡æ®µ")

                if self.device == "cuda":
                    memory_usage = self.model_wrapper.get_gpu_memory_usage()
                    logger.info(f"ğŸ“Š è½¬å½•åæ˜¾å­˜ä½¿ç”¨: {memory_usage:.1f}MB")

                return result

        except Exception as e:
            logger.error(f"âŒ éŸ³é¢‘è½¬å½•å¤±è´¥: {e}")
            return {"segments": [], "language": None}

    def create_srt_file(self, segments: List[Dict], output_path: str = "output.srt", enable_postprocess: bool = True) -> str:
        """åˆ›å»ºSRTå­—å¹•æ–‡ä»¶"""
        try:
            progress = ProgressTracker(len(segments) + 10, "ç”Ÿæˆå­—å¹•æ–‡ä»¶")

            output_dir = self.config.get('output_path', './output')
            os.makedirs(output_dir, exist_ok=True)

            if not output_path.startswith(output_dir):
                output_path = os.path.join(output_dir, os.path.basename(output_path))

            # åˆå§‹åŒ–æ–‡æœ¬åå¤„ç†å™¨
            if enable_postprocess:
                progress.update(5, "åˆå§‹åŒ–æ–‡æœ¬åå¤„ç†å™¨...")
                postprocessor = TextPostProcessor()

                # ç»Ÿè®¡åŸå§‹é”™è¯¯
                total_text = " ".join([seg["text"] for seg in segments])
                original_stats = postprocessor.get_correction_stats(total_text)
                logger.info(f"ğŸ” æ£€æµ‹åˆ°æ½œåœ¨é”™è¯¯: ä¸“ä¸šåè¯ {original_stats['professional_terms']} å¤„, "
                          f"å¤šéŸ³å­— {original_stats['polyphone_errors']} å¤„, "
                          f"æ•°å­—å•ä½ {original_stats['number_units']} å¤„")

            with open(output_path, "w", encoding="utf-8") as f:
                for i, segment in enumerate(segments, 1):
                    start_time = self._format_time(segment["start"])
                    end_time = self._format_time(segment["end"])
                    text = segment["text"].strip()

                    # åº”ç”¨æ–‡æœ¬åå¤„ç†
                    if enable_postprocess:
                        corrected_text = postprocessor.post_process(text)
                        if corrected_text != text:
                            logger.debug(f"ç‰‡æ®µ {i} æ–‡æœ¬çº é”™: '{text}' -> '{corrected_text}'")
                        text = corrected_text

                    f.write(f"{i}\n")
                    f.write(f"{start_time} --> {end_time}\n")
                    f.write(f"{text}\n\n")

                    progress.update(1, f"å†™å…¥ç‰‡æ®µ {i}/{len(segments)}")

            # ä¿å­˜åŸå§‹ç‰ˆæœ¬ï¼ˆå¯é€‰ï¼‰
            if enable_postprocess:
                progress.update(3, "ä¿å­˜åŸå§‹ç‰ˆæœ¬...")
                original_path = output_path.replace(".srt", "_original.srt")
                with open(original_path, "w", encoding="utf-8") as f:
                    for i, segment in enumerate(segments, 1):
                        start_time = self._format_time(segment["start"])
                        end_time = self._format_time(segment["end"])
                        text = segment["text"].strip()
                        f.write(f"{i}\n")
                        f.write(f"{start_time} --> {end_time}\n")
                        f.write(f"{text}\n\n")
                logger.info(f"ğŸ“ åŸå§‹å­—å¹•ä¿å­˜è‡³: {original_path}")

            progress.update(2, "å®Œæˆå­—å¹•ç”Ÿæˆ...")
            progress.close()
            logger.info(f"âœ… SRTæ–‡ä»¶ä¿å­˜æˆåŠŸ: {output_path}")

            if enable_postprocess:
                logger.info("ğŸ¯ æ–‡æœ¬åå¤„ç†åŠŸèƒ½å·²å¯ç”¨ï¼Œä¸“ä¸šåè¯å’Œå¤šéŸ³å­—é”™è¯¯å·²è‡ªåŠ¨ä¿®æ­£")

            return output_path

        except Exception as e:
            logger.error(f"âŒ SRTæ–‡ä»¶åˆ›å»ºå¤±è´¥: {e}")
            return None

    def _format_time(self, seconds: float) -> str:
        """æ ¼å¼åŒ–æ—¶é—´ä¸ºSRTæ ¼å¼"""
        hours, remainder = divmod(seconds, 3600)
        minutes, seconds = divmod(remainder, 60)
        milliseconds = int((seconds - int(seconds)) * 1000)
        return f"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d},{milliseconds:03d}"

    def cleanup(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶å’Œæ˜¾å­˜"""
        try:
            temp_path = self.config.get('temp_path', './temp')
            if os.path.exists(temp_path):
                temp_files = [f for f in os.listdir(temp_path) if f.endswith("_audio.wav")]
                for file in temp_files:
                    file_path = os.path.join(temp_path, file)
                    try:
                        os.remove(file_path)
                        logger.info(f"ğŸ—‘ï¸ åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {file}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥ {file}: {e}")

            # æ¸…ç†GPUæ˜¾å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                gc.collect()
                logger.info("ğŸ§¹ GPUæ˜¾å­˜æ¸…ç†å®Œæˆ")

        except Exception as e:
            logger.warning(f"âš ï¸ æ¸…ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")

def main():
    parser = argparse.ArgumentParser(description="ä¸­æ–‡ç”µè§†å‰§éŸ³é¢‘è½¬æ–‡å­—å·¥å…· - RTX 3060 Tiä¼˜åŒ–ç‰ˆ")
    parser.add_argument("video_path", nargs='?', default="test.mp4", help="è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output", "-o", default="output.srt", help="è¾“å‡ºå­—å¹•æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--model", "-m", default="faster-base",
                        choices=["tiny", "base", "small", "medium", "large", "faster-base", "faster-large", 
                                "funasr-paraformer", "funasr-conformer"],
                        help="æ¨¡å‹é€‰æ‹© (æ¨èRTX 3060 Tiä½¿ç”¨faster-baseæˆ–funasr-paraformer)")
    parser.add_argument("--device", "-d", default="cuda", choices=["cuda", "cpu"], help="è¿è¡Œè®¾å¤‡")
    parser.add_argument("--language", "-l", default="zh", help="è¯­è¨€è®¾ç½®")
    parser.add_argument("--keep-temp", action="store_true", help="ä¿ç•™ä¸´æ—¶æ–‡ä»¶")
    parser.add_argument("--config", "-c", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--no-postprocess", action="store_true", help="ç¦ç”¨æ–‡æœ¬åå¤„ç†")
    parser.add_argument("--add-term", nargs=2, metavar=('CORRECT', 'WRONG'), 
                        help="æ·»åŠ è‡ªå®šä¹‰çº é”™è¯æ±‡: --add-term 'æ­£ç¡®è¯' 'é”™è¯¯è¯'")

    args = parser.parse_args()

    # åŠ è½½é…ç½®
    config = Config()
    if args.config and os.path.exists(args.config):
        config.config_file = args.config
        config.load_config()

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.video_path):
        logger.error(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {args.video_path}")
        return

    # æ£€æŸ¥ä¾èµ–
    if not SystemChecker.check_dependencies():
        logger.error("âŒ è¯·å…ˆè¿è¡Œinstall_dependencies.batå®‰è£…ç¼ºå°‘çš„ä¾èµ–")
        return

    logger.info(f"ğŸ¬ å¼€å§‹å¤„ç†è§†é¢‘: {args.video_path}")
    logger.info(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {args.model}")
    logger.info(f"ğŸ’» è¿è¡Œè®¾å¤‡: {args.device}")

    if args.model in ["medium", "large"] and args.device == "cuda":
        logger.warning("[WARNING] RTX 3060 Tiæ˜¾å­˜å¯èƒ½ä¸è¶³ä»¥è¿è¡Œmedium/largeæ¨¡å‹ï¼Œå»ºè®®ä½¿ç”¨faster-base")
    
    if args.model in ["funasr-paraformer", "funasr-conformer"]:
        logger.warning("[WARNING] FunASRæ¨¡å‹å†…å­˜å ç”¨è¾ƒå¤§ï¼Œå¦‚é‡åˆ°å†…å­˜ä¸è¶³è¯·è€ƒè™‘ä½¿ç”¨faster-baseæ¨¡å‹")
        # æ£€æŸ¥å¯ç”¨å†…å­˜
        memory = psutil.virtual_memory()
        if memory.available < 4 * 1024**3:  # å°äº4GBå¯ç”¨å†…å­˜
            logger.warning(f"[WARNING] å¯ç”¨å†…å­˜ä¸è¶³({memory.available/1024**3:.1f}GB)ï¼Œå»ºè®®å…³é—­å…¶ä»–ç¨‹åºæˆ–ä½¿ç”¨smalleræ¨¡å‹")

    extractor = None
    try:
        # åˆ›å»ºæå–å™¨
        extractor = VideoSubtitleExtractor(
            model_id=args.model,
            device=args.device,
            config=config
        )

        # æå–éŸ³é¢‘
        audio_path = extractor.extract_audio(args.video_path)
        if not audio_path:
            logger.error("âŒ éŸ³é¢‘æå–å¤±è´¥")
            return

        # è½¬å½•éŸ³é¢‘
        result = extractor.transcribe_audio(
            audio_path,
            language=args.language,
            temperature=0.0
        )

        if not result["segments"]:
            logger.warning("âš ï¸ æœªè¯†åˆ«åˆ°ä»»ä½•è¯­éŸ³å†…å®¹")
            return

        # åˆ›å»ºå­—å¹•æ–‡ä»¶
        enable_postprocess = not args.no_postprocess
        srt_path = extractor.create_srt_file(result["segments"], args.output, enable_postprocess)
        if srt_path:
            logger.info(f"ğŸ‰ å­—å¹•æå–å®Œæˆï¼æ–‡ä»¶ä¿å­˜è‡³: {srt_path}")
            logger.info(f"ğŸ“ å…±è¯†åˆ«åˆ° {len(result['segments'])} ä¸ªå­—å¹•ç‰‡æ®µ")
            if enable_postprocess:
                logger.info("âœ¨ å·²åº”ç”¨æ™ºèƒ½æ–‡æœ¬çº é”™")
        else:
            logger.error("âŒ å­—å¹•æ–‡ä»¶åˆ›å»ºå¤±è´¥")

        # å¤„ç†è‡ªå®šä¹‰è¯æ±‡æ·»åŠ 
        if args.add_term:
            from text_postprocessor import TextPostProcessor
            postprocessor = TextPostProcessor()
            postprocessor.add_custom_term(args.add_term[0], [args.add_term[1]])
            logger.info(f"âœ… å·²æ·»åŠ è‡ªå®šä¹‰çº é”™è¯æ±‡: {args.add_term[0]} <- {args.add_term[1]}")

    except Exception as e:
        logger.error(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        traceback.print_exc()

    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶å’Œæ˜¾å­˜
        try:
            if extractor is not None and not args.keep_temp:
                extractor.cleanup()
        except Exception as e:
            logger.warning(f"âš ï¸ æ¸…ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")

if __name__ == "__main__":
    main()