import os
import sys
import time
import torch
import argparse
import traceback
import subprocess
import platform
from datetime import timedelta
from typing import List, Dict, Any, Optional
import logging
import re
import numpy as np
import soundfile as sf
import gc
from tqdm import tqdm
import psutil
import json
from text_postprocessor import TextPostProcessor
from audio_preprocessor import AdvancedAudioPreprocessor
from model_manager import ModelManager

# è®¾ç½®FFmpegè·¯å¾„
os.environ["PATH"] += os.pathsep + r"D:\code\ffmpeg\bin"

# TensorRTå’Œä¼˜åŒ–åº“æ”¯æŒ
TENSORRT_AVAILABLE = True
try:
    import tensorrt as trt
    import pycuda.driver as cuda
    import pycuda.autoinit
    logger.info("TensorRTä¼˜åŒ–å¼•æ“å°±ç»ª")
except ImportError as e:
    TENSORRT_AVAILABLE = False
    logger.warning(f"TensorRTä¸å¯ç”¨: {e}")

# é…ç½®æ—¥å¿—ç³»ç»Ÿ
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler("video_subtitle.log", encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# æ›¿æ¢emojiå­—ç¬¦ä»¥é¿å…ç¼–ç é—®é¢˜
def safe_log_message(message):
    """å®‰å…¨çš„æ—¥å¿—æ¶ˆæ¯ï¼Œæ›¿æ¢å¯èƒ½å¯¼è‡´ç¼–ç é—®é¢˜çš„å­—ç¬¦"""
    emoji_map = {
        'ğŸ¬': '[VIDEO]',
        'ğŸ¤–': '[MODEL]',
        'ğŸ’»': '[DEVICE]',
        'âœ…': '[OK]',
        'âŒ': '[ERROR]',
        'âš ï¸': '[WARNING]',
        'ğŸš€': '[START]',
        'ğŸ”„': '[LOADING]',
        'ğŸ“Š': '[INFO]',
        'ğŸ§¹': '[CLEANUP]',
        'ğŸ—‘ï¸': '[DELETE]',
        'ğŸ“': '[SAVE]',
        'ğŸ¯': '[TARGET]',
        'ğŸ”': '[CHECK]',
        'âœ¨': '[ENHANCE]',
        'ğŸ‰': '[SUCCESS]'
    }
    for emoji, replacement in emoji_map.items():
        message = message.replace(emoji, replacement)
    return message

# é‡å†™loggeræ–¹æ³•
original_info = logger.info
original_warning = logger.warning
original_error = logger.error

def safe_info(message, *args, **kwargs):
    return original_info(safe_log_message(str(message)), *args, **kwargs)

def safe_warning(message, *args, **kwargs):
    return original_warning(safe_log_message(str(message)), *args, **kwargs)

def safe_error(message, *args, **kwargs):
    return original_error(safe_log_message(str(message)), *args, **kwargs)

logger.info = safe_info
logger.warning = safe_warning
logger.error = safe_error

# CUDAä¼˜åŒ–è®¾ç½®
os.environ['CUDA_LAZY_LOADING'] = '1'
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True,garbage_collection_threshold:0.8'
os.environ['CUDA_VISIBLE_DEVICES'] = '0'

# å¯¼å…¥å„ç§ASRåº“
try:
    import whisper
    from faster_whisper import WhisperModel
    WHISPER_AVAILABLE = True
except ImportError:
    WHISPER_AVAILABLE = False
    logger.warning("Whisperåº“æœªå®‰è£…")

try:
    from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline
    HF_AVAILABLE = True
except ImportError:
    HF_AVAILABLE = False
    logger.warning("Transformersåº“æœªå®‰è£…")

try:
    from funasr import AutoModel
    FUNASR_AVAILABLE = True
    logger.info("FunASRåº“å¯¼å…¥æˆåŠŸ")
except ImportError:
    FUNASR_AVAILABLE = False
    logger.warning("FunASRæœªå®‰è£…")

try:
    from moviepy.editor import VideoFileClip
    MOVIEPY_AVAILABLE = True
except ImportError:
    MOVIEPY_AVAILABLE = False
    logger.warning("MoviePyæœªå®‰è£…ï¼Œå°†ä½¿ç”¨FFmpeg")

class EnhancedConfig:
    """å¢å¼ºé…ç½®ç®¡ç†"""
    def __init__(self):
        self.config_file = "enhanced_config.json"
        self.load_config()

    def load_config(self):
        default_config = {
            "models": {
                "preferred_models": {
                    "RTX 3060 Ti": ["faster-base", "funasr-paraformer", "whisper-base"],
                    "RTX 3060": ["faster-base", "whisper-small"],
                    "RTX 3070": ["faster-large", "whisper-medium", "funasr-conformer"]
                },
                "precision_levels": {
                    "high": {"fp16": True, "batch_size": 1, "beam_size": 5},
                    "balanced": {"fp16": True, "batch_size": 2, "beam_size": 3},
                    "fast": {"fp16": False, "batch_size": 4, "beam_size": 1}
                }
            },
            "audio": {
                "advanced_preprocessing": True,
                "denoise_strength": 0.7,
                "voice_enhancement": True,
                "chinese_optimization": True,
                "sample_rate": 16000
            },
            "text": {
                "postprocessing": True,
                "professional_terms": True,
                "polyphone_correction": True,
                "punctuation_smart": True,
                "context_aware": True
            },
            "optimization": {
                "tensorrt_enabled": True,
                "multi_model_ensemble": False,
                "memory_optimization": True,
                "gpu_memory_fraction": 0.8
            },
            "paths": {
                "models_path": "./models",
                "temp_path": "./temp",
                "output_path": "./output",
                "cache_path": "./cache"
            }
        }

        if os.path.exists(self.config_file):
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    # æ·±åº¦åˆå¹¶é…ç½®
                    self.config = self._deep_merge(default_config, config)
            except Exception as e:
                logger.warning(f"é…ç½®åŠ è½½å¤±è´¥: {e}")
                self.config = default_config
        else:
            self.config = default_config
            self.save_config()

    def _deep_merge(self, base, update):
        """æ·±åº¦åˆå¹¶å­—å…¸"""
        for key, value in update.items():
            if key in base and isinstance(base[key], dict) and isinstance(value, dict):
                self._deep_merge(base[key], value)
            else:
                base[key] = value
        return base

    def save_config(self):
        try:
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(self.config, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"é…ç½®ä¿å­˜å¤±è´¥: {e}")

    def get(self, path, default=None):
        """æ”¯æŒè·¯å¾„è®¿é—®ï¼šconfig.get('models.precision_levels.high')"""
        keys = path.split('.')
        current = self.config
        for key in keys:
            if isinstance(current, dict) and key in current:
                current = current[key]
            else:
                return default
        return current

class MultiModelWrapper:
    """å¤šæ¨¡å‹åŒ…è£…å™¨ - æ”¯æŒæ¨¡å‹åˆ‡æ¢å’Œé›†æˆ"""
    def __init__(self, config: EnhancedConfig):
        self.config = config
        self.models = {}
        self.current_model = None
        self.model_manager = ModelManager()

    def load_optimal_model(self, precision="balanced"):
        """åŠ è½½æœ€ä¼˜æ¨¡å‹"""
        try:
            # è·å–æ¨èæ¨¡å‹
            optimal_model = self.model_manager.get_optimal_model()
            logger.info(f"é€‰æ‹©æœ€ä¼˜æ¨¡å‹: {optimal_model}")

            # åŠ è½½æ¨¡å‹
            if optimal_model.startswith("faster-"):
                self.current_model = self._load_faster_whisper(optimal_model, precision)
            elif optimal_model.startswith("funasr"):
                self.current_model = self._load_funasr(optimal_model, precision)
            elif optimal_model.startswith("whisper"):
                self.current_model = self._load_whisper(optimal_model, precision)
            else:
                # é™çº§åˆ°åŸºç¡€æ¨¡å‹
                self.current_model = self._load_faster_whisper("faster-base", precision)

            return self.current_model is not None

        except Exception as e:
            logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False

    def _load_faster_whisper(self, model_name, precision):
        """åŠ è½½Faster-Whisperæ¨¡å‹"""
        try:
            size = model_name.replace("faster-", "")
            precision_config = self.config.get(f"models.precision_levels.{precision}", {})

            model = WhisperModel(
                size,
                device="cuda" if torch.cuda.is_available() else "cpu",
                compute_type="float16" if precision_config.get("fp16", True) else "float32",
                cpu_threads=4,
                download_root=self.config.get("paths.models_path")
            )

            logger.info(f"Faster-Whisper {size} æ¨¡å‹åŠ è½½æˆåŠŸ")
            return {"model": model, "type": "faster-whisper", "precision": precision_config}

        except Exception as e:
            logger.error(f"Faster-WhisperåŠ è½½å¤±è´¥: {e}")
            return None

    def _load_funasr(self, model_name, precision):
        """åŠ è½½FunASRæ¨¡å‹"""
        try:
            if not FUNASR_AVAILABLE:
                return None

            model_mapping = {
                "funasr-paraformer": "damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
                "funasr-conformer": "damo/speech_conformer_asr_nat-zh-cn-16k-common-vocab8404-pytorch"
            }

            actual_model = model_mapping.get(model_name, model_mapping["funasr-paraformer"])
            precision_config = self.config.get(f"models.precision_levels.{precision}", {})

            model = AutoModel(
                model=actual_model,
                device="cuda" if torch.cuda.is_available() else "cpu",
                cache_dir=self.config.get("paths.models_path"),
                disable_update=True,
                batch_size=precision_config.get("batch_size", 1)
            )

            logger.info(f"FunASR {model_name} æ¨¡å‹åŠ è½½æˆåŠŸ")
            return {"model": model, "type": "funasr", "precision": precision_config}

        except Exception as e:
            logger.error(f"FunASRåŠ è½½å¤±è´¥: {e}")
            return None

    def _load_whisper(self, model_name, precision):
        """åŠ è½½æ ‡å‡†Whisperæ¨¡å‹"""
        try:
            size = model_name.replace("whisper-", "")
            model = whisper.load_model(
                size, 
                download_root=self.config.get("paths.models_path")
            )

            if torch.cuda.is_available():
                model = model.cuda()

            precision_config = self.config.get(f"models.precision_levels.{precision}", {})

            logger.info(f"Whisper {size} æ¨¡å‹åŠ è½½æˆåŠŸ")
            return {"model": model, "type": "whisper", "precision": precision_config}

        except Exception as e:
            logger.error(f"WhisperåŠ è½½å¤±è´¥: {e}")
            return None

    def transcribe(self, audio_path: str, **kwargs) -> Dict[str, Any]:
        """æ™ºèƒ½è½¬å½•"""
        if not self.current_model:
            raise ValueError("æœªåŠ è½½ä»»ä½•æ¨¡å‹")

        model_info = self.current_model
        model_type = model_info["type"]
        model = model_info["model"]
        precision_config = model_info["precision"]

        try:
            if model_type == "faster-whisper":
                return self._transcribe_faster_whisper(model, audio_path, precision_config, **kwargs)
            elif model_type == "funasr":
                return self._transcribe_funasr(model, audio_path, precision_config, **kwargs)
            elif model_type == "whisper":
                return self._transcribe_whisper(model, audio_path, precision_config, **kwargs)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")

        except Exception as e:
            logger.error(f"è½¬å½•å¤±è´¥: {e}")
            return {"segments": [], "language": "zh", "error": str(e)}

    def _transcribe_faster_whisper(self, model, audio_path, precision_config, **kwargs):
        """Faster-Whisperè½¬å½•"""
        segments, info = model.transcribe(
            audio_path,
            language="zh",
            beam_size=precision_config.get("beam_size", 3),
            best_of=precision_config.get("best_of", 3),
            temperature=kwargs.get("temperature", 0.0),
            compression_ratio_threshold=2.4,
            log_prob_threshold=-1.0,
            no_speech_threshold=0.6,
            condition_on_previous_text=False,
            vad_filter=True,
            vad_parameters=dict(min_silence_duration_ms=500)
        )

        result = {"text": "", "segments": [], "language": info.language}

        for segment in segments:
            result["segments"].append({
                "start": segment.start,
                "end": segment.end,
                "text": segment.text.strip()
            })
            result["text"] += segment.text.strip() + " "

        return result

    def _transcribe_funasr(self, model, audio_path, precision_config, **kwargs):
        """FunASRè½¬å½•"""
        result_list = model.generate(
            input=audio_path,
            cache={},
            language="zh",
            use_itn=True,
            batch_size_s=60,
            batch_size=precision_config.get("batch_size", 1)
        )

        result = {"text": "", "segments": [], "language": "zh"}

        for i, res in enumerate(result_list):
            text = res.get("text", "")
            if text:
                start_time = i * 30.0
                end_time = (i + 1) * 30.0

                result["segments"].append({
                    "start": start_time,
                    "end": end_time,
                    "text": text.strip()
                })
                result["text"] += text.strip() + " "

        return result

    def _transcribe_whisper(self, model, audio_path, precision_config, **kwargs):
        """æ ‡å‡†Whisperè½¬å½•"""
        result = model.transcribe(
            audio_path,
            language="zh",
            fp16=precision_config.get("fp16", True),
            verbose=False,
            temperature=kwargs.get("temperature", 0.0)
        )
        return result

class EnhancedVideoSubtitleExtractor:
    """å¢å¼ºç‰ˆè§†é¢‘å­—å¹•æå–å™¨"""
    def __init__(self, config: EnhancedConfig = None, precision="balanced"):
        self.config = config or EnhancedConfig()
        self.precision = precision

        # åˆå§‹åŒ–ç»„ä»¶
        self.audio_preprocessor = AdvancedAudioPreprocessor(
            config_path="audio_config.json"
        )
        self.text_postprocessor = TextPostProcessor(
            config_file="text_correction_config.json"
        )
        self.model_wrapper = MultiModelWrapper(self.config)

        # åŠ è½½æœ€ä¼˜æ¨¡å‹
        if not self.model_wrapper.load_optimal_model(precision):
            logger.error("æ¨¡å‹åŠ è½½å¤±è´¥")
            raise RuntimeError("æ— æ³•åŠ è½½ä»»ä½•å¯ç”¨æ¨¡å‹")

    def extract_and_enhance_audio(self, video_path: str) -> Optional[str]:
        """æå–å¹¶å¢å¼ºéŸ³é¢‘"""
        try:
            # ç¬¬ä¸€æ­¥ï¼šåŸºç¡€éŸ³é¢‘æå–
            base_name = os.path.splitext(os.path.basename(video_path))[0]
            temp_path = self.config.get("paths.temp_path", "./temp")
            os.makedirs(temp_path, exist_ok=True)

            raw_audio_path = os.path.join(temp_path, f"{base_name}_raw.wav")
            enhanced_audio_path = os.path.join(temp_path, f"{base_name}_enhanced.wav")

            logger.info("ğŸµ å¼€å§‹éŸ³é¢‘æå–å’Œå¢å¼º...")

            # ä½¿ç”¨FFmpegæå–éŸ³é¢‘
            extract_cmd = [
                "ffmpeg", "-y", "-i", video_path,
                "-vn", "-acodec", "pcm_s16le",
                "-ar", str(self.config.get("audio.sample_rate", 16000)),
                "-ac", "1", "-loglevel", "error",
                raw_audio_path
            ]

            subprocess.run(extract_cmd, check=True, capture_output=True)

            if not os.path.exists(raw_audio_path):
                logger.error("åŸå§‹éŸ³é¢‘æå–å¤±è´¥")
                return None

            # ç¬¬äºŒæ­¥ï¼šé«˜çº§éŸ³é¢‘é¢„å¤„ç†
            if self.config.get("audio.advanced_preprocessing", True):
                logger.info("ğŸ”§ æ‰§è¡Œé«˜çº§éŸ³é¢‘é¢„å¤„ç†...")
                processed_path = self.audio_preprocessor.preprocess_audio(
                    raw_audio_path, enhanced_audio_path
                )

                if processed_path and os.path.exists(processed_path):
                    # éŸ³é¢‘è´¨é‡åˆ†æ
                    quality_metrics = self.audio_preprocessor.analyze_audio_quality(processed_path)
                    logger.info(f"ğŸ“Š éŸ³é¢‘è´¨é‡è¯„åˆ†: {quality_metrics.get('overall_score', 0):.1f}/100")

                    # æ¸…ç†åŸå§‹æ–‡ä»¶
                    try:
                        os.remove(raw_audio_path)
                    except:
                        pass

                    return processed_path
                else:
                    logger.warning("éŸ³é¢‘é¢„å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹éŸ³é¢‘")
                    return raw_audio_path
            else:
                return raw_audio_path

        except Exception as e:
            logger.error(f"éŸ³é¢‘æå–å¢å¼ºå¤±è´¥: {e}")
            return None

    def transcribe_with_enhancement(self, audio_path: str, **kwargs) -> Dict[str, Any]:
        """å¢å¼ºè½¬å½•"""
        try:
            logger.info("ğŸ¯ å¼€å§‹å¢å¼ºè½¬å½•...")

            # æ‰§è¡Œè½¬å½•
            result = self.model_wrapper.transcribe(audio_path, **kwargs)

            if not result["segments"]:
                logger.warning("æœªè¯†åˆ«åˆ°ä»»ä½•è¯­éŸ³å†…å®¹")
                return result

            # ç»Ÿè®¡åŸå§‹ç»“æœ
            total_segments = len(result["segments"])
            total_text = " ".join([seg["text"] for seg in result["segments"]])

            logger.info(f"ğŸ“ åŸå§‹è½¬å½•: {total_segments} ä¸ªç‰‡æ®µ, {len(total_text)} ä¸ªå­—ç¬¦")

            # æ–‡æœ¬åå¤„ç†å¢å¼º
            if self.config.get("text.postprocessing", True):
                logger.info("âœ¨ æ‰§è¡Œæ™ºèƒ½æ–‡æœ¬åå¤„ç†...")

                # è·å–é”™è¯¯ç»Ÿè®¡
                error_stats = self.text_postprocessor.get_correction_stats(total_text)
                logger.info(f"ğŸ” æ£€æµ‹åˆ°æ½œåœ¨é”™è¯¯: ä¸“ä¸šåè¯ {error_stats['professional_terms']}, "
                          f"å¤šéŸ³å­— {error_stats['polyphone_errors']}, "
                          f"åŒéŸ³å­— {error_stats['sound_alike_errors']}")

                # æ‰¹é‡å¤„ç†æ‰€æœ‰ç‰‡æ®µ
                enhanced_segments = []
                corrections_made = 0

                for segment in result["segments"]:
                    original_text = segment["text"]
                    enhanced_text = self.text_postprocessor.post_process(original_text)

                    if enhanced_text != original_text:
                        corrections_made += 1
                        logger.debug(f"æ–‡æœ¬çº é”™: '{original_text}' -> '{enhanced_text}'")

                    enhanced_segments.append({
                        "start": segment["start"],
                        "end": segment["end"],
                        "text": enhanced_text,
                        "original_text": original_text
                    })

                result["segments"] = enhanced_segments
                result["text"] = " ".join([seg["text"] for seg in enhanced_segments])
                result["corrections_made"] = corrections_made

                logger.info(f"âœ… æ–‡æœ¬åå¤„ç†å®Œæˆï¼Œä¿®æ­£äº† {corrections_made} å¤„é”™è¯¯")

            return result

        except Exception as e:
            logger.error(f"å¢å¼ºè½¬å½•å¤±è´¥: {e}")
            return {"segments": [], "language": "zh", "error": str(e)}

    def create_enhanced_srt(self, segments: List[Dict], output_path: str) -> str:
        """åˆ›å»ºå¢å¼ºSRTæ–‡ä»¶"""
        try:
            output_dir = self.config.get("paths.output_path", "./output")
            os.makedirs(output_dir, exist_ok=True)

            if not output_path.startswith(output_dir):
                output_path = os.path.join(output_dir, os.path.basename(output_path))

            # åˆ›å»ºä¸»SRTæ–‡ä»¶
            with open(output_path, "w", encoding="utf-8") as f:
                for i, segment in enumerate(segments, 1):
                    start_time = self._format_time(segment["start"])
                    end_time = self._format_time(segment["end"])
                    text = segment["text"].strip()

                    f.write(f"{i}\n")
                    f.write(f"{start_time} --> {end_time}\n")
                    f.write(f"{text}\n\n")

            # åˆ›å»ºå¯¹æ¯”æ–‡ä»¶ï¼ˆåŒ…å«åŸå§‹æ–‡æœ¬ï¼‰
            if any("original_text" in seg for seg in segments):
                comparison_path = output_path.replace(".srt", "_comparison.srt")
                with open(comparison_path, "w", encoding="utf-8") as f:
                    for i, segment in enumerate(segments, 1):
                        start_time = self._format_time(segment["start"])
                        end_time = self._format_time(segment["end"])
                        enhanced_text = segment["text"].strip()
                        original_text = segment.get("original_text", enhanced_text)

                        f.write(f"{i}\n")
                        f.write(f"{start_time} --> {end_time}\n")
                        f.write(f"åŸå§‹: {original_text}\n")
                        f.write(f"ä¼˜åŒ–: {enhanced_text}\n\n")

                logger.info(f"ğŸ“Š å¯¹æ¯”æ–‡ä»¶å·²ä¿å­˜: {comparison_path}")

            logger.info(f"âœ… SRTæ–‡ä»¶ä¿å­˜æˆåŠŸ: {output_path}")
            return output_path

        except Exception as e:
            logger.error(f"SRTæ–‡ä»¶åˆ›å»ºå¤±è´¥: {e}")
            return None

    def _format_time(self, seconds: float) -> str:
        """æ ¼å¼åŒ–æ—¶é—´"""
        hours, remainder = divmod(seconds, 3600)
        minutes, seconds = divmod(remainder, 60)
        milliseconds = int((seconds - int(seconds)) * 1000)
        return f"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d},{milliseconds:03d}"

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            temp_path = self.config.get("paths.temp_path", "./temp")
            if os.path.exists(temp_path):
                temp_files = [f for f in os.listdir(temp_path) 
                             if f.endswith(('.wav', '.tmp'))]
                for file in temp_files:
                    try:
                        os.remove(os.path.join(temp_path, file))
                    except:
                        pass

            # æ¸…ç†GPUå†…å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                gc.collect()

            logger.info("ğŸ§¹ èµ„æºæ¸…ç†å®Œæˆ")

        except Exception as e:
            logger.warning(f"æ¸…ç†è¿‡ç¨‹å‡ºé”™: {e}")

def main():
    parser = argparse.ArgumentParser(description="å¢å¼ºç‰ˆä¸­æ–‡è§†é¢‘å­—å¹•æå–å·¥å…·")
    parser.add_argument("video_path", nargs='?', default="test.mp4", help="è¾“å…¥è§†é¢‘æ–‡ä»¶")
    parser.add_argument("--output", "-o", default="output.srt", help="è¾“å‡ºå­—å¹•æ–‡ä»¶")
    parser.add_argument("--precision", "-p", default="balanced", 
                       choices=["high", "balanced", "fast"], help="ç²¾åº¦çº§åˆ«")
    parser.add_argument("--model", "-m", help="æŒ‡å®šæ¨¡å‹")
    parser.add_argument("--no-enhance", action="store_true", help="ç¦ç”¨éŸ³é¢‘å¢å¼º")
    parser.add_argument("--no-postprocess", action="store_true", help="ç¦ç”¨æ–‡æœ¬åå¤„ç†")
    parser.add_argument("--keep-temp", action="store_true", help="ä¿ç•™ä¸´æ—¶æ–‡ä»¶")

    args = parser.parse_args()

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.video_path):
        logger.error(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {args.video_path}")
        return

    logger.info(f"ğŸ¬ å¼€å§‹å¤„ç†è§†é¢‘: {args.video_path}")
    logger.info(f"ğŸ”§ ç²¾åº¦çº§åˆ«: {args.precision}")

    extractor = None
    try:
        # åˆ›å»ºé…ç½®
        config = EnhancedConfig()

        # æ ¹æ®å‚æ•°è°ƒæ•´é…ç½®
        if args.no_enhance:
            config.config["audio"]["advanced_preprocessing"] = False
        if args.no_postprocess:
            config.config["text"]["postprocessing"] = False

        # åˆ›å»ºæå–å™¨
        extractor = EnhancedVideoSubtitleExtractor(config, args.precision)

        # æå–å’Œå¢å¼ºéŸ³é¢‘
        audio_path = extractor.extract_and_enhance_audio(args.video_path)
        if not audio_path:
            logger.error("âŒ éŸ³é¢‘å¤„ç†å¤±è´¥")
            return

        # å¢å¼ºè½¬å½•
        result = extractor.transcribe_with_enhancement(audio_path)
        if not result["segments"]:
            logger.error("âŒ è½¬å½•å¤±è´¥æˆ–æ— è¯­éŸ³å†…å®¹")
            return

        # åˆ›å»ºå¢å¼ºSRT
        srt_path = extractor.create_enhanced_srt(result["segments"], args.output)
        if srt_path:
            logger.info(f"ğŸ‰ è½¬æ¢å®Œæˆï¼")
            logger.info(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {srt_path}")
            logger.info(f"ğŸ“Š è¯†åˆ«ç‰‡æ®µ: {len(result['segments'])}")
            if "corrections_made" in result:
                logger.info(f"âœ¨ æ–‡æœ¬ä¿®æ­£: {result['corrections_made']} å¤„")

    except Exception as e:
        logger.error(f"âŒ å¤„ç†å¤±è´¥: {e}")
        traceback.print_exc()

    finally:
        if extractor and not args.keep_temp:
            extractor.cleanup()

if __name__ == "__main__":
    main()